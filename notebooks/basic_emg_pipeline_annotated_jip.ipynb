{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jipuiters/Documents/PYTHON/Erasmus/ReSurfEMG/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard code libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Custom code libraries from ReSurfEMG\n",
    "from resurfemg.data_connector.config import Config\n",
    "from resurfemg.data_connector import file_discovery\n",
    "from resurfemg.postprocessing import features as feat\n",
    "from resurfemg.postprocessing import quality_assessment as qa\n",
    "from resurfemg.pipelines import ipy_widgets\n",
    "from resurfemg.data_connector.tmsisdk_lite import Poly5Reader\n",
    "from resurfemg.data_connector.data_classes import (\n",
    "VentilatorDataGroup, EmgDataGroup)\n",
    "\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the ventilator and sEMG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⛔ File contains no data and is skipped: paw_012_t1_v1_nodata.npy\n",
      "⛔ File contains no data and is skipped: paw_006_nodata.npy\n",
      "⛔ File contains no data and is skipped: two_track_emg_006_nodata.npy\n",
      "⛔ File contains no data and is skipped: two_track_emg_012_t1_v1_nodata.npy\n",
      "⛔ File contains no data and is skipped: two_track_emg_005_t1_v1_nodata.npy\n",
      "⛔ File contains no data and is skipped: two_track_emg_011_t0_v2_nodata.npy\n",
      "⛔ File contains no data and is skipped: paw_011_t0_v2_nodata.npy\n",
      "⛔ File contains no data and is skipped: paw_005_t1_v1_nodata.npy\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "No ECG channel detected. Set ECG channel index with `EmgDataGroup.set_ecg_idx(arg)` method.\n",
      "Auto-detected Pvent channel from labels.\n",
      "\n",
      "✅ Complete import: 16 patients loaded.\n",
      "\n",
      "Patient 001:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_001_t0.npy\n",
      "    Vent-file:  paw_001_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_001_t1.npy\n",
      "    Vent-file:  paw_001_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_001_t3.npy\n",
      "    Vent-file:  paw_001_t3.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_001_t24.npy\n",
      "    Vent-file:  paw_001_t24.npy\n",
      "  Time t48:\n",
      "    EMG-file:   two_track_emg_001_t48.npy\n",
      "    Vent-file:  paw_001_t48.npy\n",
      "Patient 002:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_002_t0.npy\n",
      "    Vent-file:  paw_002_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_002_t1.npy\n",
      "    Vent-file:  paw_002_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_002_t3.npy\n",
      "    Vent-file:  paw_002_t3.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_002_t24.npy\n",
      "    Vent-file:  paw_002_t24.npy\n",
      "  Time t48:\n",
      "    EMG-file:   two_track_emg_002_t48.npy\n",
      "    Vent-file:  paw_002_t48.npy\n",
      "Patient 003:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_003_t0.npy\n",
      "    Vent-file:  paw_003_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_003_t1.npy\n",
      "    Vent-file:  paw_003_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_003_t3.npy\n",
      "    Vent-file:  paw_003_t3.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_003_t24.npy\n",
      "    Vent-file:  paw_003_t24.npy\n",
      "Patient 004:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_004_t0.npy\n",
      "    Vent-file:  paw_004_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_004_t1.npy\n",
      "    Vent-file:  paw_004_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_004_t3.npy\n",
      "    Vent-file:  paw_004_t3.npy\n",
      "Patient 005:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_005_t0.npy\n",
      "    Vent-file:  paw_005_t0.npy\n",
      "  Time t1v2:\n",
      "    EMG-file:   two_track_emg_005_t1_v2.npy\n",
      "    Vent-file:  paw_005_t1_v2.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_005_t3.npy\n",
      "    Vent-file:  paw_005_t3.npy\n",
      "Patient 006:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_006_t0.npy\n",
      "    Vent-file:  paw_006_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_006_t1.npy\n",
      "    Vent-file:  paw_006_t1.npy\n",
      "  Time t2:\n",
      "    EMG-file:   two_track_emg_006_t2_weanen_kunstneus.npy\n",
      "    Vent-file:  paw_006_t2_weanen_kunstneus.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_006_t3.npy\n",
      "    Vent-file:  paw_006_t3.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_006_t24.npy\n",
      "    Vent-file:  paw_006_t24.npy\n",
      "  Time t48:\n",
      "    EMG-file:   two_track_emg_006_t48_weanen.npy\n",
      "    Vent-file:  paw_006_t48_weanen.npy\n",
      "Patient 007:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_007_t0.npy\n",
      "    Vent-file:  paw_007_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_007_t1.npy\n",
      "    Vent-file:  paw_007_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_007_t3.npy\n",
      "    Vent-file:  paw_007_t3.npy\n",
      "  Time t5:\n",
      "    EMG-file:   two_track_emg_007_t5_SBT.npy\n",
      "    Vent-file:  paw_007_t5_SBT.npy\n",
      "Patient 008:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_008_t0.npy\n",
      "    Vent-file:  paw_008_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_008_t1.npy\n",
      "    Vent-file:  paw_008_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_008_t3.npy\n",
      "    Vent-file:  paw_008_t3.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_008_t24.npy\n",
      "    Vent-file:  paw_008_t24.npy\n",
      "Patient 009:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_009_t0.npy\n",
      "    Vent-file:  paw_009_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_009_t1.npy\n",
      "    Vent-file:  paw_009_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_009_t3.npy\n",
      "    Vent-file:  paw_009_t3_IGNORE_paw_data.npy\n",
      "Patient 010:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_010_t0.npy\n",
      "    Vent-file:  paw_010_t0.npy\n",
      "  Time t1v1:\n",
      "    EMG-file:   two_track_emg_010_t1_v1.npy\n",
      "    Vent-file:  paw_010_t1_v1.npy\n",
      "  Time t1v2:\n",
      "    EMG-file:   two_track_emg_010_t1_v2.npy\n",
      "    Vent-file:  paw_010_t1_v2.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_010_t24.npy\n",
      "    Vent-file:  paw_010_t24.npy\n",
      "  Time t48:\n",
      "    EMG-file:   two_track_emg_010_t48.npy\n",
      "    Vent-file:  paw_010_t48.npy\n",
      "Patient 011:\n",
      "  Time t0v1:\n",
      "    EMG-file:   two_track_emg_011_t0_v1.npy\n",
      "    Vent-file:  paw_011_t0_v1.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_011_t1.npy\n",
      "    Vent-file:  paw_011_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_011_t3.npy\n",
      "    Vent-file:  paw_011_t3.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_011_t24.npy\n",
      "    Vent-file:  paw_011_t24.npy\n",
      "  Time t48:\n",
      "    EMG-file:   two_track_emg_011_t48.npy\n",
      "    Vent-file:  paw_011_t48.npy\n",
      "Patient 012:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_012_t0.npy\n",
      "    Vent-file:  paw_012_t0.npy\n",
      "  Time t1v2:\n",
      "    EMG-file:   two_track_emg_012_t1_v2.npy\n",
      "    Vent-file:  paw_012_t1_v2.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_012_t3.npy\n",
      "    Vent-file:  paw_012_t3.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_012_t24.npy\n",
      "    Vent-file:  paw_012_t24.npy\n",
      "Patient 013:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_013_t0.npy\n",
      "    Vent-file:  paw_013_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_013_t1.npy\n",
      "    Vent-file:  paw_013_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_013_t3.npy\n",
      "    Vent-file:  paw_013_t3.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_013_t24.npy\n",
      "    Vent-file:  paw_013_t24.npy\n",
      "  Time t48:\n",
      "    EMG-file:   two_track_emg_013_t48.npy\n",
      "    Vent-file:  paw_013_t48.npy\n",
      "Patient 014:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_014_t0.npy\n",
      "    Vent-file:  paw_014_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_014_t1.npy\n",
      "    Vent-file:  paw_014_t1.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_014_t3.npy\n",
      "    Vent-file:  paw_014_t3.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_014_t24.npy\n",
      "    Vent-file:  paw_014_t24.npy\n",
      "  Time t48:\n",
      "    EMG-file:   two_track_emg_014_t48.npy\n",
      "    Vent-file:  paw_014_t48.npy\n",
      "Patient 015:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_015_t0.npy\n",
      "    Vent-file:  paw_015_t0.npy\n",
      "  Time t1v1:\n",
      "    EMG-file:   two_track_emg_015_t1_v1.npy\n",
      "    Vent-file:  paw_015_t1_v1.npy\n",
      "  Time t1v2:\n",
      "    EMG-file:   two_track_emg_015_t1_v2.npy\n",
      "    Vent-file:  paw_015_t1_v2.npy\n",
      "  Time t3:\n",
      "    EMG-file:   two_track_emg_015_t3.npy\n",
      "    Vent-file:  paw_015_t3.npy\n",
      "Patient 016:\n",
      "  Time t0:\n",
      "    EMG-file:   two_track_emg_016_t0.npy\n",
      "    Vent-file:  paw_016_t0.npy\n",
      "  Time t1:\n",
      "    EMG-file:   two_track_emg_016_t1.npy\n",
      "    Vent-file:  paw_016_t1.npy\n",
      "  Time t24:\n",
      "    EMG-file:   two_track_emg_016_t24.npy\n",
      "    Vent-file:  paw_016_t24.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from resurfemg.data_connector.data_classes import EmgDataGroup, VentilatorDataGroup\n",
    "\n",
    "# === Geldige basis tijdstippen ===\n",
    "valid_base_timepoints = {\"t0\", \"t1\", \"t2\", \"t3\", \"t5\", \"t24\", \"t48\"}\n",
    "\n",
    "# === Pad naar je datafolder ===\n",
    "base_path = os.path.expanduser('~/Documents/Anonymous_data_kopie')\n",
    "all_files = [f for f in os.listdir(base_path) if f.endswith('.npy')]\n",
    "\n",
    "# === Aangepaste regex: haal ook versie eruit ===\n",
    "pattern = re.compile(\n",
    "    r'(?P<type>two_track_emg|paw)_(?P<id>\\d{3})_(?P<tp>t\\d+)(?:_v(?P<version>\\d+))?(?:_.*)?\\.npy'\n",
    ")\n",
    "\n",
    "# === Data mapping ===\n",
    "record_map = {}\n",
    "\n",
    "for f in all_files:\n",
    "    if \"nodata\" in f.lower():\n",
    "        print(f\"⛔ File contains no data and is skipped: {f}\")\n",
    "        continue\n",
    "\n",
    "    match = pattern.match(f)\n",
    "    if not match:\n",
    "        print(f\"⚠️  Could not parse name of file: {f}\")\n",
    "        continue\n",
    "\n",
    "    data_type = match.group(\"type\")\n",
    "    patient_id = match.group(\"id\")\n",
    "    base_tp = match.group(\"tp\")\n",
    "    version = match.group(\"version\")\n",
    "\n",
    "    # Alleen tijdstippen gebruiken die geldig zijn\n",
    "    if base_tp not in valid_base_timepoints:\n",
    "        print(f\"⚠️  invalid time iD '{base_tp}' in file {f} — skipped\")\n",
    "        continue\n",
    "\n",
    "    # Nieuw tijdstiplabel: t1v1 of gewoon t1\n",
    "    timepoint = base_tp if version is None else f\"{base_tp}v{version}\"\n",
    "    key = (patient_id, timepoint)\n",
    "\n",
    "    if key not in record_map:\n",
    "        record_map[key] = {}\n",
    "    if data_type == \"two_track_emg\":\n",
    "        record_map[key][\"emg\"] = f\n",
    "    elif data_type == \"paw\":\n",
    "        record_map[key][\"vent\"] = f\n",
    "\n",
    "# === Data inladen ===\n",
    "patient_data = {}\n",
    "\n",
    "for (pid, tp), files in sorted(record_map.items()):\n",
    "    # Meld als er maar één van de twee typen is\n",
    "    if \"emg\" not in files and \"vent\" in files:\n",
    "        print(f\"❌ Only ventilatorfile found patient {pid}, {tp} — EMG file missing. Data not loaded.\")\n",
    "        continue\n",
    "    elif \"vent\" not in files and \"emg\" in files:\n",
    "        print(f\"❌ Only EMG-file found patient {pid}, {tp} — ventilatorfile missing. Data not loaded.\")\n",
    "        continue\n",
    "\n",
    "    emg_path = os.path.join(base_path, files[\"emg\"])\n",
    "    vent_path = os.path.join(base_path, files[\"vent\"])\n",
    "\n",
    "    y_emg = np.load(emg_path)\n",
    "    y_vent = np.load(vent_path)\n",
    "\n",
    "    fs_emg = 2048\n",
    "    fs_vent = 100\n",
    "\n",
    "    emg_ts = EmgDataGroup(\n",
    "        y_emg,\n",
    "        fs=fs_emg,\n",
    "        labels=[\"parasternal\", \"diaphragm\"],\n",
    "        units=2 * [\"uV\"]\n",
    "    )\n",
    "\n",
    "    vent_ts = VentilatorDataGroup(\n",
    "        y_vent,\n",
    "        fs=fs_vent,\n",
    "        labels=[\"Paw\"],\n",
    "        units=[\"cmH2O\"]\n",
    "    )\n",
    "\n",
    "    if pid not in patient_data:\n",
    "        patient_data[pid] = {}\n",
    "    patient_data[pid][tp] = {\n",
    "        \"emg\": emg_ts,\n",
    "        \"vent\": vent_ts,\n",
    "        \"emg_file\": emg_path,\n",
    "        \"vent_file\": vent_path\n",
    "    }\n",
    "\n",
    "# === Samenvatting ===\n",
    "print(f\"\\n✅ Complete import: {len(patient_data)} patients loaded.\\n\")\n",
    "for pid in sorted(patient_data.keys()):\n",
    "    print(f\"Patient {pid}:\")\n",
    "    for tp in sorted(patient_data[pid].keys(), key=lambda x: int(re.search(r'\\d+', x).group())):\n",
    "        print(f\"  Time {tp}:\")\n",
    "        print(f\"    EMG-file:   {os.path.basename(patient_data[pid][tp]['emg_file'])}\")\n",
    "        print(f\"    Vent-file:  {os.path.basename(patient_data[pid][tp]['vent_file'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying bandpass filter patient 001, t0...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "emg_bandpass_butter() got an unexpected keyword argument 'fs_emg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m         emg_ts = data[\u001b[33m'\u001b[39m\u001b[33memg\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     28\u001b[39m         \u001b[38;5;66;03m# Voer standaard filtering uit (20-500 Hz bandpass)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m         \u001b[43memg_ts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfilter_emg\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m            \u001b[49m\u001b[43msignal_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mraw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# filter op de originele data\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhp_cf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlp_cf\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchannel_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# None = alle kanalen\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Filtering complete patient \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m All EMG-signals filtered and stored in `.y_filt` per channel.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PYTHON/Erasmus/ReSurfEMG/resurfemg/data_connector/data_classes.py:946\u001b[39m, in \u001b[36mTimeSeriesGroup.run\u001b[39m\u001b[34m(self, method, channel_idxs, **kwargs)\u001b[39m\n\u001b[32m    944\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    945\u001b[39m                 _kwargs[\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m] = kwargs[\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m][idx]\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchannel_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    948\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mInvalid method\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PYTHON/Erasmus/ReSurfEMG/resurfemg/data_connector/data_classes.py:139\u001b[39m, in \u001b[36mTimeSeries.filter_emg\u001b[39m\u001b[34m(self, signal_type, hp_cf, lp_cf, order)\u001b[39m\n\u001b[32m    137\u001b[39m y_data = \u001b[38;5;28mself\u001b[39m.signal_type_data(signal_type=signal_type)\n\u001b[32m    138\u001b[39m \u001b[38;5;66;03m# Eliminate the baseline wander from the data using a band-pass filter\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28mself\u001b[39m.y_filt = \u001b[43mfilt\u001b[49m\u001b[43m.\u001b[49m\u001b[43memg_bandpass_butter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhigh_pass\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhp_cf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlow_pass\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlp_cf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfs_emg\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: emg_bandpass_butter() got an unexpected keyword argument 'fs_emg'"
     ]
    }
   ],
   "source": [
    "# Filter\n",
    "#emg_timeseries.run('filter_emg')\n",
    "# Which equals:\n",
    "# emg_timeseries.run(\n",
    "#     'filter_emg',\n",
    "#     signal_type='raw',\n",
    "#     hp_cf=20.0,\n",
    "#     lp_cf=500.0,    \n",
    "#     channel_idxs=[0, 1],\n",
    "# )\n",
    "# Where:\n",
    "# signal_type:      Filter the raw, just assigned, data\n",
    "# hp_cf:            High-pass cut-off frequency of 20 Hz\n",
    "# lp_cf:            Low-pass cut-off frequency of 500 Hz\n",
    "# channel_idxs:     For all channels (None would default to this)\n",
    "\n",
    "# --> Data is stored in:\n",
    "# emg_timeseries.channels[channel_idx].y_filt\n",
    "# Or for short:\n",
    "# emg_timeseries[channel_idx].y_filt\n",
    "# Filter alle EMG-data op alle tijdstippen\n",
    "for pid, patient in patient_data.items():\n",
    "    for tp, data in patient.items():\n",
    "        print(f\"Applying bandpass filter patient {pid}, {tp}...\")\n",
    "        \n",
    "        emg_ts = data['emg']\n",
    "        \n",
    "        # Voer standaard filtering uit (20-500 Hz bandpass)\n",
    "        emg_ts.run(\n",
    "            'filter_emg',\n",
    "            signal_type='raw',   # filter op de originele data\n",
    "            hp_cf=20.0,\n",
    "            lp_cf=500.0,\n",
    "            channel_idxs=None    # None = alle kanalen\n",
    "        )\n",
    "        \n",
    "        print(f\" Filtering complete patient {pid},{tp}.\")\n",
    "\n",
    "print(\"\\n All EMG-signals filtered and stored in `.y_filt` per channel.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Eliminate ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Through gating\n",
    "\n",
    "# # Gate the EMG\n",
    "#emg_timeseries.run('gating', overwrite=True)\n",
    "# # Which equals:\n",
    "# # emg_timeseries.run(\n",
    "# #     'gating'\n",
    "# #     signal_type='filt',        \n",
    "# #     gate_width_samples=None,    \n",
    "# #     ecg_peak_idxs=None,         \n",
    "# #     ecg_raw=None,               \n",
    "# #     bp_filter=True,\n",
    "# #     channel_idxs=None,\n",
    "# #     overwrite=True)\n",
    "# # )\n",
    "# # Where:\n",
    "# # signal_type:          Filter the clean, just filtered, data\n",
    "# # gate_width_samples:   Gate width, `None` defaults to fs // 10\n",
    "# # ecg_peak_idxs:        Sample idxs of ECG peaks, when `None` peaks are \n",
    "# #                       automatically identified.\n",
    "# # ecg_raw:              ECG data to detect ECG peaks in if no ecg_peak_idxs are\n",
    "# #                       provided. If `None` and no ecg-channel is detected\n",
    "# #                       from the labels the raw channel data is used.\n",
    "# # bp_filter:            True/False: Filter the provided ecg_raw between 1-500\n",
    "# #                       Hz before peak detection\n",
    "# # channel_idxs:         For all channels (None would default to this)\n",
    "# # overwrite:            Overwrite the existing ECG peaks\n",
    "\n",
    "# # --> Data is stored in:\n",
    "# # emg_timeseries.channels[channel_idx].y_clean\n",
    "# # Or for short:\n",
    "# # emg_timeseries[channel_idx].y_clean\n",
    "\n",
    "# Verwijder ECG-artefacten via gating voor alle tijdstippen\n",
    "for pid, patient in patient_data.items():\n",
    "    for tp, data in patient.items():\n",
    "        print(f\" Removing ECG-Artefacts patient {pid},{tp}...\")\n",
    "        \n",
    "        emg_ts = data['emg']\n",
    "        \n",
    "        emg_ts.run(\n",
    "            'gating',\n",
    "            signal_type='filt',  # gebruik gefilterde data\n",
    "            gate_width_samples=int(emg_ts.param['fs'] * 0.40),  # 400 ms\n",
    "            ecg_peak_idxs=None,\n",
    "            ecg_raw=None,\n",
    "            bp_filter=True,\n",
    "            channel_idxs=None,\n",
    "            overwrite=True\n",
    "        )\n",
    "        \n",
    "        print(f\"Artefacts succesfully removed patient {pid}, {tp}.\")\n",
    "\n",
    "print(\"\\n All ECG-artefacts removed and stored in `.y_clean` per channel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the envelope of the signal\n",
    "#emg_timeseries.run('envelope')\n",
    "# Which equals:\n",
    "# emg_timeseries.run(\n",
    "#     'envelope',\n",
    "#     env_window=None,\n",
    "#     env_type='rms',\n",
    "#     signal_type='clean',\n",
    "# )\n",
    "# Where:\n",
    "# env_window:           Envelope window width, `None` defaults to fs // 5\n",
    "# env_type:             'rms' for root-mean-square (default), 'arv' for average\n",
    "#                       rectified\n",
    "# signal_type:          Calculate the envelope over the clean data\n",
    "\n",
    "# --> Data is stored in:\n",
    "# emg_timeseries.channels[channel_idx].y_env\n",
    "# Or for short:\n",
    "# emg_timeseries[channel_idx].y_env\n",
    "\n",
    "# Envelope berekenen over het 'clean' signaal (na filtering & gating)\n",
    "# Bereken envelopes voor alle patiënten en tijdstippen\n",
    "for pid, patient in patient_data.items():\n",
    "    for tp, data in patient.items():\n",
    "        print(f\"Applying envelope patient {pid}, {tp}...\")\n",
    "\n",
    "        emg_ts = data['emg']\n",
    "\n",
    "        emg_ts.run(\n",
    "            'envelope',\n",
    "            env_window= 3*(fs_emg // 5),   # standaard = fs // 5, nu dus 3*breder dan default= 600 ms\n",
    "            env_type='rms',          # of 'arv' voor average rectified\n",
    "            signal_type='clean'      # gebruik gated signaal\n",
    "        )\n",
    "\n",
    "        print(f\"succesfully calculated Envelope patient {pid}, {tp}.\")\n",
    "\n",
    "print(\"\\nEnvelopes stored in `.y_env` per channel.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the baseline for the EMG envelopes and p_vent\n",
    "#emg_timeseries.run('baseline')\n",
    "# Which equals:\n",
    "# emg_timeseries.run(\n",
    "#    'baseline',\n",
    "#     percentile=33,\n",
    "#     window_s=int(7.5 * fs_emg),\n",
    "#     step_s=fs_emg // 5,\n",
    "#     method='default',\n",
    "#     signal_type='env',\n",
    "#     augm_percentile=25,\n",
    "#     ma_window=None,\n",
    "#     perc_window=None,\n",
    "#     channel_idxs=[0, 1], \n",
    "# )\n",
    "# Where:\n",
    "# percentile:       Percentile of signal in the window to take as the baseline\n",
    "#                   value \n",
    "# window_s:         Window length in samples (default: int(7.5 * fs))\n",
    "# step_s:           Number of consecutive samples with the same baseline value\n",
    "#                   (default: fs // 5)\n",
    "# method:           'default' or 'slopesum'\n",
    "# signal_type:      Calculate the baseline over the envelope (y_env) for emg \n",
    "#                   and over the original signal for p_vent\n",
    "# augm_percentile   Augmented_percentile for slopesum baseline\n",
    "# ma_window:        Moving average window in samples for average dy/dt in\n",
    "#                   slopesum baseline\n",
    "# perc_window:      'perc_window' for slopesum baseline.\n",
    "# channel_idxs:     For all channels (None would default to this)\n",
    "\n",
    "# --> Data is stored in:\n",
    "# emg_timeseries.channels[channel_idx].y_baseline\n",
    "\n",
    "#vent_timeseries.run(\n",
    "#    'baseline',\n",
    "#    channel_idxs=[0],\n",
    "#    signal_type='raw')\n",
    "\n",
    "# Baseline berekenen voor zowel EMG (env) als ventilatordruk (raw)\n",
    "for pid, patient in patient_data.items():\n",
    "    for tp, data in patient.items():\n",
    "        print(f\"calculating baseline patient {pid}, {tp}...\")\n",
    "\n",
    "        emg_ts = data['emg']\n",
    "        vent_ts = data['vent']\n",
    "\n",
    "        # EMG baseline op de envelope\n",
    "        emg_ts.run(\n",
    "            'baseline',\n",
    "            signal_type='env',     # werk op de RMS-envelope\n",
    "            channel_idxs=None      # beide leads\n",
    "        )\n",
    "\n",
    "        # Ventilator-baseline op het ruwe signaal\n",
    "        vent_ts.run(\n",
    "            'baseline',\n",
    "            signal_type='raw',\n",
    "            channel_idxs=[0]\n",
    "        )\n",
    "\n",
    "        print(f\"Baseline ready patient {pid}, {tp}.\")\n",
    "\n",
    "print(\"\\nBaselines stored in `.y_baseline` per channel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOTION ARTEFACT DETECTION\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def calculate_baseline_drift(baseline, window_size):\n",
    "    \"\"\"\n",
    "    Calculate baseline drift: Divide the baseline signal into non-overlapping windows,\n",
    "    and for each window compute (max - min).\n",
    "    \"\"\"\n",
    "    drift = []\n",
    "    for i in range(0, len(baseline) - window_size + 1, window_size):\n",
    "        window = baseline[i:i + window_size]\n",
    "        drift.append(max(window) - min(window))\n",
    "    return drift\n",
    "\n",
    "def identify_abnormal_windows(drift, window_size, fs, threshold_factor=3):\n",
    "    \"\"\"\n",
    "    Identify abnormal windows using the median absolute deviation (MAD).\n",
    "    Returns a list of tuples with (start_time, end_time) for windows that are abnormal.\n",
    "    \"\"\"\n",
    "    median_drift = np.median(drift)\n",
    "    mad = np.median(np.abs(drift - median_drift))\n",
    "    threshold = median_drift + threshold_factor * mad\n",
    "    abnormal_windows = [i for i, d in enumerate(drift) if d > threshold]\n",
    "\n",
    "    abnormal_times = []\n",
    "    if abnormal_windows:\n",
    "        start_time = abnormal_windows[0] * (window_size / fs)\n",
    "        end_time = start_time + (window_size / fs)\n",
    "        for i in range(1, len(abnormal_windows)):\n",
    "            current_time = abnormal_windows[i] * (window_size / fs)\n",
    "            if current_time <= end_time:  # overlapping or adjacent\n",
    "                end_time += (window_size / fs)\n",
    "            else:\n",
    "                abnormal_times.append((start_time, end_time))\n",
    "                start_time = current_time\n",
    "                end_time = start_time + (window_size / fs)\n",
    "        abnormal_times.append((start_time, end_time))\n",
    "    return abnormal_times\n",
    "\n",
    "def merge_time_windows(time_windows):\n",
    "    \"\"\"\n",
    "    Merge overlapping or adjacent time windows.\n",
    "    \"\"\"\n",
    "    if not time_windows:\n",
    "        return []\n",
    "    time_windows.sort()  # sort by start time\n",
    "    merged_windows = [time_windows[0]]\n",
    "    for current_start, current_end in time_windows[1:]:\n",
    "        last_start, last_end = merged_windows[-1]\n",
    "        if current_start <= last_end:  # overlapping or adjacent\n",
    "            merged_windows[-1] = (last_start, max(last_end, current_end))\n",
    "        else:\n",
    "            merged_windows.append((current_start, current_end))\n",
    "    return merged_windows\n",
    "\n",
    "#############################################\n",
    "# PRINTING FUNCTION WITH SEPARATE ABNORMAL TIME WINDOWS\n",
    "#############################################\n",
    "\n",
    "def print_formatted_results(pid, tp, emg_baseline_drift, vent_baseline_drift, filtered_channels, ab_paras, ab_diaphragm, ab_vent):\n",
    "    print(f\"\\nResults for Patient {pid}, Time {tp}:\")\n",
    "    \n",
    "    # Parasternal results (lead index 0)\n",
    "    print(f\"  Parasternal: Mean Baseline Drift({np.mean(emg_baseline_drift[0]):.2f}), Median Baseline Drift({np.median(emg_baseline_drift[0]):.2f}), Max Baseline Drift({np.max(emg_baseline_drift[0]):.2f})\")\n",
    "    if ab_paras == \"filtered_out\":\n",
    "        print(\"    Abnormal Time Windows Parasternal: Whole signal filtered out\")\n",
    "    elif ab_paras:\n",
    "        merged = merge_time_windows(ab_paras)\n",
    "        print(f\"    Abnormal Time Windows Parasternal: {merged}\")\n",
    "    else:\n",
    "        print(\"    Abnormal Time Windows Parasternal: None\")\n",
    "\n",
    "    # Diaphragm results (lead index 1)\n",
    "    print(f\"  Diaphragm: Mean Baseline Drift({np.mean(emg_baseline_drift[1]):.2f}), Median Baseline Drift({np.median(emg_baseline_drift[1]):.2f}), Max Baseline Drift({np.max(emg_baseline_drift[1]):.2f})\")\n",
    "    if ab_diaphragm == \"filtered_out\":\n",
    "        print(\"    Abnormal Time Windows Diaphragm: Whole signal filtered out\")\n",
    "    elif ab_diaphragm:\n",
    "        merged = merge_time_windows(ab_diaphragm)\n",
    "        print(f\"    Abnormal Time Windows Diaphragm: {merged}\")\n",
    "    else:\n",
    "        print(\"    Abnormal Time Windows Diaphragm: None\")\n",
    "\n",
    "    # Ventilator results (assumed one channel for vent)\n",
    "    print(f\"  Ventilator: Mean Baseline Drift({np.mean(vent_baseline_drift[0]):.2f}), Median Baseline Drift({np.median(vent_baseline_drift[0]):.2f}), Max Baseline Drift({np.max(vent_baseline_drift[0]):.2f})\")\n",
    "    if ab_vent == \"filtered_out\":\n",
    "        print(\"    Abnormal Time Windows Ventilator: Whole signal filtered out\")\n",
    "    elif ab_vent:\n",
    "        merged = merge_time_windows(ab_vent)\n",
    "        print(f\"    Abnormal Time Windows Ventilator: {merged}\")\n",
    "    else:\n",
    "        print(\"    Abnormal Time Windows Ventilator: None\")\n",
    "    \n",
    "    if filtered_channels:\n",
    "        for channel in filtered_channels:\n",
    "            print(f\"  Note: Measurement for patient {pid}, time {tp}, channel {channel} filtered out due to high median baseline drift.\")\n",
    "\n",
    "#############################################\n",
    "# MAIN SCRIPT: ITERATE OVER PATIENT DATA AND WRITE CSV OUTPUT\n",
    "#############################################\n",
    "\n",
    "# Settings\n",
    "fs_emg = 2048  \n",
    "fs_ventilator = 100  \n",
    "window_size_emg = int(5 * fs_emg)  \n",
    "window_size_vent = int(5 * fs_ventilator)  \n",
    "median_drift_threshold = 5.0  \n",
    "mad_threshold_factor = 8.0  \n",
    "\n",
    "channel_names = [\"parasternal\", \"diaphragm\"]\n",
    "\n",
    "# Dictionary to store abnormal times for each patient and time point.\n",
    "# Structure: abnormal_times_dict[pid][tp] = {\"parasternal\": ..., \"diaphragm\": ..., \"ventilator\": ...}\n",
    "abnormal_times_dict = {}\n",
    "\n",
    "# List to store CSV rows.\n",
    "# We create separate columns for each lead's drift stats and abnormal time windows.\n",
    "csv_rows = []\n",
    "\n",
    "for pid, patient in patient_data.items():\n",
    "    for tp, data in patient.items():\n",
    "        emg_ts = data['emg']\n",
    "        vent_ts = data['vent']\n",
    "\n",
    "        # Initialize abnormal times dictionary for this patient and time if not present.\n",
    "        if pid not in abnormal_times_dict:\n",
    "            abnormal_times_dict[pid] = {}\n",
    "        if tp not in abnormal_times_dict[pid]:\n",
    "            abnormal_times_dict[pid][tp] = {}\n",
    "\n",
    "        # To store drift and abnormal time windows for each lead.\n",
    "        emg_baseline_drift = []\n",
    "        vent_baseline_drift = []\n",
    "        filtered_channels = []  # To note which channels are fully filtered out.\n",
    "\n",
    "        # Process EMG channels separately.\n",
    "        for channel_idx in range(len(emg_ts.channels)):\n",
    "            baseline = emg_ts.channels[channel_idx].y_baseline\n",
    "            drift = calculate_baseline_drift(baseline, window_size_emg)\n",
    "            emg_baseline_drift.append(drift)\n",
    "            median_current = np.median(drift)\n",
    "            # Filter based on high median baseline drift instead of the mean.\n",
    "            if median_current > median_drift_threshold:\n",
    "                filtered_channels.append(channel_names[channel_idx])\n",
    "                abnormal_times = \"filtered_out\"\n",
    "            else:\n",
    "                abnormal_times = identify_abnormal_windows(drift, window_size_emg, fs_emg, mad_threshold_factor)\n",
    "            # Store the abnormal times for this EMG channel using the lead name as key.\n",
    "            abnormal_times_dict[pid][tp][channel_names[channel_idx]] = abnormal_times\n",
    "\n",
    "        # Process Ventilator channels.\n",
    "        for channel_idx in range(len(vent_ts.channels)):\n",
    "            baseline = vent_ts.channels[channel_idx].y_baseline\n",
    "            drift = calculate_baseline_drift(baseline, window_size_vent)\n",
    "            vent_baseline_drift.append(drift)\n",
    "            median_current = np.median(drift)\n",
    "            if median_current > median_drift_threshold:\n",
    "                filtered_channels.append(f\"Ventilator channel {channel_idx}\")\n",
    "                abnormal_times_v = \"filtered_out\"\n",
    "            else:\n",
    "                abnormal_times_v = identify_abnormal_windows(drift, window_size_vent, fs_ventilator, mad_threshold_factor)\n",
    "            # For the ventilator, we assume one channel is used for the summary.\n",
    "            if channel_idx == 0:\n",
    "                abnormal_times_dict[pid][tp][\"ventilator\"] = abnormal_times_v\n",
    "\n",
    "        # Create CSV row with separate columns.\n",
    "        # We report drift values (mean, median and max) for each lead and then the abnormal time windows.\n",
    "        row = [\n",
    "            pid,\n",
    "            tp,\n",
    "            f\"Parasternal: Mean Drift: {np.mean(emg_baseline_drift[0]):.2f}, Median Drift: {np.median(emg_baseline_drift[0]):.2f}, Max Drift: {np.max(emg_baseline_drift[0]):.2f}\",\n",
    "            f\"Abnormal Parasternal: {abnormal_times_dict[pid][tp].get('parasternal', None)}\",\n",
    "            f\"Diaphragm: Mean Drift: {np.mean(emg_baseline_drift[1]):.2f}, Median Drift: {np.median(emg_baseline_drift[1]):.2f}, Max Drift: {np.max(emg_baseline_drift[1]):.2f}\",\n",
    "            f\"Abnormal Diaphragm: {abnormal_times_dict[pid][tp].get('diaphragm', None)}\",\n",
    "            f\"Ventilator: Mean Drift: {np.mean(vent_baseline_drift[0]):.2f}, Median Drift: {np.median(vent_baseline_drift[0]):.2f}, Max Drift: {np.max(vent_baseline_drift[0]):.2f}\",\n",
    "            f\"Abnormal Ventilator: {abnormal_times_dict[pid][tp].get('ventilator', None)}\",\n",
    "            f\"Filtered Channels: {filtered_channels}\"\n",
    "        ]\n",
    "        csv_rows.append(row)\n",
    "\n",
    "        # Retrieve separate abnormal times for printing.\n",
    "        ab_paras = abnormal_times_dict[pid][tp].get(\"parasternal\", None)\n",
    "        ab_diaphragm = abnormal_times_dict[pid][tp].get(\"diaphragm\", None)\n",
    "        ab_vent = abnormal_times_dict[pid][tp].get(\"ventilator\", None)\n",
    "        print_formatted_results(pid, tp, emg_baseline_drift, vent_baseline_drift, filtered_channels, ab_paras, ab_diaphragm, ab_vent)\n",
    "\n",
    "print(\"\\nAverage, median and maximum baseline drift measurements printed for each channel.\")\n",
    "\n",
    "# Save the output to a CSV file with separate columns for each abnormal windows field.\n",
    "with open('baseline_drift_analysis.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    headers = [\n",
    "        \"Patient ID\", \"Time ID\",\n",
    "        \"Parasternal\", \"Abnormal Parasternal\",\n",
    "        \"Diaphragm\", \"Abnormal Diaphragm\",\n",
    "        \"Ventilator\", \"Abnormal Ventilator\",\n",
    "        \"Filtered Channels\"\n",
    "    ]\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(csv_rows)\n",
    "\n",
    "print(\"Output saved to baseline_drift_analysis.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUAL INSPECTION MOTION ARTEFACT EPOCHS\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "import numpy as np\n",
    "import csv\n",
    "import ast\n",
    "\n",
    "#############################################\n",
    "# STEP 1: LOAD ABNORMAL TIME WINDOWS FROM CSV\n",
    "#############################################\n",
    "\n",
    "def load_abnormal_times(csv_filename):\n",
    "    \"\"\"\n",
    "    Loads the CSV file and parses the abnormal time window fields for each patient and time.\n",
    "    Returns a dictionary with structure:\n",
    "       abnormal[patient_id][time_id] = {\n",
    "           \"parasternal\": [ (start, end), ... ] or \"filtered_out\",\n",
    "           \"diaphragm\":   [ (start, end), ... ] or \"filtered_out\",\n",
    "           \"ventilator\":  [ (start, end), ... ] or \"filtered_out\"\n",
    "       }\n",
    "    The CSV file contains columns such as:\n",
    "      \"Abnormal Parasternal\", \"Abnormal Diaphragm\", \"Abnormal Ventilator\"\n",
    "    Each value is of the form:\n",
    "      \"Abnormal Parasternal: [(0.0, 15.0), (30.0, 35.0), ...]\"\n",
    "    \"\"\"\n",
    "    abnormal = {}\n",
    "    with open(csv_filename, newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            pid = row[\"Patient ID\"]\n",
    "            tp = row[\"Time ID\"]\n",
    "            if pid not in abnormal:\n",
    "                abnormal[pid] = {}\n",
    "            abnormal[pid][tp] = {}\n",
    "            \n",
    "            # Parse the abnormal windows for each channel\n",
    "            # For Parasternal:\n",
    "            ap_str = row[\"Abnormal Parasternal\"].strip()\n",
    "            if ap_str.startswith(\"Abnormal Parasternal:\"):\n",
    "                ap_str = ap_str.split(\":\", 1)[1].strip()\n",
    "            if ap_str.lower() == \"filtered_out\":\n",
    "                abnormal[pid][tp][\"parasternal\"] = \"filtered_out\"\n",
    "            else:\n",
    "                try:\n",
    "                    abnormal[pid][tp][\"parasternal\"] = ast.literal_eval(ap_str)\n",
    "                except Exception as e:\n",
    "                    abnormal[pid][tp][\"parasternal\"] = []\n",
    "                    \n",
    "            # For Diaphragm:\n",
    "            ad_str = row[\"Abnormal Diaphragm\"].strip()\n",
    "            if ad_str.startswith(\"Abnormal Diaphragm:\"):\n",
    "                ad_str = ad_str.split(\":\", 1)[1].strip()\n",
    "            if ad_str.lower() == \"filtered_out\":\n",
    "                abnormal[pid][tp][\"diaphragm\"] = \"filtered_out\"\n",
    "            else:\n",
    "                try:\n",
    "                    abnormal[pid][tp][\"diaphragm\"] = ast.literal_eval(ad_str)\n",
    "                except Exception as e:\n",
    "                    abnormal[pid][tp][\"diaphragm\"] = []\n",
    "            \n",
    "            # For Ventilator:\n",
    "            av_str = row[\"Abnormal Ventilator\"].strip()\n",
    "            if av_str.startswith(\"Abnormal Ventilator:\"):\n",
    "                av_str = av_str.split(\":\", 1)[1].strip()\n",
    "            if av_str.lower() == \"filtered_out\":\n",
    "                abnormal[pid][tp][\"ventilator\"] = \"filtered_out\"\n",
    "            else:\n",
    "                try:\n",
    "                    abnormal[pid][tp][\"ventilator\"] = ast.literal_eval(av_str)\n",
    "                except Exception as e:\n",
    "                    abnormal[pid][tp][\"ventilator\"] = []\n",
    "    return abnormal\n",
    "\n",
    "# Load the CSV file (make sure the file name/path is correct)\n",
    "abnormal_times_dict = load_abnormal_times(\"baseline_drift_analysis.csv\")\n",
    "\n",
    "\n",
    "#############################################\n",
    "# STEP 2: DEFINE A HELPER FOR PLOTTING ABNORMAL WINDOWS\n",
    "#############################################\n",
    "\n",
    "def plot_abnormal_windows(ax, abnormal_windows, t_start, t_end):\n",
    "    \"\"\"\n",
    "    Overlays a translucent red region on the axis 'ax' from t_start to t_end for\n",
    "    every abnormal time window that overlaps with the current display.\n",
    "    \n",
    "    If abnormal_windows is \"filtered_out\", shade the whole (t_start, t_end) region.\n",
    "    \"\"\"\n",
    "    if abnormal_windows == \"filtered_out\":\n",
    "        ax.axvspan(t_start, t_end, color='red', alpha=0.3)\n",
    "    elif abnormal_windows and isinstance(abnormal_windows, list):\n",
    "        for (win_start, win_end) in abnormal_windows:\n",
    "            # Only mark the overlapping portion of any abnormal window \n",
    "            if win_end > t_start and win_start < t_end:\n",
    "                ax.axvspan(max(t_start, win_start), min(t_end, win_end), color='red', alpha=0.3)\n",
    "\n",
    "\n",
    "#############################################\n",
    "# STEP 3: MODIFY THE INTERACTIVE PLOTTING FUNCTION\n",
    "#############################################\n",
    "\n",
    "def scrollable_emg_plot(pid, tp, window_size=10, y_lims_emg=None, y_lims_vent=None):\n",
    "    \"\"\"\n",
    "    Displays an interactive plot of the EMG (parasternal, diaphragm) envelope \n",
    "    and baseline plus the ventilator signal for a given patient and time.\n",
    "    Overlays red shading for low‐quality segments as defined from the CSV.\n",
    "    \n",
    "    The CSV abnormal times are loaded into abnormal_times_dict, where each \n",
    "    channel is assigned to one of: \"parasternal\", \"diaphragm\", or \"ventilator\".\n",
    "    \"\"\"\n",
    "    if pid not in patient_data or tp not in patient_data[pid]:\n",
    "        print(f\"❌ Invalid patient ID or Time ID ({pid}, {tp})\")\n",
    "        return\n",
    "    \n",
    "    emg_ts = patient_data[pid][tp]['emg']\n",
    "    vent_ts = patient_data[pid][tp]['vent']\n",
    "    \n",
    "    # Retrieve abnormal windows for this patient and time (if available).  \n",
    "    # This dictionary should now have keys \"parasternal\", \"diaphragm\", \"ventilator\".\n",
    "    abnormal = abnormal_times_dict.get(pid, {}).get(tp, {})\n",
    "\n",
    "    # Determine the global time axis from the first EMG channel:\n",
    "    t_data = emg_ts[0].t_data\n",
    "    t_min = t_data[0]\n",
    "    t_max = t_data[-1]\n",
    "    t_slider_max = t_max - window_size\n",
    "\n",
    "    @interact(t_start=FloatSlider(min=t_min, max=t_slider_max, step=1, value=t_min, description='Start (s)'))\n",
    "    def update_plot(t_start):\n",
    "        t_end = t_start + window_size\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(14, 8), sharex=True)\n",
    "        axes_emg = axes[:2]\n",
    "        ax_vent = axes[2]\n",
    "\n",
    "        colors_clean = ['lightgray', 'lightgray']\n",
    "        colors_env = ['tab:blue', 'tab:green']\n",
    "\n",
    "        # Plot the cleaned (filtered) EMG signals.\n",
    "        emg_ts.run('plot_full', axes=axes_emg, signal_type='clean', colors=colors_clean, baseline_bool=False)\n",
    "\n",
    "        # Add envelope and baseline for each EMG channel.\n",
    "        for ch_idx, ax in enumerate(axes_emg):\n",
    "            ax.plot(emg_ts[ch_idx].t_data, emg_ts[ch_idx].y_env, color=colors_env[ch_idx],\n",
    "                    linewidth=2.0, label='envelope')\n",
    "            ax.plot(emg_ts[ch_idx].t_data, emg_ts[ch_idx].y_baseline, color=colors_env[ch_idx],\n",
    "                    linestyle='--', linewidth=1.5, label='baseline')\n",
    "            ax.legend(loc='upper right')\n",
    "        axes_emg[0].set_title(f'EMG - patient {pid}, {tp}')\n",
    "        axes_emg[-1].set_xlabel('Time (s)')\n",
    "\n",
    "        # Plot the ventilator signal.\n",
    "        vent_ts.run('plot_full', axes=[ax_vent])\n",
    "        ax_vent.set_title(f'Ventilator - patient {pid}, {tp}')\n",
    "        ax_vent.set_xlabel('Time (s)')\n",
    "\n",
    "        # Set x-axis limits for all subplots.\n",
    "        for ax in axes:\n",
    "            ax.set_xlim([t_start, t_end])\n",
    "        if y_lims_emg is not None:\n",
    "            for ax in axes_emg:\n",
    "                ax.set_ylim(y_lims_emg)\n",
    "        if y_lims_vent is not None:\n",
    "            ax_vent.set_ylim(y_lims_vent)\n",
    "\n",
    "        # Get abnormal time windows per channel\n",
    "        ab_paras = abnormal.get(\"parasternal\", [])\n",
    "        ab_diaphragm = abnormal.get(\"diaphragm\", [])\n",
    "        ab_vent = abnormal.get(\"ventilator\", [])\n",
    "\n",
    "        # Overlay red shading for each channel.\n",
    "        plot_abnormal_windows(axes_emg[0], ab_paras, t_start, t_end)\n",
    "        plot_abnormal_windows(axes_emg[1], ab_diaphragm, t_start, t_end)\n",
    "        plot_abnormal_windows(ax_vent, ab_vent, t_start, t_end)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "#############################################\n",
    "# STEP 4: USE THE INTERACTIVE PLOT\n",
    "#############################################\n",
    "\n",
    "# (Ensure that patient_data is defined and loaded as in your original scripts.)\n",
    "scrollable_emg_plot(\n",
    "    pid='005',       # example patient id\n",
    "    tp='t0',         # example time id\n",
    "    window_size=40,  # time window in seconds\n",
    "    y_lims_emg=[-5, 30],\n",
    "    y_lims_vent=[-5, 25]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKGROUND NOISE DETECTION\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def calculate_drift(signal, window_size):\n",
    "    \"\"\"\n",
    "    Divide the signal into non-overlapping windows and calculate the drift (max - min)\n",
    "    for each window.\n",
    "    \"\"\"\n",
    "    drift = []\n",
    "    for i in range(0, len(signal) - window_size + 1, window_size):\n",
    "        window = signal[i : i + window_size]\n",
    "        drift.append(max(window) - min(window))\n",
    "    return drift\n",
    "\n",
    "def print_formatted_results(pid, tp, emg_stats, vent_stats, measurement_status):\n",
    "    \"\"\"\n",
    "    Print summary statistics for each channel and the overall measurement status.\n",
    "    \"\"\"\n",
    "    print(f\"\\nResults for Patient {pid}, Time {tp}:\")\n",
    "    print(f\"  Parasternal (Envelope): Mean Drift: {emg_stats[0][0]:.2f}, Median Drift: {emg_stats[0][1]:.2f}, Max Drift: {emg_stats[0][2]:.2f}\")\n",
    "    print(f\"  Diaphragm (Envelope):  Mean Drift: {emg_stats[1][0]:.2f}, Median Drift: {emg_stats[1][1]:.2f}, Max Drift: {emg_stats[1][2]:.2f}\")\n",
    "    print(f\"  Ventilator (Raw):      Mean Drift: {vent_stats[0]:.2f}, Median Drift: {vent_stats[1]:.2f}, Max Drift: {vent_stats[2]:.2f}\")\n",
    "    print(f\"  Measurement Status: {measurement_status}\")\n",
    "\n",
    "#############################################\n",
    "# MAIN SCRIPT: DETECTING BACKGROUND NOISE AND SPECIFIC CONDITIONS\n",
    "#############################################\n",
    "\n",
    "# Adjustable parameter: window duration in seconds (change this to adjust window size easily)\n",
    "window_sec = 10  \n",
    "\n",
    "# Set thresholds\n",
    "threshold_emg = 4.0    # for EMG channels in uV\n",
    "threshold_vent = 4.0   # for the ventilator channel in cmH20\n",
    "\n",
    "# Settings for EMG processing.\n",
    "fs_emg = 2048  \n",
    "window_size_emg = int(window_sec * fs_emg)  # window size for EMG envelope data in samples\n",
    "\n",
    "# Prepare CSV output.\n",
    "csv_rows = []\n",
    "headers = [\n",
    "    \"Patient ID\", \"Time ID\",\n",
    "    \"Parasternal (Mean, Median, Max)\",\n",
    "    \"Diaphragm (Mean, Median, Max)\",\n",
    "    \"Ventilator (Mean, Median, Max)\",\n",
    "    \"Measurement Status\"\n",
    "]\n",
    "\n",
    "# Loop across patient measurements.\n",
    "for pid, patient in patient_data.items():\n",
    "    for tp, data in patient.items():\n",
    "        emg_ts = data['emg']\n",
    "        vent_ts = data['vent']  # ventilator data group\n",
    "\n",
    "        # Process EMG channels using envelope data (y_env).\n",
    "        emg_stats = []\n",
    "        for channel_idx in range(len(emg_ts.channels)):\n",
    "            envelope = emg_ts.channels[channel_idx].y_env\n",
    "            drift = calculate_drift(envelope, window_size_emg)\n",
    "            mean_drift = np.mean(drift)\n",
    "            median_drift = np.median(drift)\n",
    "            max_drift = np.max(drift)\n",
    "            emg_stats.append((mean_drift, median_drift, max_drift))\n",
    "        \n",
    "        # Process the Ventilator channel using its raw data.\n",
    "        vent_channel = vent_ts.channels[0]        # assuming a single ventilator channel\n",
    "        fs_vent = vent_ts.param['fs']              # obtain ventilator sampling frequency (e.g. 100)\n",
    "        window_size_vent = int(window_sec * fs_vent) # window size in samples for ventilator\n",
    "        raw_data = vent_channel.y_raw              # raw ventilator data using y_raw\n",
    "        drift_vent = calculate_drift(raw_data, window_size_vent)\n",
    "        vent_mean = np.mean(drift_vent)\n",
    "        vent_median = np.median(drift_vent)\n",
    "        vent_max = np.max(drift_vent)\n",
    "        vent_stats = (vent_mean, vent_median, vent_max)\n",
    "        \n",
    "        # Determine measurement status based on channel-specific thresholds.\n",
    "        status_list = []\n",
    "        if vent_median <= threshold_vent:\n",
    "            status_list.append(\"ventilator malfunction\")\n",
    "        if emg_stats[1][1] <= threshold_emg:  # channel index 1: diaphragm\n",
    "            status_list.append(\"no respiratory activity diaphragm\")\n",
    "        if emg_stats[0][1] <= threshold_emg:  # channel index 0: parasternal\n",
    "            status_list.append(\"no respiratory activity parasternal\")\n",
    "        if not status_list:\n",
    "            status_list.append(\"respiratory activity\")\n",
    "        measurement_status = \", \".join(status_list)\n",
    "\n",
    "        # Print the results.\n",
    "        print_formatted_results(pid, tp, emg_stats, vent_stats, measurement_status)\n",
    "        \n",
    "        # Prepare CSV row.\n",
    "        row = [\n",
    "            pid,\n",
    "            tp,\n",
    "            f\"Mean: {emg_stats[0][0]:.2f}, Median: {emg_stats[0][1]:.2f}, Max: {emg_stats[0][2]:.2f}\",\n",
    "            f\"Mean: {emg_stats[1][0]:.2f}, Median: {emg_stats[1][1]:.2f}, Max: {emg_stats[1][2]:.2f}\",\n",
    "            f\"Mean: {vent_stats[0]:.2f}, Median: {vent_stats[1]:.2f}, Max: {vent_stats[2]:.2f}\",\n",
    "            measurement_status\n",
    "        ]\n",
    "        csv_rows.append(row)\n",
    "\n",
    "# Save results to a CSV file.\n",
    "with open('background_noise_detection.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(headers)\n",
    "    csv_writer.writerows(csv_rows)\n",
    "\n",
    "print(\"\\nCSV output saved to background_noise_detection.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSIGNING LABEL TO MEASUREMENTS, INCLUDE, EXCLUDE OR SUBANALYSIS\n",
    "import csv\n",
    "import ast\n",
    "\n",
    "# File paths\n",
    "background_csv = 'background_noise_detection.csv'\n",
    "baseline_csv = 'baseline_drift_analysis.csv'\n",
    "output_csv = 'measurement_classification.csv'\n",
    "\n",
    "# Load background noise detection\n",
    "bg_data = {}\n",
    "with open(background_csv, newline='') as bg_file:\n",
    "    reader = csv.DictReader(bg_file)\n",
    "    for row in reader:\n",
    "        key = (row[\"Patient ID\"].strip(), row[\"Time ID\"].strip())\n",
    "        bg_data[key] = row\n",
    "\n",
    "# Load baseline drift analysis\n",
    "bd_data = {}\n",
    "with open(baseline_csv, newline='') as bd_file:\n",
    "    reader = csv.DictReader(bd_file)\n",
    "    for row in reader:\n",
    "        key = (row[\"Patient ID\"].strip(), row[\"Time ID\"].strip())\n",
    "        bd_data[key] = row\n",
    "\n",
    "# Combined set of keys\n",
    "all_keys = set(bg_data.keys()).union(set(bd_data.keys()))\n",
    "\n",
    "results = []\n",
    "\n",
    "for key in sorted(all_keys):\n",
    "    pid, tid = key\n",
    "    reasons = []\n",
    "    label = \"Include\"  # default\n",
    "    status = bg_data.get(key, {}).get(\"Measurement Status\", \"missing\").strip().lower()\n",
    "    raw_filtered = bd_data.get(key, {}).get(\"Filtered Channels\", \"\").strip()\n",
    "\n",
    "    # Get readable status from the background noise CSV\n",
    "    status_str = bg_data.get(key, {}).get(\"Measurement Status\", \"\").strip()\n",
    "\n",
    "    # Determine filtered channels list\n",
    "    if raw_filtered.startswith(\"Filtered Channels:\"):\n",
    "        filtered_str = raw_filtered[len(\"Filtered Channels:\"):].strip()\n",
    "    else:\n",
    "        filtered_str = raw_filtered\n",
    "\n",
    "    try:\n",
    "        filtered_list = ast.literal_eval(filtered_str) if filtered_str else []\n",
    "    except:\n",
    "        filtered_list = filtered_str\n",
    "\n",
    "    # Normalize to a list if not already\n",
    "    if not isinstance(filtered_list, list):\n",
    "        filtered_list = [filtered_list] if filtered_list else []\n",
    "\n",
    "    # Check for ventilator malfunction\n",
    "    if \"ventilator malfunction\" in status:\n",
    "        label = \"Exclude\"\n",
    "        reasons.append(status_str)\n",
    "\n",
    "    # Check for background noise: if status is not \"respiratory activity\", add it as a reason.\n",
    "    elif status != \"respiratory activity\":\n",
    "        reasons.append(status_str)\n",
    "\n",
    "    # Check for motion artefacts\n",
    "    if filtered_list:\n",
    "        fa_reasons = [f\"motion artefacts {ch.capitalize()}\" for ch in filtered_list]\n",
    "        reasons.extend(fa_reasons)\n",
    "\n",
    "    # Exclude if both channels have no respiratory activity.\n",
    "    # Use substring matching on each reason (splitting combined strings)\n",
    "    if (any(\"no respiratory activity diaphragm\" in r.lower() for r in reasons) and \n",
    "        any(\"no respiratory activity parasternal\" in r.lower() for r in reasons)):\n",
    "        label = \"Exclude\"\n",
    "        # Reset reasons to the two canonical reasons.\n",
    "        reasons = [\"no respiratory activity diaphragm\", \"no respiratory activity parasternal\"]\n",
    "\n",
    "    # Determine final label (only assess \"Subanalysis\" when not already Excluded)\n",
    "    elif not reasons:\n",
    "        label = \"Include\"\n",
    "    elif label != \"Exclude\":\n",
    "        motion_only = all(\"motion artefacts\" in r.lower() for r in reasons)\n",
    "        noise_only = all(\"no respiratory activity\" in r.lower() for r in reasons)\n",
    "        if len(reasons) == 1 and (motion_only or noise_only):\n",
    "            label = \"Subanalysis\"\n",
    "        else:\n",
    "            label = \"Exclude\"\n",
    "\n",
    "    results.append({\n",
    "        \"Patient ID\": pid,\n",
    "        \"Time ID\": tid,\n",
    "        \"Status\": status_str,\n",
    "        \"Filtered Channels\": filtered_list,\n",
    "        \"Label\": label,\n",
    "        \"Reason\": \"; \".join(reasons) if reasons else \"\"\n",
    "    })\n",
    "\n",
    "# Write output CSV\n",
    "with open(output_csv, mode='w', newline='') as out_file:\n",
    "    fieldnames = [\"Patient ID\", \"Time ID\", \"Status\", \"Filtered Channels\", \"Label\", \"Reason\"]\n",
    "    writer = csv.DictWriter(out_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"\\nCSV summary saved as {output_csv}\")\n",
    "\n",
    "# Print summary of measurement classification.\n",
    "total = len(results)\n",
    "included = sum(1 for r in results if r[\"Label\"] == \"Include\")\n",
    "excluded = sum(1 for r in results if r[\"Label\"] == \"Exclude\")\n",
    "subanalysis = sum(1 for r in results if r[\"Label\"] == \"Subanalysis\")\n",
    "\n",
    "print(f\"\\nSummary for {total} measurements:\")\n",
    "print(f\"  Included     : {included} ({included / total:.2%})\")\n",
    "print(f\"  Subanalysis  : {subanalysis} ({subanalysis / total:.2%})\")\n",
    "print(f\"  Excluded     : {excluded} ({excluded / total:.2%})\")\n",
    "\n",
    "# Print detailed results\n",
    "def print_sorted_results(label_name, label_value, show_reason=False):\n",
    "    print(f\"\\n{label_name} measurements:\")\n",
    "    filtered = sorted([r for r in results if r[\"Label\"] == label_value], key=lambda x: (x[\"Patient ID\"], x[\"Time ID\"]))\n",
    "    for r in filtered:\n",
    "        base_str = f\"  {r['Patient ID']} - {r['Time ID']}\"\n",
    "        if show_reason:\n",
    "            print(f\"{base_str}: {r['Reason']}\")\n",
    "        else:\n",
    "            print(base_str)\n",
    "\n",
    "print_sorted_results(\"Included\", \"Include\")\n",
    "print_sorted_results(\"Subanalysis\", \"Subanalysis\", show_reason=True)\n",
    "print_sorted_results(\"Excluded\", \"Exclude\", show_reason=True)\n",
    "\n",
    "# --- Additional printed summary for excluded measurements breakdown ---\n",
    "# We define the following mutually exclusive categories for exclusions:\n",
    "# 1. \"ventilator malfunction\": if the measurement reasons contain \"ventilator malfunction\" (regardless of other reasons).\n",
    "# 2. \"no respiratory activity in EMG channels\": if the reasons contain both \"no respiratory activity diaphragm\" AND \"no respiratory activity parasternal\".\n",
    "# 3. \"Motion artefacte diaphragm, Background noise parasternal\": if the reasons contain both \"no respiratory activity parasternal\" and \"motion artefacts diaphragm\".\n",
    "# 4. \"Motion artefacte parasternal, Background noise diaphragm\": if the reasons contain both \"no respiratory activity diaphragm\" and \"motion artefacts parasternal\".\n",
    "category_counts = {\n",
    "    \"ventilator malfunction\": 0,\n",
    "    \"no respiratory activity in EMG channels\": 0,\n",
    "    \"Motion artefacts diaphragm, Background noise parasternal\": 0,\n",
    "    \"Motion artefacts parasternal, Background noise diaphragm\": 0\n",
    "}\n",
    "\n",
    "# Loop over excluded measurements and assign a category.\n",
    "for r in results:\n",
    "    if r[\"Label\"] != \"Exclude\":\n",
    "        continue\n",
    "    # Split the reasons string by \";\" to get an array and strip each part.\n",
    "    r_list = [x.strip().lower() for x in r[\"Reason\"].split(\";\") if x.strip()]\n",
    "    \n",
    "    # Check for \"ventilator malfunction\" first.\n",
    "    if any(\"ventilator malfunction\" in s for s in r_list):\n",
    "        category = \"ventilator malfunction\"\n",
    "    elif (any(\"no respiratory activity diaphragm\" in s for s in r_list) and \n",
    "          any(\"no respiratory activity parasternal\" in s for s in r_list)):\n",
    "        category = \"no respiratory activity in EMG channels\"\n",
    "    elif (any(\"no respiratory activity parasternal\" in s for s in r_list) and \n",
    "          any(\"motion artefacts diaphragm\" in s for s in r_list)):\n",
    "        category = \"Motion artefacts diaphragm, Background noise parasternal\"\n",
    "    elif (any(\"no respiratory activity diaphragm\" in s for s in r_list) and \n",
    "          any(\"motion artefacts parasternal\" in s for s in r_list)):\n",
    "        category = \"Motion artefacts parasternal, Background noise diaphragm\"\n",
    "    else:\n",
    "        # In theory, all exclusions should fall into one category.\n",
    "        category = \"UNCLASSIFIED\"\n",
    "        print(f\"Unclassified measurement: {r['Patient ID']} - {r['Time ID']} with reasons: {r_list}\")\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "print(\"\\n=== Excluded Measurements Breakdown by Category ===\")\n",
    "for cat, count in category_counts.items():\n",
    "    percentage = (count / total) * 100 if total > 0 else 0\n",
    "    print(f\"{cat}: {count} measurements ({percentage:.2f}% of total measurements)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSIGNING LABEL TO MEASUREMENTS, INCLUDE, EXCLUDE OR SUBANALYSIS\n",
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "background_csv = 'background_noise_detection.csv'\n",
    "baseline_csv = 'baseline_drift_analysis.csv'\n",
    "output_csv = 'measurement_classification.csv'\n",
    "\n",
    "# Load background noise detection\n",
    "bg_data = {}\n",
    "with open(background_csv, newline='') as bg_file:\n",
    "    reader = csv.DictReader(bg_file)\n",
    "    for row in reader:\n",
    "        key = (row[\"Patient ID\"].strip(), row[\"Time ID\"].strip())\n",
    "        bg_data[key] = row\n",
    "\n",
    "# Load baseline drift analysis\n",
    "bd_data = {}\n",
    "with open(baseline_csv, newline='') as bd_file:\n",
    "    reader = csv.DictReader(bd_file)\n",
    "    for row in reader:\n",
    "        key = (row[\"Patient ID\"].strip(), row[\"Time ID\"].strip())\n",
    "        bd_data[key] = row\n",
    "\n",
    "# Combined set of keys from both CSVs.\n",
    "all_keys = set(bg_data.keys()).union(set(bd_data.keys()))\n",
    "\n",
    "results = []\n",
    "\n",
    "for key in sorted(all_keys):\n",
    "    pid, tid = key\n",
    "    reasons = []\n",
    "    label = \"Include\"  # default\n",
    "    status = bg_data.get(key, {}).get(\"Measurement Status\", \"missing\").strip().lower()\n",
    "    raw_filtered = bd_data.get(key, {}).get(\"Filtered Channels\", \"\").strip()\n",
    "\n",
    "    # Get readable status from the background noise CSV\n",
    "    status_str = bg_data.get(key, {}).get(\"Measurement Status\", \"\").strip()\n",
    "\n",
    "    # Determine filtered channels list; remove prefixed text if present.\n",
    "    if raw_filtered.startswith(\"Filtered Channels:\"):\n",
    "        filtered_str = raw_filtered[len(\"Filtered Channels:\"):].strip()\n",
    "    else:\n",
    "        filtered_str = raw_filtered\n",
    "\n",
    "    try:\n",
    "        filtered_list = ast.literal_eval(filtered_str) if filtered_str else []\n",
    "    except:\n",
    "        filtered_list = filtered_str\n",
    "\n",
    "    # Normalize to list if needed\n",
    "    if not isinstance(filtered_list, list):\n",
    "        filtered_list = [filtered_list] if filtered_list else []\n",
    "\n",
    "    # Check for ventilator malfunction\n",
    "    if \"ventilator malfunction\" in status:\n",
    "        label = \"Exclude\"\n",
    "        reasons.append(status_str)\n",
    "\n",
    "    # Check for background noise: if status is not \"respiratory activity\", add it as a reason.\n",
    "    elif status != \"respiratory activity\":\n",
    "        reasons.append(status_str)\n",
    "\n",
    "    # Check for motion artefacts.\n",
    "    if filtered_list:\n",
    "        fa_reasons = [f\"motion artefacts {ch.capitalize()}\" for ch in filtered_list]\n",
    "        reasons.extend(fa_reasons)\n",
    "\n",
    "    # Exclude if both channels have no respiratory activity.\n",
    "    if (any(\"no respiratory activity diaphragm\" in r.lower() for r in reasons) and \n",
    "        any(\"no respiratory activity parasternal\" in r.lower() for r in reasons)):\n",
    "        label = \"Exclude\"\n",
    "        # Reset reasons to the two canonical messages.\n",
    "        reasons = [\"no respiratory activity diaphragm\", \"no respiratory activity parasternal\"]\n",
    "\n",
    "    # Determine final label (only assess \"Subanalysis\" when not already Excluded)\n",
    "    elif not reasons:\n",
    "        label = \"Include\"\n",
    "    elif label != \"Exclude\":\n",
    "        motion_only = all(\"motion artefacts\" in r.lower() for r in reasons)\n",
    "        noise_only = all(\"no respiratory activity\" in r.lower() for r in reasons)\n",
    "        if len(reasons) == 1 and (motion_only or noise_only):\n",
    "            label = \"Subanalysis\"\n",
    "        else:\n",
    "            label = \"Exclude\"\n",
    "\n",
    "    results.append({\n",
    "        \"Patient ID\": pid,\n",
    "        \"Time ID\": tid,\n",
    "        \"Status\": status_str,\n",
    "        \"Filtered Channels\": filtered_list,\n",
    "        \"Label\": label,\n",
    "        \"Reason\": \"; \".join(reasons) if reasons else \"\"\n",
    "    })\n",
    "\n",
    "# Write output CSV\n",
    "with open(output_csv, mode='w', newline='') as out_file:\n",
    "    fieldnames = [\"Patient ID\", \"Time ID\", \"Status\", \"Filtered Channels\", \"Label\", \"Reason\"]\n",
    "    writer = csv.DictWriter(out_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"\\nCSV summary saved as {output_csv}\")\n",
    "\n",
    "# Print summary of measurement classification.\n",
    "total = len(results)\n",
    "included = sum(1 for r in results if r[\"Label\"] == \"Include\")\n",
    "excluded = sum(1 for r in results if r[\"Label\"] == \"Exclude\")\n",
    "subanalysis = sum(1 for r in results if r[\"Label\"] == \"Subanalysis\")\n",
    "\n",
    "print(f\"\\nSummary for {total} measurements:\")\n",
    "print(f\"  Included     : {included} ({included / total:.2%})\")\n",
    "print(f\"  Subanalysis  : {subanalysis} ({subanalysis / total:.2%})\")\n",
    "print(f\"  Excluded     : {excluded} ({excluded / total:.2%})\")\n",
    "\n",
    "# Print detailed sorted results.\n",
    "def print_sorted_results(label_name, label_value, show_reason=False):\n",
    "    print(f\"\\n{label_name} measurements:\")\n",
    "    filtered = sorted([r for r in results if r[\"Label\"] == label_value], key=lambda x: (x[\"Patient ID\"], x[\"Time ID\"]))\n",
    "    for r in filtered:\n",
    "        base_str = f\"  {r['Patient ID']} - {r['Time ID']}\"\n",
    "        if show_reason:\n",
    "            print(f\"{base_str}: {r['Reason']}\")\n",
    "        else:\n",
    "            print(base_str)\n",
    "\n",
    "print_sorted_results(\"Included\", \"Include\")\n",
    "print_sorted_results(\"Subanalysis\", \"Subanalysis\", show_reason=True)\n",
    "print_sorted_results(\"Excluded\", \"Exclude\", show_reason=True)\n",
    "\n",
    "# --- Additional printed summary for excluded measurements breakdown ---\n",
    "# Categories defined for exclusions\n",
    "excluded_category_counts = {\n",
    "    \"ventilator malfunction\": 0,\n",
    "    \"no respiratory activity in EMG channels\": 0,\n",
    "    \"Motion artefacts diaphragm, Background noise parasternal\": 0,\n",
    "    \"Motion artefacts parasternal, Background noise diaphragm\": 0\n",
    "}\n",
    "\n",
    "for r in results:\n",
    "    if r[\"Label\"] != \"Exclude\":\n",
    "        continue\n",
    "    r_list = [x.strip().lower() for x in r[\"Reason\"].split(\";\") if x.strip()]\n",
    "    if any(\"ventilator malfunction\" in s for s in r_list):\n",
    "        category = \"ventilator malfunction\"\n",
    "    elif (any(\"no respiratory activity diaphragm\" in s for s in r_list) and \n",
    "          any(\"no respiratory activity parasternal\" in s for s in r_list)):\n",
    "        category = \"no respiratory activity in EMG channels\"\n",
    "    elif (any(\"no respiratory activity parasternal\" in s for s in r_list) and \n",
    "          any(\"motion artefacts diaphragm\" in s for s in r_list)):\n",
    "        category = \"Motion artefacts diaphragm, Background noise parasastern(al)\"  # slight variation; you may fix text\n",
    "        category = \"Motion artefacts diaphragm, Background noise parasternal\"\n",
    "    elif (any(\"no respiratory activity diaphragm\" in s for s in r_list) and \n",
    "          any(\"motion artefacts parasternal\" in s for s in r_list)):\n",
    "        category = \"Motion artefacts parasternal, Background noise diaphragm\"\n",
    "    else:\n",
    "        category = \"UNCLASSIFIED\"\n",
    "        print(f\"Unclassified measurement: {r['Patient ID']} - {r['Time ID']} with reasons: {r_list}\")\n",
    "    if category in excluded_category_counts:\n",
    "        excluded_category_counts[category] += 1\n",
    "    else:\n",
    "        excluded_category_counts[category] = 1\n",
    "\n",
    "print(\"\\n=== Excluded Measurements Breakdown by Category ===\")\n",
    "for cat, count in excluded_category_counts.items():\n",
    "    percentage = (count / total) * 100 if total > 0 else 0\n",
    "    print(f\"{cat}: {count} measurements ({percentage:.2f}% of total measurements)\")\n",
    "\n",
    "# --- New: Additional printed summary for subanalysis measurements breakdown ---\n",
    "subanalysis_records = [r for r in results if r[\"Label\"] == \"Subanalysis\"]\n",
    "\n",
    "# Initialize counters for subanalysis categories\n",
    "subanalysis_counts = {\n",
    "    \"Background noise parasternal\": 0,\n",
    "    \"Background noise diaphragm\": 0,\n",
    "    \"Motion artefacts parasternal\": 0,\n",
    "    \"Motion artefacts diaphragm\": 0\n",
    "}\n",
    "\n",
    "for r in subanalysis_records:\n",
    "    # Assume the subanalysis measurements should have one reason\n",
    "    r_list = [x.strip().lower() for x in r[\"Reason\"].split(\";\") if x.strip()]\n",
    "    # Check for keywords in the reason string.\n",
    "    if any(\"no respiratory activity parasternal\" in s for s in r_list):\n",
    "        subanalysis_counts[\"Background noise parasternal\"] += 1\n",
    "    if any(\"no respiratory activity diaphragm\" in s for s in r_list):\n",
    "        subanalysis_counts[\"Background noise diaphragm\"] += 1\n",
    "    if any(\"motion artefacts parasternal\" in s for s in r_list):\n",
    "        subanalysis_counts[\"Motion artefacts parasternal\"] += 1\n",
    "    if any(\"motion artefacts diaphragm\" in s for s in r_list):\n",
    "        subanalysis_counts[\"Motion artefacts diaphragm\"] += 1\n",
    "\n",
    "total_subanalysis = len(subanalysis_records)\n",
    "\n",
    "print(\"\\n=== Subanalysis Measurements Breakdown by Category ===\")\n",
    "for cat, count in subanalysis_counts.items():\n",
    "    perc = (count / total_subanalysis * 100) if total_subanalysis > 0 else 0\n",
    "    print(f\"{cat}: {count} measurements ({perc:.2f}% of total measurements)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORISATION SUMMARY \n",
    "import pandas as pd\n",
    "\n",
    "###########################################\n",
    "# PART 1: Extract durations from patient_data\n",
    "###########################################\n",
    "\n",
    "# Dictionary to store duration (in minutes) per measurement,\n",
    "# keyed by (Patient ID, Time ID)\n",
    "durations = {}\n",
    "\n",
    "print(\"Extracting measurement durations:\")\n",
    "\n",
    "for pid, patient in patient_data.items():\n",
    "    for tp, data in patient.items():\n",
    "        try:\n",
    "            # Retrieve the EMG channels (as in your visual inspection code)\n",
    "            emg_ts = data['emg']\n",
    "            # Use the time axis of the first EMG channel.\n",
    "            t_data = emg_ts[0].t_data  # assume t_data is a list or array of time stamps (in seconds)\n",
    "            if len(t_data) >= 2:\n",
    "                t_min = float(t_data[0])\n",
    "                t_max = float(t_data[-1])\n",
    "                duration_seconds = t_max - t_min\n",
    "                duration_minutes = duration_seconds / 60.0\n",
    "            else:\n",
    "                print(f\"Patient {pid}, Time {tp}: Not enough time data samples.\")\n",
    "                duration_minutes = 0\n",
    "            # Normalize keys: ensure patient ID is a string padded to 3 digits,\n",
    "            # and time ID is stripped.\n",
    "            key = (str(pid).strip().zfill(3), str(tp).strip())\n",
    "            durations[key] = duration_minutes\n",
    "            print(f\"Patient {pid}, Time {tp}: Duration = {duration_seconds:.2f} seconds ({duration_minutes:.2f} minutes)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving duration for Patient {pid}, Time {tp}: {e}\")\n",
    "            key = (str(pid).strip().zfill(3), str(tp).strip())\n",
    "            durations[key] = 0\n",
    "\n",
    "###########################################\n",
    "# PART 2: Read CSV and combine durations for summary\n",
    "###########################################\n",
    "\n",
    "# Read the measurement classification CSV file.\n",
    "df = pd.read_csv(\"measurement_classification.csv\")\n",
    "\n",
    "# Normalize CSV keys so they match those used above:\n",
    "# Convert Patient ID to string, strip whitespace, and zero-pad to length 3.\n",
    "df['Patient ID'] = df['Patient ID'].astype(str).str.strip().apply(lambda x: x.zfill(3))\n",
    "df['Time ID'] = df['Time ID'].astype(str).str.strip()\n",
    "\n",
    "# Add a new column \"Duration (min)\" to the DataFrame using the durations dictionary.\n",
    "def lookup_duration(row):\n",
    "    key = (row['Patient ID'], row['Time ID'])\n",
    "    return durations.get(key, 0)\n",
    "\n",
    "df['Duration (min)'] = df.apply(lookup_duration, axis=1)\n",
    "\n",
    "# --- Compute overall totals ---\n",
    "total_measurements = len(df)\n",
    "total_patients = df[\"Patient ID\"].nunique()\n",
    "total_duration = df['Duration (min)'].sum()\n",
    "\n",
    "# --- Compute stats per label ---\n",
    "labels = [\"Include\", \"Subanalysis\", \"Exclude\"]\n",
    "summary_info = {}\n",
    "for lab in labels:\n",
    "    lab_df = df[df[\"Label\"] == lab]\n",
    "    num_meas = len(lab_df)\n",
    "    unique_patients = lab_df[\"Patient ID\"].nunique()\n",
    "    percentage = (num_meas / total_measurements) * 100 if total_measurements > 0 else 0\n",
    "    duration_minutes = lab_df['Duration (min)'].sum()\n",
    "    summary_info[lab] = (num_meas, percentage, unique_patients, duration_minutes)\n",
    "\n",
    "# --- Print the final summary ---\n",
    "print(f\"\\nSummary for {total_measurements} measurements ({total_patients} patients): measured time: {total_duration:.0f} minutes\")\n",
    "print(f\"  Included     : {summary_info['Include'][0]} ({summary_info['Include'][1]:.2f}%) across {summary_info['Include'][2]} patients: {summary_info['Include'][3]:.0f} minutes\")\n",
    "print(f\"  Subanalysis  : {summary_info['Subanalysis'][0]} ({summary_info['Subanalysis'][1]:.2f}%) across {summary_info['Subanalysis'][2]} patients: {summary_info['Subanalysis'][3]:.0f} minutes\")\n",
    "print(f\"  Exclude      : {summary_info['Exclude'][0]} ({summary_info['Exclude'][1]:.2f}%) across {summary_info['Exclude'][2]} patients: {summary_info['Exclude'][3]:.0f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUEEL INSPECTION POST FILTERING\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "import numpy as np\n",
    "\n",
    "def scrollable_emg_plot(pid, tp, window_size=10, y_lims_emg=None, y_lims_vent=None):\n",
    "    if pid not in patient_data or tp not in patient_data[pid]:\n",
    "        print(f\"❌ Invalid patient ID of time ID({pid}, {tp})\")\n",
    "        return\n",
    "\n",
    "    emg_ts = patient_data[pid][tp]['emg']\n",
    "    vent_ts = patient_data[pid][tp]['vent']\n",
    "\n",
    "    # Neem tijd-as van eerste kanaal om globale tijd te bepalen\n",
    "    t_data = emg_ts[0].t_data\n",
    "    t_min = t_data[0]\n",
    "    t_max = t_data[-1]\n",
    "    t_slider_max = t_max - window_size\n",
    "\n",
    "    # Slider setup\n",
    "    @interact(t_start=FloatSlider(min=t_min, max=t_slider_max, step=1, value=t_min, description='Start (s)'))\n",
    "    def update_plot(t_start):\n",
    "        t_end = t_start + window_size\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(14, 8), sharex=True)\n",
    "        axes_emg = axes[:2]\n",
    "        axes_vent = axes[2]\n",
    "\n",
    "        colors_clean = ['lightgray', 'lightgray']\n",
    "        colors_env = ['tab:blue', 'tab:green']\n",
    "\n",
    "        # Gefilterde EMG\n",
    "        emg_ts.run(\n",
    "            'plot_full',\n",
    "            axes=axes_emg,\n",
    "            signal_type='clean',\n",
    "            colors=colors_clean,\n",
    "            baseline_bool=False\n",
    "        )\n",
    "\n",
    "        # Envelope + baseline\n",
    "        for ch_idx, ax in enumerate(axes_emg):\n",
    "            ax.plot(emg_ts[ch_idx].t_data, emg_ts[ch_idx].y_env, color=colors_env[ch_idx], linewidth=2.0, label='envelope')\n",
    "            ax.plot(emg_ts[ch_idx].t_data, emg_ts[ch_idx].y_baseline, color=colors_env[ch_idx], linestyle='--', linewidth=1.5, label='baseline')\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "        axes_emg[0].set_title(f'EMG - patient {pid}, {tp}')\n",
    "        axes_emg[-1].set_xlabel('Time (s)')\n",
    "\n",
    "        # Ventilator\n",
    "        vent_ts.run('plot_full', axes=[axes_vent])\n",
    "        axes_vent.set_title(f'Ventilator - patient {pid}, {tp}')\n",
    "        axes_vent.set_xlabel('Time (s)')\n",
    "\n",
    "        # Zoom\n",
    "        for ax in axes:\n",
    "            ax.set_xlim([t_start, t_end])\n",
    "        if y_lims_emg is not None:\n",
    "            for ax in axes_emg:\n",
    "                ax.set_ylim(y_lims_emg)\n",
    "        if y_lims_vent is not None:\n",
    "            axes_vent.set_ylim(y_lims_vent)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Gebruik de interactieve plot\n",
    "scrollable_emg_plot(\n",
    "    pid='004',                 # patient id\n",
    "    tp='t0',                   # time id\n",
    "    window_size=20,            # time window\n",
    "    y_lims_emg=[-5, 80],\n",
    "    y_lims_vent=[-15, 20]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak detection EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EMG PEAK DETECTION\n",
    "from resurfemg.postprocessing.event_detection import detect_emg_breaths\n",
    "from resurfemg.postprocessing.event_detection import onoffpeak_baseline_crossing  # gebruik deze in plaats van slope_extrapolation\n",
    "\n",
    "# Parameters\n",
    "prominence_factor = 0.4\n",
    "min_peak_width_s = 0.6  # bepaalt gevoeligheid\n",
    "\n",
    "# Container voor resultaten\n",
    "emg_peak_results = {}\n",
    "\n",
    "for pid, patient in patient_data.items():\n",
    "    print(f\"\\n Detecting EMG-peaks patient {pid}\")\n",
    "    emg_peak_results[pid] = {}\n",
    "\n",
    "    for tp, data in patient.items():\n",
    "        print(f\"  Time {tp}:\")\n",
    "        emg_ts = data[\"emg\"]\n",
    "        fs = emg_ts.param[\"fs\"]\n",
    "        emg_peak_results[pid][tp] = {}\n",
    "\n",
    "        for ch_idx, channel in enumerate(emg_ts.channels):\n",
    "            y_env = channel.y_env\n",
    "            y_baseline = channel.y_baseline\n",
    "\n",
    "            # Detecteer pieken\n",
    "            peak_idxs = detect_emg_breaths(\n",
    "                emg_env=y_env,\n",
    "                emg_baseline=y_baseline,\n",
    "                threshold=0,\n",
    "                prominence_factor=prominence_factor,\n",
    "                min_peak_width_s=int(min_peak_width_s * fs)\n",
    "            )\n",
    "\n",
    "            # Detecteer onsets/offsets met baseline-crossing methode\n",
    "            peak_start_idxs, peak_end_idxs, valid_starts, valid_ends, valid_peaks = onoffpeak_baseline_crossing(\n",
    "                signal_env=y_env,\n",
    "                baseline=y_baseline,\n",
    "                peak_idxs=peak_idxs\n",
    "            )\n",
    "\n",
    "            # Opslaan geldige pieken\n",
    "            channel_results = []\n",
    "            for i, peak_idx in enumerate(peak_idxs):\n",
    "                if valid_peaks[i]:\n",
    "                    channel_results.append({\n",
    "                        \"peak_idx\": int(peak_idx),\n",
    "                        \"onset_idx\": int(peak_start_idxs[i]),\n",
    "                        \"offset_idx\": int(peak_end_idxs[i])\n",
    "                    })\n",
    "\n",
    "            emg_peak_results[pid][tp][ch_idx] = channel_results\n",
    "            print(f\"    {len(channel_results)} valid peaks in channel {ch_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUAL INSPECTION EMG PEAKS\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def simple_emg_viewer_dual(pid='005', tp='t0', window_s=20):\n",
    "    \"\"\"\n",
    "    Viewer voor beide EMG-kanalen en ventilator, met tijdslider en piekinspectie.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pid : str\n",
    "        Patiënt-ID (zoals '005')\n",
    "    tp : str\n",
    "        Tijdstip (zoals 't0', 't1', 't3')\n",
    "    window_s : int\n",
    "        Lengte van het tijdsvenster in seconden\n",
    "    \"\"\"\n",
    "\n",
    "    # Ophalen van data voor de juiste tijdsmeting\n",
    "    emg_ts = patient_data[pid][tp]['emg']\n",
    "    vent_ts = patient_data[pid][tp]['vent']\n",
    "    fs = emg_ts.param['fs']\n",
    "\n",
    "    # Tijdas (gelijk voor beide EMG-kanalen)\n",
    "    t_env = emg_ts[0].t_data\n",
    "    duration = t_env[-1]\n",
    "\n",
    "    t_vent = vent_ts[0].t_data\n",
    "    y_vent = vent_ts[0].y_raw\n",
    "    y_vent_baseline = vent_ts[0].y_baseline\n",
    "\n",
    "    # Slider\n",
    "    t_slider = widgets.FloatSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=duration - window_s,\n",
    "        step=1,\n",
    "        description='Start (s)',\n",
    "        continuous_update=False\n",
    "    )\n",
    "\n",
    "    def plot_window(t_start):\n",
    "        t_end = t_start + window_s\n",
    "\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "        colors = ['tab:green', 'tab:blue']\n",
    "        labels = ['Parasternal', 'Diaphragm']\n",
    "\n",
    "        # EMG-kanalen\n",
    "        for ch_idx in [0, 1]:\n",
    "            t_emg = emg_ts[ch_idx].t_data\n",
    "            y_emg = emg_ts[ch_idx].y_env\n",
    "            y_baseline = emg_ts[ch_idx].y_baseline\n",
    "            peaks = emg_peak_results[pid][tp][ch_idx]\n",
    "\n",
    "            ax = axs[ch_idx]\n",
    "            ax.plot(t_emg, y_emg, color=colors[ch_idx], label=f\"{labels[ch_idx]} envelope\")\n",
    "            ax.plot(t_emg, y_baseline, linestyle='--', color=colors[ch_idx], alpha=0.6, label=\"baseline\")\n",
    "\n",
    "            # Pieken + onset/offset\n",
    "            for p in peaks:\n",
    "                pt = t_emg[p['peak_idx']]\n",
    "                onset = t_emg[p['onset_idx']]\n",
    "                offset = t_emg[p['offset_idx']]\n",
    "                if t_start <= pt <= t_end:\n",
    "                    ax.plot(pt, y_emg[p['peak_idx']], 'o', color='red', label='piek' if p == peaks[0] else \"\")\n",
    "                    ax.axvline(onset, linestyle='--', color='green', alpha=0.5, label='onset' if p == peaks[0] else \"\")\n",
    "                    ax.axvline(offset, linestyle='--', color='orange', alpha=0.5, label='offset' if p == peaks[0] else \"\")\n",
    "\n",
    "            ax.set_ylabel(\"EMG (µV)\")\n",
    "            ax.set_title(f'EMG - patient {pid}, {tp}')\n",
    "            ax.set_xlim([t_start, t_end])\n",
    "            ax.set_ylim([-5, 30])\n",
    "            ax.legend(loc='upper right')\n",
    "\n",
    "        # Ventilator\n",
    "        ax3 = axs[2]\n",
    "        ax3.plot(t_vent, y_vent, label='Paw', color='tab:blue')\n",
    "        ax3.plot(t_vent, y_vent_baseline, linestyle='--', color='red', label='Baseline')\n",
    "        ax3.set_xlim([t_start, t_end])\n",
    "        ax3.set_ylim([-5, 20])\n",
    "        ax3.set_ylabel(\"Paw (cmH₂O)\")\n",
    "        ax3.set_xlabel(\"Time (s)\")\n",
    "        ax3.set_title(\"Ventilator\")\n",
    "        ax3.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    display(t_slider)\n",
    "    widgets.interact(plot_window, t_start=t_slider)\n",
    "\n",
    "simple_emg_viewer_dual(pid='005', tp='t0', window_s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. EMG peak assesment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMG PEAK QUALITY ASSESSMENT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.integrate import trapezoid\n",
    "from resurfemg.postprocessing import quality_assessment as qa\n",
    "from resurfemg.postprocessing import features\n",
    "\n",
    "# Parameters\n",
    "snr_threshold = 1.2\n",
    "aub_threshold = 60  # percent\n",
    "bellshape_threshold = 50  # percent\n",
    "\n",
    "# Result container\n",
    "results = []\n",
    "\n",
    "# Loop over all patients and timepoints\n",
    "for pid, patient in patient_data.items():\n",
    "    for tp, data in patient.items():\n",
    "        emg_ts = data[\"emg\"]\n",
    "        fs = emg_ts.param[\"fs\"]\n",
    "        t_data = emg_ts.channels[0].t_data  # time axis (the same for all channels)\n",
    "\n",
    "        for ch_idx, channel in enumerate(emg_ts.channels):\n",
    "            y_env = channel.y_env\n",
    "            y_baseline = channel.y_baseline\n",
    "            ch_label = emg_ts.labels[ch_idx] if ch_idx < len(emg_ts.labels) else f\"channel_{ch_idx}\"\n",
    "\n",
    "            peaks = emg_peak_results[pid][tp][ch_idx]\n",
    "\n",
    "            if len(peaks) == 0:\n",
    "                print(f\"⚠️ No peaks detected for patient {pid}, {tp}, channel {ch_idx}\")\n",
    "                continue\n",
    "\n",
    "            peak_idxs = [p[\"peak_idx\"] for p in peaks]\n",
    "            onset_idxs = [p[\"onset_idx\"] for p in peaks]\n",
    "            offset_idxs = [p[\"offset_idx\"] for p in peaks]\n",
    "\n",
    "            # ➤ Calculate SNR\n",
    "            snr_values = qa.snr_pseudo(y_env, peak_idxs, y_baseline, fs)\n",
    "\n",
    "            # ➤ Area Under Baseline (AUB)\n",
    "            valid_aub, perc_under, _ = qa.percentage_under_baseline(\n",
    "                signal=y_env,\n",
    "                fs=fs,\n",
    "                peak_idxs=peak_idxs,\n",
    "                start_idxs=onset_idxs,\n",
    "                end_idxs=offset_idxs,\n",
    "                baseline=y_baseline,\n",
    "                aub_threshold=aub_threshold,\n",
    "            )\n",
    "\n",
    "            # ➤ Bell-curve error\n",
    "            time_products = features.time_product(y_env, fs, onset_idxs, offset_idxs, y_baseline)\n",
    "            valid_bell, _, perc_bell, _, _ = qa.evaluate_bell_curve_error(\n",
    "                peak_idxs=peak_idxs,\n",
    "                start_idxs=onset_idxs,\n",
    "                end_idxs=offset_idxs,\n",
    "                signal=y_env,\n",
    "                fs=fs,\n",
    "                time_products=time_products,\n",
    "                bell_threshold=bellshape_threshold,\n",
    "            )\n",
    "\n",
    "            # ➤ For each peak, assign a label based on all three conditions.\n",
    "            for i in range(len(peaks)):\n",
    "                peak_time = t_data[peak_idxs[i]]\n",
    "                onset_time = t_data[onset_idxs[i]]\n",
    "                offset_time = t_data[offset_idxs[i]]\n",
    "\n",
    "                label = (\n",
    "                    \"True peak\" if (\n",
    "                        snr_values[i] > snr_threshold and\n",
    "                        perc_under[i] < aub_threshold and\n",
    "                        perc_bell[i] < bellshape_threshold\n",
    "                    ) else \"False peak\"\n",
    "                )\n",
    "\n",
    "                results.append({\n",
    "                    \"patient_id\": pid,\n",
    "                    \"timepoint\": tp,\n",
    "                    \"channel\": ch_label,\n",
    "                    \"time_s\": peak_time,\n",
    "                    \"onset_s\": onset_time,\n",
    "                    \"offset_s\": offset_time,\n",
    "                    \"snr\": snr_values[i],\n",
    "                    \"perc_under_baseline\": perc_under[i],\n",
    "                    \"perc_bellshape_error\": perc_bell[i],\n",
    "                    \"label\": label\n",
    "                })\n",
    "\n",
    "# Collect all results into one DataFrame and save to CSV.\n",
    "results_df = pd.DataFrame(results)\n",
    "save_path = Path(\"emg_peak_assessment_all_patients.csv\")\n",
    "results_df.to_csv(save_path, index=False)\n",
    "print(f\"\\n✅ EMG-assessment stored in: {save_path}\")\n",
    "\n",
    "# ===============================\n",
    "# FALSE PEAK BREAKDOWN SUMMARY PER CHANNEL\n",
    "# ===============================\n",
    "# We now want to see, separately for parasternal and diaphragm channels,\n",
    "# the number and percentage (relative to that channel's total) of peaks\n",
    "# failing each criterion or combination thereof.\n",
    "file_path = 'emg_peak_assessment_all_patients.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "for channel in ['parasternal', 'diaphragm']:\n",
    "    ch_df = df[df['channel'] == channel]\n",
    "    total_ch = len(ch_df)\n",
    "    ch_false = ch_df[ch_df['label'] == 'False peak'].copy()\n",
    "    total_false_ch = len(ch_false)\n",
    "    \n",
    "    # Create boolean columns indicating if the respective criterion was failed.\n",
    "    ch_false['fails_snr'] = ch_false['snr'] <= snr_threshold\n",
    "    ch_false['fails_aub'] = ch_false['perc_under_baseline'] >= aub_threshold\n",
    "    ch_false['fails_bell'] = ch_false['perc_bellshape_error'] >= bellshape_threshold\n",
    "    \n",
    "    # Count breakdown (note: these counts are exclusive)\n",
    "    count_all_three = ch_false[(ch_false['fails_snr']) & (ch_false['fails_aub']) & (ch_false['fails_bell'])].shape[0]\n",
    "    count_snr_only = ch_false[(ch_false['fails_snr']) & (~ch_false['fails_aub']) & (~ch_false['fails_bell'])].shape[0]\n",
    "    count_aub_only = ch_false[(ch_false['fails_aub']) & (~ch_false['fails_snr']) & (~ch_false['fails_bell'])].shape[0]\n",
    "    count_bell_only = ch_false[(ch_false['fails_bell']) & (~ch_false['fails_snr']) & (~ch_false['fails_aub'])].shape[0]\n",
    "    count_bell_aub_only = ch_false[(ch_false['fails_bell']) & (ch_false['fails_aub']) & (~ch_false['fails_snr'])].shape[0]\n",
    "    count_bell_snr_only = ch_false[(ch_false['fails_bell']) & (ch_false['fails_snr']) & (~ch_false['fails_aub'])].shape[0]\n",
    "    count_aub_snr_only = ch_false[(ch_false['fails_aub']) & (ch_false['fails_snr']) & (~ch_false['fails_bell'])].shape[0]\n",
    "    \n",
    "    print(f\"\\n=== False Peak Breakdown for {channel.capitalize()} ===\")\n",
    "    print(f\"Total peaks: {total_ch}\")\n",
    "    print(f\"False peaks (total): {total_false_ch} ({(total_false_ch/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing all three (snr, AUB, bellshape): {count_all_three} ({(count_all_three/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing SNR criterion only: {count_snr_only} ({(count_snr_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing AUB criterion only: {count_aub_only} ({(count_aub_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing bellshape criterion only: {count_bell_only} ({(count_bell_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing both bellshape and AUB only: {count_bell_aub_only} ({(count_bell_aub_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing both bellshape and SNR only: {count_bell_snr_only} ({(count_bell_snr_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing both AUB and SNR only: {count_aub_snr_only} ({(count_aub_snr_only/total_ch*100):.1f}%)\")\n",
    "\n",
    "# ===============================\n",
    "# CHANNEL-BASED EMG PEAK DETECTION SUMMARY\n",
    "# ===============================\n",
    "parasternal_peaks = df[df['channel'] == 'parasternal']\n",
    "diaphragm_peaks = df[df['channel'] == 'diaphragm']\n",
    "\n",
    "# Count total and true peaks per channel\n",
    "total_parasternal = len(parasternal_peaks)\n",
    "true_parasternal = (parasternal_peaks['label'] == 'True peak').sum()\n",
    "percentage_true_parasternal = (true_parasternal / total_parasternal) * 100 if total_parasternal > 0 else 0\n",
    "\n",
    "total_diaphragm = len(diaphragm_peaks)\n",
    "true_diaphragm = (diaphragm_peaks['label'] == 'True peak').sum()\n",
    "percentage_true_diaphragm = (true_diaphragm / total_diaphragm) * 100 if total_diaphragm > 0 else 0\n",
    "\n",
    "print(\"\\n=== EMG Peak Detection Summary ===\")\n",
    "print(f\"Parasternal - Total peaks: {total_parasternal}, True peaks: {true_parasternal} ({percentage_true_parasternal:.1f}%)\")\n",
    "print(f\"Diaphragm   - Total peaks: {total_diaphragm}, True peaks: {true_diaphragm} ({percentage_true_diaphragm:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Part 1: Load classification file and select included measurements\n",
    "# ---------------------------\n",
    "msr_df = pd.read_csv(\"measurement_classification.csv\")\n",
    "\n",
    "# Create a key by concatenating Patient ID (padded to 3 digits) and Time ID\n",
    "msr_df[\"key\"] = msr_df[\"Patient ID\"].astype(str).str.strip().str.zfill(3) + \"_\" + msr_df[\"Time ID\"].astype(str).str.strip()\n",
    "\n",
    "# Select only measurements labeled as \"Include\"\n",
    "include_df = msr_df[msr_df[\"Label\"] == \"Include\"]\n",
    "included_keys = set(include_df[\"key\"].unique())\n",
    "\n",
    "# ---------------------------\n",
    "# Part 2: Load EMG peak assessment results and filter to included measurements\n",
    "# ---------------------------\n",
    "peaks_df = pd.read_csv(\"emg_peak_assessment_all_patients.csv\")\n",
    "peaks_df[\"key\"] = peaks_df[\"patient_id\"].astype(str).str.strip().str.zfill(3) + \"_\" + peaks_df[\"timepoint\"].astype(str).str.strip()\n",
    "\n",
    "# Filter to only include peaks from measurements labeled \"Include\"\n",
    "filtered_peaks = peaks_df[peaks_df[\"key\"].isin(included_keys)].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# Part 3: Overall EMG Peak Detection Summary by Channel\n",
    "# ---------------------------\n",
    "summary = {}\n",
    "for channel in [\"parasternal\", \"diaphragm\"]:\n",
    "    ch_df = filtered_peaks[filtered_peaks[\"channel\"].str.lower() == channel]\n",
    "    total_peaks = len(ch_df)\n",
    "    true_peaks = (ch_df[\"label\"] == \"True peak\").sum()\n",
    "    perc_true = (true_peaks / total_peaks * 100) if total_peaks > 0 else 0\n",
    "    summary[channel] = (total_peaks, true_peaks, perc_true)\n",
    "\n",
    "print(\"\\n=== EMG Peak Detection Summary ===\")\n",
    "print(f\"Parasternal - Total peaks: {summary['parasternal'][0]}, True peaks: {summary['parasternal'][1]} ({summary['parasternal'][2]:.1f}%)\")\n",
    "print(f\"Diaphragm   - Total peaks: {summary['diaphragm'][0]}, True peaks: {summary['diaphragm'][1]} ({summary['diaphragm'][2]:.1f}%)\")\n",
    "\n",
    "# ---------------------------\n",
    "# Part 4: False Peak Breakdown for Each Channel\n",
    "# ---------------------------\n",
    "# Thresholds\n",
    "snr_threshold = 1.2\n",
    "aub_threshold = 60      # in percent\n",
    "bellshape_threshold = 50  # in percent\n",
    "\n",
    "for channel in [\"parasternal\", \"diaphragm\"]:\n",
    "    ch_df = filtered_peaks[filtered_peaks[\"channel\"].str.lower() == channel]\n",
    "    total_ch = len(ch_df)\n",
    "    \n",
    "    # Only consider false peaks.\n",
    "    false_df = ch_df[ch_df[\"label\"] == \"False peak\"].copy()\n",
    "    total_false = len(false_df)\n",
    "    \n",
    "    # Create boolean columns indicating failure of each criterion.\n",
    "    false_df['fails_snr'] = false_df['snr'] <= snr_threshold\n",
    "    false_df['fails_aub'] = false_df['perc_under_baseline'] >= aub_threshold\n",
    "    false_df['fails_bell'] = false_df['perc_bellshape_error'] >= bellshape_threshold\n",
    "    \n",
    "    # Count breakdown (counts calculated exclusively)\n",
    "    count_all_three = false_df[(false_df['fails_snr']) & (false_df['fails_aub']) & (false_df['fails_bell'])].shape[0]\n",
    "    count_snr_only = false_df[(false_df['fails_snr']) & (~false_df['fails_aub']) & (~false_df['fails_bell'])].shape[0]\n",
    "    count_aub_only = false_df[(false_df['fails_aub']) & (~false_df['fails_snr']) & (~false_df['fails_bell'])].shape[0]\n",
    "    count_bell_only = false_df[(false_df['fails_bell']) & (~false_df['fails_snr']) & (~false_df['fails_aub'])].shape[0]\n",
    "    count_bell_aub_only = false_df[(false_df['fails_bell']) & (false_df['fails_aub']) & (~false_df['fails_snr'])].shape[0]\n",
    "    count_bell_snr_only = false_df[(false_df['fails_bell']) & (false_df['fails_snr']) & (~false_df['fails_aub'])].shape[0]\n",
    "    count_aub_snr_only = false_df[(false_df['fails_aub']) & (false_df['fails_snr']) & (~false_df['fails_bell'])].shape[0]\n",
    "    \n",
    "    print(f\"\\n=== False Peak Breakdown for {channel.capitalize()} ===\")\n",
    "    print(f\"Total peaks: {total_ch}\")\n",
    "    print(f\"False peaks (total): {total_false} ({(total_false/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing all three (snr, AUB, bellshape): {count_all_three} ({(count_all_three/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing SNR criterion only: {count_snr_only} ({(count_snr_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing AUB criterion only: {count_aub_only} ({(count_aub_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing bellshape criterion only: {count_bell_only} ({(count_bell_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing both bellshape and AUB only: {count_bell_aub_only} ({(count_bell_aub_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing both bellshape and SNR only: {count_bell_snr_only} ({(count_bell_snr_only/total_ch*100):.1f}%)\")\n",
    "    print(f\"  - Failing both AUB and SNR only: {count_aub_snr_only} ({(count_aub_snr_only/total_ch*100):.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SUMMARY EMG PEAK ASSESMENT\n",
    "import pandas as pd\n",
    "\n",
    "# Inladen\n",
    "df = pd.read_csv(\"emg_peak_assessment_all_patients.csv\")\n",
    "\n",
    "# Zorg dat patient_id een string is met voorloopnullen\n",
    "df[\"patient_id\"] = df[\"patient_id\"].astype(str).str.zfill(3)\n",
    "\n",
    "# Groepeer per patiënt, tijdstip én kanaal\n",
    "summary = (\n",
    "    df.groupby([\"patient_id\", \"timepoint\", \"channel\", \"label\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Voeg totalen en percentages toe op patientniveau\n",
    "summary[\"total_peaks\"] = summary.get(\"True peak\", 0) + summary.get(\"False peak\", 0)\n",
    "summary[\"true_peak_pct\"] = (summary.get(\"True peak\", 0) / summary[\"total_peaks\"] * 100).round(1)\n",
    "\n",
    "# Opslaan als .csv-bestand\n",
    "summary.to_csv(\"emg_peak_summary.csv\", index=False)\n",
    "print(f\"\\n✅ EMG-summary stored in: emg_peak_summary.csv\")\n",
    "\n",
    "# Toon tabel per patient/cardinal level\n",
    "print(\"\\n🔍 EMG Peak Quality Assessment per Patient/Time ID/Channel:\")\n",
    "print(\n",
    "    summary[\n",
    "        [\n",
    "            \"patient_id\",\n",
    "            \"timepoint\",\n",
    "            \"channel\",\n",
    "            \"True peak\",\n",
    "            \"False peak\",\n",
    "            \"total_peaks\",\n",
    "            \"true_peak_pct\",\n",
    "        ]\n",
    "    ].to_string(index=False)\n",
    ")\n",
    "\n",
    "# ---- Nieuwe toevoeging: Overzicht per kanaal ----\n",
    "\n",
    "# Groepeer over kanaal en label om het totaal aantal peaks per channel te berekenen\n",
    "channel_summary = (\n",
    "    df.groupby([\"channel\", \"label\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Voeg totalen en percentages toe op kanaalniveau\n",
    "channel_summary[\"total_peaks\"] = channel_summary.get(\"True peak\", 0) + channel_summary.get(\"False peak\", 0)\n",
    "channel_summary[\"true_peak_pct\"] = (\n",
    "    channel_summary.get(\"True peak\", 0) / channel_summary[\"total_peaks\"] * 100\n",
    ").round(1)\n",
    "\n",
    "# Opslaan als .csv-bestand (optioneel)\n",
    "channel_summary.to_csv(\"emg_peak_channel_summary.csv\", index=False)\n",
    "print(f\"\\n✅ EMG-channel-summary stored in: emg_peak_channel_summary.csv\")\n",
    "\n",
    "# Toon de samenvatting per kanaal\n",
    "print(\"\\n🔍Overall EMG Peak Quality Assessment per Channel:\")\n",
    "print(channel_summary.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ventilator onset,end, trigger detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VENTILATOR, START MV, END MV, TRIGGER DETECTION\n",
    "import csv\n",
    "from types import MethodType\n",
    "import importlib\n",
    "import resurfemg.preprocessing.airwaypressure as paw\n",
    "importlib.reload(paw)\n",
    "\n",
    "# --- Define the pipeline processing function for ventilator data ---\n",
    "def pipeline_process_vent(self, threshold_small_peaks=None):\n",
    "    \"\"\"\n",
    "    Process airway pressure data using the raw ventilator data.\n",
    "    \n",
    "    Assumes that the ventilator data is loaded as:\n",
    "         vent_ts = patient_data[pid][tp]['vent']\n",
    "    and that:\n",
    "         t_vent = vent_ts[0].t_data\n",
    "         y_vent = vent_ts[0].y_raw\n",
    "         (fs will be set manually).\n",
    "         \n",
    "    Steps:\n",
    "      1. Select the first time series from the ventilator data group.\n",
    "      2. Manually set its sampling frequency (fs_vent = 100) and alias y_raw.\n",
    "      3. Set self.channels to a list containing the chosen time series.\n",
    "      4. Call the airwaypressure functions to process the data:\n",
    "             - Find MV start (minima peaks)\n",
    "             - Find MV end (maxima peaks)\n",
    "             - Remove small peaks\n",
    "             - Extract breathing trigger\n",
    "             - Remove false MV starts\n",
    "    \"\"\"\n",
    "    if threshold_small_peaks is None:\n",
    "        threshold_small_peaks = 0.7\n",
    "\n",
    "    # Use the ventilator data group (assumed list-like) and select the first timeseries.\n",
    "    vent_channel = self[0]\n",
    "\n",
    "    # Manually set the sampling frequency for ventilator data.\n",
    "    fs_vent = 100\n",
    "    vent_channel.fs = fs_vent  # Important: set fs so that airwaypressure functions work.\n",
    "    \n",
    "    # Set the raw ventilator data and sampling frequency on the overall object.\n",
    "    self.y_raw = vent_channel.y_raw  \n",
    "    self.fs = fs_vent\n",
    "\n",
    "    # Create a dummy 'channels' attribute so that airwaypressure functions can access data via self.channels[0]\n",
    "    self.channels = [vent_channel]\n",
    "\n",
    "    # Process the airway pressure data:\n",
    "    self.time_start_in_mv, self.peak_start_in_mv, self.idx_start_in_mv = paw.find_peaks_vent(\n",
    "        self, 1.5, peak='minima'\n",
    "    )\n",
    "    self.time_end_in_mv, self.peak_end_in_mv, self.idx_end_in_mv = paw.find_peaks_vent(\n",
    "        self, 1.5, peak='maxima'\n",
    "    )\n",
    "    self.time_end_in_mv, self.peak_end_in_mv, self.idx_end_in_mv = paw.remove_small_peaks(\n",
    "        self, threshold_percentile=threshold_small_peaks\n",
    "    )\n",
    "    self.time_bt, self.bt, self.idx_bt = paw.extract_breathing_trigger(self)\n",
    "    self.time_start_in_mv, self.peak_start_in_mv, self.idx_start_in_mv = paw.remove_false_mv_starts(self)\n",
    "\n",
    "# --- Optionally, define a CSV save function for individual instances (if needed) ---\n",
    "def save_pipeline_output_to_csv(self, output_filename=\"vent_pipeline_output.csv\"):\n",
    "    \"\"\"\n",
    "    Save the pipeline processed output for one measurement to a CSV file.\n",
    "    The CSV file will include one row per computed parameter.\n",
    "    \"\"\"\n",
    "    with open(output_filename, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Parameter\", \"Values\"])\n",
    "        writer.writerow([\"time_start_in_mv\", \", \".join(map(str, self.time_start_in_mv))])\n",
    "        writer.writerow([\"peak_start_in_mv\", \", \".join(map(str, self.peak_start_in_mv))])\n",
    "        writer.writerow([\"idx_start_in_mv\", \", \".join(map(str, self.idx_start_in_mv))])\n",
    "        writer.writerow([\"time_end_in_mv\", \", \".join(map(str, self.time_end_in_mv))])\n",
    "        writer.writerow([\"peak_end_in_mv\", \", \".join(map(str, self.peak_end_in_mv))])\n",
    "        writer.writerow([\"idx_end_in_mv\", \", \".join(map(str, self.idx_end_in_mv))])\n",
    "        writer.writerow([\"time_bt\", \", \".join(map(str, self.time_bt))])\n",
    "        writer.writerow([\"bt\", \", \".join(map(str, self.bt))])\n",
    "        writer.writerow([\"idx_bt\", \", \".join(map(str, self.idx_bt))])\n",
    "    print(f\"Individual pipeline output saved to {output_filename}\")\n",
    "\n",
    "# --- Aggregate processing for all patient and time IDs ---\n",
    "# (Assuming patient_data is structured as:\n",
    "#   patient_data[patient_id][time_id] is a dictionary with at least a key 'vent'\n",
    "# )\n",
    "results = []   # List to store processed results dictionaries.\n",
    "\n",
    "for pid, patient in patient_data.items():\n",
    "    for tp, data in patient.items():\n",
    "        # Print a status message before processing\n",
    "        print(f\"calculating ventilator detection patient {pid}, {tp}...\")\n",
    "        \n",
    "        # Get the ventilator data group for this measurement.\n",
    "        vent_ts = data['vent']  # This is assumed list-like.\n",
    "        \n",
    "        # Attach the pipeline processing method to this instance.\n",
    "        vent_ts.pipeline_process_vent = MethodType(pipeline_process_vent, vent_ts)\n",
    "        # Run the pipeline processing method.\n",
    "        vent_ts.pipeline_process_vent(threshold_small_peaks=0.7)\n",
    "        \n",
    "        # Print a ready message after processing.\n",
    "        print(f\"Ventilator detection ready patient {pid}, {tp}.\")\n",
    "\n",
    "        # Collect the processed output into a dictionary.\n",
    "        rec = {\n",
    "            \"Patient ID\": pid,\n",
    "            \"Time ID\": tp,\n",
    "            \"time_start_in_mv\": \", \".join(map(str, vent_ts.time_start_in_mv)),\n",
    "            \"peak_start_in_mv\": \", \".join(map(str, vent_ts.peak_start_in_mv)),\n",
    "            \"idx_start_in_mv\": \", \".join(map(str, vent_ts.idx_start_in_mv)),\n",
    "            \"time_end_in_mv\": \", \".join(map(str, vent_ts.time_end_in_mv)),\n",
    "            \"peak_end_in_mv\": \", \".join(map(str, vent_ts.peak_end_in_mv)),\n",
    "            \"idx_end_in_mv\": \", \".join(map(str, vent_ts.idx_end_in_mv)),\n",
    "            \"time_bt\": \", \".join(map(str, vent_ts.time_bt)),\n",
    "            \"bt\": \", \".join(map(str, vent_ts.bt)),\n",
    "            \"idx_bt\": \", \".join(map(str, vent_ts.idx_bt)),\n",
    "        }\n",
    "        results.append(rec)\n",
    "\n",
    "# --- Write aggregated results to a CSV file ---\n",
    "fieldnames = [\n",
    "    \"Patient ID\", \"Time ID\",\n",
    "    \"time_start_in_mv\", \"peak_start_in_mv\", \"idx_start_in_mv\",\n",
    "    \"time_end_in_mv\", \"peak_end_in_mv\", \"idx_end_in_mv\",\n",
    "    \"time_bt\", \"bt\", \"idx_bt\"\n",
    "]\n",
    "\n",
    "output_csv = \"all_vent_pipeline_output.csv\"\n",
    "with open(output_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in results:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"All ventilator pipeline output saved to {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUAL INSPECTION EMG PEAKS VS VENTILATOR ONSET\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, FloatSlider\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the ventilator markers CSV\n",
    "vent_markers_df = pd.read_csv(\"all_vent_pipeline_output.csv\")\n",
    "\n",
    "def parse_csv_array(val_str):\n",
    "    \"\"\"\n",
    "    Parse a string representation of a numeric array.\n",
    "    This version removes square brackets and extra quotes, then splits on commas.\n",
    "    \"\"\"\n",
    "    if not val_str or not val_str.strip():\n",
    "        return np.array([])\n",
    "    # Remove any surrounding brackets and quotes:\n",
    "    val_str = val_str.strip().strip(\"[]\").replace(\"\\\"\", \"\").replace(\"'\", \"\")\n",
    "    # Split on commas and convert to float:\n",
    "    return np.array([float(x.strip()) for x in val_str.split(\",\") if x.strip() != \"\"])\n",
    "\n",
    "# ----- Load EMG quality assessment CSV and build a dictionary -----\n",
    "# Assumes the CSV file has the columns:\n",
    "# \"patient_id\", \"timepoint\", \"channel\", \"time_s\", \"onset_s\", \"offset_s\", \"snr\", \"perc_under_baseline\", \"perc_bellshape_error\", \"label\"\n",
    "emg_assessment_file = \"emg_peak_assessment_all_patients.csv\"\n",
    "emg_assessment_df = pd.read_csv(emg_assessment_file)\n",
    "\n",
    "# Build dictionary: emg_assessment[pid][tp][channel] = list of peak dicts.\n",
    "# Normalize patient IDs (convert to int if possible to remove leading zeros) and convert channel names to lowercase.\n",
    "emg_assessment = {}\n",
    "for idx, row in emg_assessment_df.iterrows():\n",
    "    pid_raw = str(row[\"patient_id\"]).strip()\n",
    "    if pid_raw.isdigit():\n",
    "        pid_str = str(int(pid_raw))\n",
    "    else:\n",
    "        pid_str = pid_raw\n",
    "    tp_str = str(row[\"timepoint\"]).strip()\n",
    "    ch = row[\"channel\"].strip().lower()\n",
    "    d = row.to_dict()\n",
    "    emg_assessment.setdefault(pid_str, {}).setdefault(tp_str, {}).setdefault(ch, []).append(d)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def scrollable_emg_plot(pid, tp, window_size=10, y_lims_emg=None, y_lims_vent=None):\n",
    "    \"\"\"\n",
    "    Plots the EMG and ventilator signals interactively for patient `pid` and time `tp`.\n",
    "    Overlays:\n",
    "      - Ventilator markers from the CSV:\n",
    "            • MV Start: (time_start_in_mv, peak_start_in_mv) as green triangles.\n",
    "            • MV End:   (time_end_in_mv, peak_end_in_mv) as red inverted triangles.\n",
    "            • Breathing Trigger: (time_bt, bt) as blue circles.\n",
    "      - EMG peaks along with onset and offset markers:\n",
    "            * Peak coordinates are taken from the global dictionary emg_peak_results[pid][tp][ch_idx].\n",
    "            * The quality label is obtained from the quality assessment dictionary (emg_assessment).\n",
    "              Peaks labeled as \"True peak\" are drawn with blue dots and those labeled as \"False peak\" with red dots.\n",
    "              If no quality data is found, a default red dot is used.\n",
    "    \"\"\"\n",
    "    # Normalize patient ID (remove leading zeros if numeric)\n",
    "    pid_key = str(int(pid)) if str(pid).isdigit() else str(pid).strip()\n",
    "    if pid not in patient_data or tp not in patient_data[pid]:\n",
    "        print(f\"❌ Invalid patient ID or time ID ({pid}, {tp})\")\n",
    "        return\n",
    "\n",
    "    emg_ts = patient_data[pid][tp]['emg']\n",
    "    vent_ts = patient_data[pid][tp]['vent']\n",
    "\n",
    "    # Use the time-axis from the first EMG channel\n",
    "    t_data = emg_ts[0].t_data\n",
    "    t_min = t_data[0]\n",
    "    t_max = t_data[-1]\n",
    "    t_slider_max = t_max - window_size\n",
    "\n",
    "    @interact(t_start=FloatSlider(min=t_min, max=t_slider_max, step=1,\n",
    "                                   value=t_min, description='Start (s)'))\n",
    "    def update_plot(t_start):\n",
    "        t_end = t_start + window_size\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(14, 8), sharex=True)\n",
    "        axes_emg = axes[:2]\n",
    "        axes_vent = axes[2]\n",
    "\n",
    "        colors_clean = ['lightgray', 'lightgray']\n",
    "        colors_env = ['tab:blue', 'tab:green']\n",
    "\n",
    "        # Plot the EMG channels using the run method (assumed to be defined for the timeseries objects)\n",
    "        emg_ts.run('plot_full', axes=axes_emg, signal_type='clean',\n",
    "                   colors=colors_clean, baseline_bool=False)\n",
    "        for ch_idx, ax in enumerate(axes_emg):\n",
    "            ax.plot(emg_ts[ch_idx].t_data, emg_ts[ch_idx].y_env,\n",
    "                    color=colors_env[ch_idx], linewidth=2.0, label='envelope')\n",
    "            ax.plot(emg_ts[ch_idx].t_data, emg_ts[ch_idx].y_baseline,\n",
    "                    color=colors_env[ch_idx], linestyle='--', linewidth=1.5, label='baseline')\n",
    "            # ----- Overlay EMG peaks with onset/offset markers, color-coded by quality -----\n",
    "            # Add dummy plots for legend: Blue for True peak, Red for False peak.\n",
    "            ax.plot([], [], 'o', color='blue', markersize=8, label='True peak')\n",
    "            ax.plot([], [], 'o', color='red', markersize=8, label='False peak')\n",
    "            \n",
    "            # Use global emg_peak_results for peak coordinates.\n",
    "            if pid in emg_peak_results and tp in emg_peak_results[pid]:\n",
    "                peaks = emg_peak_results[pid][tp][ch_idx]\n",
    "                t_emg = emg_ts[ch_idx].t_data\n",
    "                y_emg = emg_ts[ch_idx].y_env\n",
    "                # Get channel label from the timeseries and normalize to lowercase.\n",
    "                ch_label_orig = emg_ts.labels[ch_idx] if ch_idx < len(emg_ts.labels) else f\"channel_{ch_idx}\"\n",
    "                ch_label = ch_label_orig.strip().lower()\n",
    "                quality_data = None\n",
    "                if pid_key in emg_assessment and tp in emg_assessment[pid_key]:\n",
    "                    channel_map = {k.lower(): k for k in emg_assessment[pid_key][tp].keys()}\n",
    "                    if ch_label in channel_map:\n",
    "                        quality_data = emg_assessment[pid_key][tp][channel_map[ch_label]]\n",
    "                for p in peaks:\n",
    "                    pt = t_emg[p['peak_idx']]\n",
    "                    onset = t_emg[p['onset_idx']]\n",
    "                    offset = t_emg[p['offset_idx']]\n",
    "                    if t_start <= pt <= t_end:\n",
    "                        # Determine color based on quality label.\n",
    "                        peak_color = 'red'  # default\n",
    "                        if quality_data is not None:\n",
    "                            match = None\n",
    "                            for q in quality_data:\n",
    "                                if abs(float(q[\"time_s\"]) - pt) < 1e-3:\n",
    "                                    match = q\n",
    "                                    break\n",
    "                            if match and match[\"label\"].strip().lower() == \"true peak\":\n",
    "                                peak_color = 'blue'\n",
    "                        ax.plot(pt, y_emg[p['peak_idx']], 'o', color=peak_color, markersize=8)\n",
    "                        ax.axvline(onset, linestyle='--', color='green', alpha=0.5)\n",
    "                        ax.axvline(offset, linestyle='--', color='orange', alpha=0.5)\n",
    "            else:\n",
    "                print(f\"⚠️ No peak data in global emg_peak_results for patient {pid}, {tp}, channel {ch_idx}\")\n",
    "            # -----------------------------------------------------------\n",
    "            ax.legend(loc='upper right')\n",
    "            ax.set_xlim([t_start, t_end])\n",
    "            if y_lims_emg is not None:\n",
    "                ax.set_ylim(y_lims_emg)\n",
    "        axes_emg[0].set_title(f'EMG - patient {pid}, {tp}')\n",
    "        axes_emg[-1].set_xlabel('Time (s)')\n",
    "\n",
    "        # Plot the ventilator trace.\n",
    "        vent_ts.run('plot_full', axes=[axes_vent])\n",
    "        axes_vent.set_title(f'Ventilator - patient {pid}, {tp}')\n",
    "        axes_vent.set_xlabel('Time (s)')\n",
    "        if y_lims_vent is not None:\n",
    "            axes_vent.set_ylim(y_lims_vent)\n",
    "\n",
    "        # Overlay ventilator markers from the CSV.\n",
    "        mask = ((vent_markers_df[\"Patient ID\"].astype(str)\n",
    "                             .str.strip().str.lstrip(\"0\")) == str(pid).lstrip(\"0\")) & \\\n",
    "               ((vent_markers_df[\"Time ID\"].astype(str)\n",
    "                             .str.strip()) == str(tp).strip())\n",
    "        if mask.sum() > 0:\n",
    "            row = vent_markers_df[mask].iloc[0]\n",
    "            time_start_in_mv = parse_csv_array(row[\"time_start_in_mv\"])\n",
    "            peak_start_in_mv = parse_csv_array(row[\"peak_start_in_mv\"])\n",
    "            time_end_in_mv = parse_csv_array(row[\"time_end_in_mv\"])\n",
    "            peak_end_in_mv = parse_csv_array(row[\"peak_end_in_mv\"])\n",
    "            time_bt = parse_csv_array(row[\"time_bt\"])\n",
    "            bt = parse_csv_array(row[\"bt\"])\n",
    "\n",
    "            if time_start_in_mv.size and peak_start_in_mv.size:\n",
    "                axes_vent.plot(time_start_in_mv, peak_start_in_mv, 'g^', markersize=10, label=\"MV Start\")\n",
    "            if time_end_in_mv.size and peak_end_in_mv.size:\n",
    "                axes_vent.plot(time_end_in_mv, peak_end_in_mv, 'rv', markersize=10, label=\"MV End\")\n",
    "            if time_bt.size and bt.size:\n",
    "                axes_vent.plot(time_bt, bt, 'bo', markersize=8, label=\"Breathing Trigger\")\n",
    "            axes_vent.legend(loc='upper right')\n",
    "        else:\n",
    "            print(f\"No marker data found for patient {pid}, {tp}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "scrollable_emg_plot(\n",
    "    pid='002',       # example patient ID\n",
    "    tp='t3',         # example time ID\n",
    "    window_size=20,  # time window in seconds\n",
    "    y_lims_emg=[-5, 80],\n",
    "    y_lims_vent=[-5, 20]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSIGN VENTILATOR TRIGGER/AUTO TYPE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def parse_csv_array(val):\n",
    "    \"\"\"\n",
    "    Parse a value from the CSV that is expected to represent a numeric array.\n",
    "    \n",
    "    - If the value is missing (NaN), return an empty NumPy array.\n",
    "    - If the value is not a string (e.g. a single numeric value), return a NumPy array with that item.\n",
    "    - Otherwise, remove any extraneous brackets or quotes, split on commas,\n",
    "      and return a NumPy array of floats.\n",
    "    \"\"\"\n",
    "    # If the value is NaN, return an empty array.\n",
    "    if pd.isnull(val):\n",
    "        return np.array([])\n",
    "    # If it's not a string, return a one-element array.\n",
    "    if not isinstance(val, str):\n",
    "        return np.array([val])\n",
    "    # Remove any surrounding brackets and quotes.\n",
    "    val_str = val.strip().strip(\"[]\").replace(\"\\\"\", \"\").replace(\"'\", \"\")\n",
    "    if not val_str:\n",
    "        return np.array([])\n",
    "    # Split on comma and convert each to float.\n",
    "    return np.array([float(x.strip()) for x in val_str.split(\",\") if x.strip() != \"\"])\n",
    "\n",
    "# Load the output CSV from the ventilator pipeline.\n",
    "df = pd.read_csv(\"all_vent_pipeline_output.csv\")\n",
    "\n",
    "breath_records = []   # Will store one record per detected breath.\n",
    "breath_idx_counter = 1\n",
    "\n",
    "# Process each measurement (each row in the CSV).\n",
    "for index, row in df.iterrows():\n",
    "    pid = row[\"Patient ID\"]\n",
    "    tid = row[\"Time ID\"]\n",
    "    \n",
    "    # Parse the marker arrays.\n",
    "    ts = parse_csv_array(row[\"time_start_in_mv\"])   # MV start times (x coordinate)\n",
    "    ps = parse_csv_array(row[\"peak_start_in_mv\"])     # MV start amplitudes\n",
    "    te = parse_csv_array(row[\"time_end_in_mv\"])       # MV end times (x coordinate)\n",
    "    pe = parse_csv_array(row[\"peak_end_in_mv\"])       # MV end amplitudes\n",
    "    tb = parse_csv_array(row[\"time_bt\"])              # Breathing trigger times (x coordinate)\n",
    "    pb = parse_csv_array(row[\"bt\"])                   # Breathing trigger amplitudes\n",
    "    \n",
    "    # Keep track of which MV start and breathing trigger indices have been used.\n",
    "    used_ts = set()\n",
    "    used_tb = set()\n",
    "    \n",
    "    # Process each detected MV end (te).\n",
    "    for i, te_val in enumerate(te):\n",
    "        window_start = te_val - 1.5\n",
    "        \n",
    "        # Find MV start candidates in the window [te - 1.5, te] that haven't been used.\n",
    "        candidates_ts = []\n",
    "        for j, ts_val in enumerate(ts):\n",
    "            if j in used_ts:\n",
    "                continue\n",
    "            if window_start <= ts_val <= te_val:\n",
    "                candidates_ts.append((ts_val, j))\n",
    "        if len(candidates_ts) == 0:\n",
    "            # No matching MV start found in this window; ignore this MV end.\n",
    "            continue\n",
    "        \n",
    "        # Choose the MV start that is closest to the MV end (the maximum ts in the window).\n",
    "        chosen_ts_val, chosen_ts_idx = max(candidates_ts, key=lambda x: x[0])\n",
    "        \n",
    "        # Check for breathing trigger candidates within the same window.\n",
    "        candidates_tb = []\n",
    "        for k, tb_val in enumerate(tb):\n",
    "            if k in used_tb:\n",
    "                continue\n",
    "            if window_start <= tb_val <= te_val:\n",
    "                candidates_tb.append((tb_val, k))\n",
    "        if candidates_tb:\n",
    "            # Select the candidate trigger closest to the MV end.\n",
    "            chosen_tb_val, chosen_tb_idx = max(candidates_tb, key=lambda x: x[0])\n",
    "            breath_type = \"Triggered Breath\"\n",
    "        else:\n",
    "            breath_type = \"Auto Breath\"\n",
    "            chosen_tb_val = None\n",
    "            chosen_tb_idx = None\n",
    "        \n",
    "        # Mark the chosen markers as used.\n",
    "        used_ts.add(chosen_ts_idx)\n",
    "        if chosen_tb_idx is not None:\n",
    "            used_tb.add(chosen_tb_idx)\n",
    "        \n",
    "        # Create a record for this detected breath.\n",
    "        rec = {\n",
    "            \"Patient ID\": pid,\n",
    "            \"Time ID\": tid,\n",
    "            \"Breath Index\": breath_idx_counter,\n",
    "            \"Breath Type\": breath_type,\n",
    "            \"time_start_in_mv\": chosen_ts_val,\n",
    "            \"peak_start_in_mv\": ps[chosen_ts_idx] if chosen_ts_idx < len(ps) else np.nan,\n",
    "            \"time_end_in_mv\": te_val,\n",
    "            \"peak_end_in_mv\": pe[i] if i < len(pe) else np.nan,\n",
    "        }\n",
    "        if breath_type == \"Triggered Breath\":\n",
    "            rec[\"time_bt\"] = chosen_tb_val\n",
    "            rec[\"bt\"] = pb[chosen_tb_idx] if chosen_tb_idx is not None and chosen_tb_idx < len(pb) else np.nan\n",
    "        else:\n",
    "            rec[\"time_bt\"] = \"\"\n",
    "            rec[\"bt\"] = \"\"\n",
    "            \n",
    "        breath_records.append(rec)\n",
    "        breath_idx_counter += 1\n",
    "\n",
    "# Convert the detected breath records into a DataFrame and save as CSV.\n",
    "breath_df = pd.DataFrame(breath_records)\n",
    "breath_df.to_csv(\"vent_breaths_output.csv\", index=False)\n",
    "print(\"Breath detection CSV saved as vent_breaths_output.csv\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Now, compute and print summary statistics.\n",
    "total_breaths = len(breath_df)\n",
    "total_triggered = (breath_df[\"Breath Type\"] == \"Triggered Breath\").sum()\n",
    "total_auto = (breath_df[\"Breath Type\"] == \"Auto Breath\").sum()\n",
    "\n",
    "if total_breaths > 0:\n",
    "    percent_triggered = 100 * total_triggered / total_breaths\n",
    "    percent_auto = 100 * total_auto / total_breaths\n",
    "else:\n",
    "    percent_triggered = 0\n",
    "    percent_auto = 0\n",
    "\n",
    "print(\"\\nOverall Breath Detection Summary:\")\n",
    "print(f\"  Total breaths: {total_breaths}\")\n",
    "print(f\"  Triggered breaths: {total_triggered} ({percent_triggered:.2f}%)\")\n",
    "print(f\"  Auto breaths: {total_auto} ({percent_auto:.2f}%)\")\n",
    "\n",
    "# Also, compute the numbers per patient/time measurement.\n",
    "grouped = breath_df.groupby([\"Patient ID\", \"Time ID\"])\n",
    "print(\"\\nBreath Detection by Patient and Time ID:\")\n",
    "for (pid, tid), group in grouped:\n",
    "    total = len(group)\n",
    "    triggered = (group[\"Breath Type\"] == \"Triggered Breath\").sum()\n",
    "    auto = (group[\"Breath Type\"] == \"Auto Breath\").sum()\n",
    "    pct_triggered = 100 * triggered / total if total > 0 else 0\n",
    "    pct_auto = 100 * auto / total if total > 0 else 0\n",
    "    print(f\"  Patient {pid}, Time {tid}:\")\n",
    "    print(f\"    Total breaths: {total}\")\n",
    "    print(f\"    Triggered: {triggered} ({pct_triggered:.2f}%)\")\n",
    "    print(f\"    Auto: {auto} ({pct_auto:.2f}%)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Part 1: Load measurement classification file and select included measurements\n",
    "# ---------------------------\n",
    "msr_df = pd.read_csv(\"measurement_classification.csv\")\n",
    "\n",
    "# Create a key by concatenating \"Patient ID\" and \"Time ID\"\n",
    "msr_df[\"key\"] = msr_df[\"Patient ID\"].astype(str).str.strip() + \"_\" + msr_df[\"Time ID\"].astype(str).str.strip()\n",
    "\n",
    "# Select only measurements labeled as \"Include\"\n",
    "include_df = msr_df[msr_df[\"Label\"] == \"Include\"]\n",
    "included_keys = set(include_df[\"key\"].unique())\n",
    "\n",
    "# ---------------------------\n",
    "# Part 2: Load ventilator breath detection results\n",
    "# ---------------------------\n",
    "breath_df = pd.read_csv(\"vent_breaths_output.csv\")\n",
    "\n",
    "# Create the same key in the breath data\n",
    "breath_df[\"key\"] = breath_df[\"Patient ID\"].astype(str).str.strip() + \"_\" + breath_df[\"Time ID\"].astype(str).str.strip()\n",
    "\n",
    "# ---------------------------\n",
    "# Part 3: Filter for included measurements only\n",
    "# ---------------------------\n",
    "included_breaths = breath_df[breath_df[\"key\"].isin(included_keys)].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# Part 4: Compute overall summary for included measurements\n",
    "# ---------------------------\n",
    "total_breaths = len(included_breaths)\n",
    "triggered_breaths = (included_breaths[\"Breath Type\"] == \"Triggered Breath\").sum()\n",
    "auto_breaths = (included_breaths[\"Breath Type\"] == \"Auto Breath\").sum()\n",
    "\n",
    "perc_triggered = (triggered_breaths / total_breaths * 100) if total_breaths > 0 else 0\n",
    "perc_auto = (auto_breaths / total_breaths * 100) if total_breaths > 0 else 0\n",
    "\n",
    "# ---------------------------\n",
    "# Part 5: Print the overall summary\n",
    "# ---------------------------\n",
    "print(\"\\n=== Overall Breath Detection Summary ===\")\n",
    "print(f\"  Total breaths: {total_breaths}\")\n",
    "print(f\"  Triggered breaths: {triggered_breaths} ({perc_triggered:.2f}%)\")\n",
    "print(f\"  Auto breaths: {auto_breaths} ({perc_auto:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Instellingen ===\n",
    "assessment_file = \"emg_peak_assessment_all_patients.csv\"\n",
    "pid = \"005\"\n",
    "tp = \"t0\"\n",
    "window = 0.5  # seconden\n",
    "confidence = 0.95\n",
    "\n",
    "# === CI-functie\n",
    "def wilson_ci(x, n, confidence=0.95):\n",
    "    if n == 0:\n",
    "        return (0.0, 0.0)\n",
    "    z = norm.ppf(1 - (1 - confidence) / 2)\n",
    "    phat = x / n\n",
    "    denom = 1 + (z**2 / n)\n",
    "    centre = phat + (z**2 / (2 * n))\n",
    "    margin = z * np.sqrt((phat * (1 - phat) + (z**2 / (4 * n))) / n)\n",
    "    return (centre - margin) / denom * 100, (centre + margin) / denom * 100\n",
    "\n",
    "# === Overlapfunctie\n",
    "def compute_overlap(reference_times, comparison_times, window):\n",
    "    count_overlap = sum(np.any(np.abs(comparison_times - t_ref) <= window) for t_ref in reference_times)\n",
    "    percentage = (count_overlap / len(reference_times)) * 100 if len(reference_times) > 0 else 0\n",
    "    return count_overlap, percentage\n",
    "\n",
    "# === Data inladen ===\n",
    "df = pd.read_csv(assessment_file)\n",
    "df[\"patient_id\"] = df[\"patient_id\"].astype(str).str.zfill(3)\n",
    "\n",
    "# Filter op patiënt, tijdstip en true peaks\n",
    "df_sub = df[\n",
    "    (df[\"patient_id\"] == pid) &\n",
    "    (df[\"timepoint\"] == tp) &\n",
    "    (df[\"label\"] == \"True peak\")\n",
    "]\n",
    "\n",
    "# Check of kanaalnamen aanwezig zijn\n",
    "channels = df_sub[\"channel\"].unique()\n",
    "if not {\"parasternal\", \"diaphragm\"}.issubset(set(channels)):\n",
    "    print(f\"⚠️ Not both channels are present for patient {pid}, {tp}: {channels}\")\n",
    "else:\n",
    "    # Haal tijdstippen per kanaal\n",
    "    t_para = df_sub[df_sub[\"channel\"] == \"parasternal\"][\"time_s\"].to_numpy()\n",
    "    t_diaphragm = df_sub[df_sub[\"channel\"] == \"diaphragm\"][\"time_s\"].to_numpy()\n",
    "\n",
    "    # Overlapberekening\n",
    "    ov_para, perc_para = compute_overlap(t_para, t_diaphragm, window)\n",
    "    ci_para = wilson_ci(ov_para, len(t_para))\n",
    "\n",
    "    ov_dia, perc_dia = compute_overlap(t_diaphragm, t_para, window)\n",
    "    ci_dia = wilson_ci(ov_dia, len(t_diaphragm))\n",
    "\n",
    "    # Print output\n",
    "    print(f\"\\nOverlap-analysis patient {pid}, {tp} (±{window}s):\")\n",
    "    print(f\"Parasternal: {len(t_para)} peaks → {ov_para} overlap with diaphragm \"\n",
    "          f\"({perc_para:.1f}%, 95% CI: {ci_para[0]:.1f}%–{ci_para[1]:.1f}%)\")\n",
    "    print(f\"Diaphragm: {len(t_diaphragm)} peaks → {ov_dia} overlap with parasternal \"\n",
    "          f\"({perc_dia:.1f}%, 95% CI: {ci_dia[0]:.1f}%–{ci_dia[1]:.1f}%)\")\n",
    "\n",
    "    # === Plot\n",
    "    labels = ['Diaphragm', 'Parasternal']\n",
    "    percentages = [perc_dia, perc_para]\n",
    "    overlaps = [ov_dia, ov_para]\n",
    "    counts = [len(t_diaphragm), len(t_para)]\n",
    "    ci_lower = [p - ci[0] for p, ci in zip(percentages, [ci_dia, ci_para])]\n",
    "    ci_upper = [ci[1] - p for p, ci in zip(percentages, [ci_dia, ci_para])]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    bars = plt.bar(labels, percentages, yerr=[ci_lower, ci_upper], capsize=5, color=[\"blue\", \"green\"])\n",
    "    plt.ylabel(\"Percentage overlapping peaks\")\n",
    "    plt.ylim(0, 110)\n",
    "    plt.title(f\"Overlap of True Peaks – Patient {pid}, {tp.upper()}\")\n",
    "    plt.grid(axis=\"y\")\n",
    "\n",
    "    for bar, total, n_overlap in zip(bars, counts, overlaps):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n",
    "                 f\"{n_overlap}/{total}\", ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === Instellingen ===\n",
    "assessment_file = \"emg_peak_assessment_all_patients.csv\"\n",
    "pid = \"005\"\n",
    "tp = \"t0\"\n",
    "window = 0.6  # seconden\n",
    "confidence = 0.95\n",
    "\n",
    "# === Wilson CI functie\n",
    "def wilson_ci(x, n, confidence=0.95):\n",
    "    if n == 0:\n",
    "        return (0.0, 0.0)\n",
    "    z = norm.ppf(1 - (1 - confidence) / 2)\n",
    "    phat = x / n\n",
    "    denom = 1 + (z**2 / n)\n",
    "    centre = phat + (z**2 / (2 * n))\n",
    "    margin = z * np.sqrt((phat * (1 - phat) + (z**2 / (4 * n))) / n)\n",
    "    return (centre - margin) / denom * 100, (centre + margin) / denom * 100\n",
    "\n",
    "# === Overlapfunctie\n",
    "def compute_overlap(reference_times, comparison_times, window):\n",
    "    count_overlap = sum(np.any(np.abs(comparison_times - t_ref) <= window) for t_ref in reference_times)\n",
    "    percentage = (count_overlap / len(reference_times)) * 100 if len(reference_times) > 0 else 0\n",
    "    return count_overlap, percentage\n",
    "\n",
    "# === Data inladen ===\n",
    "df = pd.read_csv(assessment_file)\n",
    "df[\"patient_id\"] = df[\"patient_id\"].astype(str).str.zfill(3)\n",
    "\n",
    "# Filter op patiënt en tijdstip\n",
    "df_sub = df[(df[\"patient_id\"] == pid) & (df[\"timepoint\"] == tp)]\n",
    "\n",
    "# Check of beide kanalen aanwezig zijn\n",
    "channels = df_sub[\"channel\"].unique()\n",
    "if not {\"parasternal\", \"diaphragm\"}.issubset(set(channels)):\n",
    "    print(f\"⚠️ Niet beide kanalen aanwezig voor patiënt {pid}, {tp}: {channels}\")\n",
    "else:\n",
    "    # Tijdstippen per kanaal en label\n",
    "    t_para_true = df_sub[(df_sub[\"channel\"] == \"parasternal\") & (df_sub[\"label\"] == \"True peak\")][\"time_s\"].to_numpy()\n",
    "    t_para_all = df_sub[df_sub[\"channel\"] == \"parasternal\"][\"time_s\"].to_numpy()\n",
    "    t_dia_true = df_sub[(df_sub[\"channel\"] == \"diaphragm\") & (df_sub[\"label\"] == \"True peak\")][\"time_s\"].to_numpy()\n",
    "    t_dia_all = df_sub[df_sub[\"channel\"] == \"diaphragm\"][\"time_s\"].to_numpy()\n",
    "\n",
    "    # Overlap berekeningen\n",
    "    ov_dia_true, perc_dia_true = compute_overlap(t_dia_true, t_para_true, window)\n",
    "    ci_dia_true = wilson_ci(ov_dia_true, len(t_dia_true))\n",
    "\n",
    "    ov_dia_all, perc_dia_all = compute_overlap(t_dia_true, t_para_all, window)\n",
    "    ci_dia_all = wilson_ci(ov_dia_all, len(t_dia_true))\n",
    "\n",
    "    ov_para_true, perc_para_true = compute_overlap(t_para_true, t_dia_true, window)\n",
    "    ci_para_true = wilson_ci(ov_para_true, len(t_para_true))\n",
    "\n",
    "    ov_para_all, perc_para_all = compute_overlap(t_para_true, t_dia_all, window)\n",
    "    ci_para_all = wilson_ci(ov_para_all, len(t_para_true))\n",
    "\n",
    "        # === Print output naar terminal\n",
    "    print(f\"\\nOverlap-analysis patient {pid}, {tp} (±{window}s):\")\n",
    "\n",
    "    print(\"True peaks only:\")\n",
    "    print(f\"  Parasternal: {len(t_para_true)} peaks → {ov_para_true} overlap with diaphragm \"\n",
    "          f\"({perc_para_true:.1f}%, 95% CI: {ci_para_true[0]:.1f}%–{ci_para_true[1]:.1f}%)\")\n",
    "    print(f\"  Diaphragm:   {len(t_dia_true)} peaks → {ov_dia_true} overlap with parasternal \"\n",
    "          f\"({perc_dia_true:.1f}%, 95% CI: {ci_dia_true[0]:.1f}%–{ci_dia_true[1]:.1f}%)\")\n",
    "\n",
    "    print(\"\\nCompared with all detected peaks:\")\n",
    "    print(f\"  Parasternal: {len(t_para_true)} True peaks → {ov_para_all} overlap with all diaphragm peaks\"\n",
    "          f\"({perc_para_all:.1f}%, 95% CI: {ci_para_all[0]:.1f}%–{ci_para_all[1]:.1f}%)\")\n",
    "    print(f\"  Diaphragm:   {len(t_dia_true)} True peaks → {ov_dia_all} overlap with all parasternal peaks\"\n",
    "          f\"({perc_dia_all:.1f}%, 95% CI: {ci_dia_all[0]:.1f}%–{ci_dia_all[1]:.1f}%)\")\n",
    "\n",
    "    # === Plot\n",
    "    labels = [\"Diaphragm\", \"Parasternal\"]\n",
    "    true_perc = [perc_dia_true, perc_para_true]\n",
    "    all_perc = [perc_dia_all, perc_para_all]\n",
    "    true_ci = [ci_dia_true, ci_para_true]\n",
    "    all_ci = [ci_dia_all, ci_para_all]\n",
    "    true_ov = [ov_dia_true, ov_para_true]\n",
    "    all_ov = [ov_dia_all, ov_para_all]\n",
    "    true_total = [len(t_dia_true), len(t_para_true)]\n",
    "\n",
    "    x = np.arange(len(labels))  # [0, 1]\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    bars1 = ax.bar(x - width/2, true_perc, width,\n",
    "                   yerr=[[p - c[0] for p, c in zip(true_perc, true_ci)],\n",
    "                         [c[1] - p for p, c in zip(true_perc, true_ci)]],\n",
    "                   capsize=5, color=['blue', 'blue'])\n",
    "\n",
    "    bars2 = ax.bar(x + width/2, all_perc, width,\n",
    "                   yerr=[[p - c[0] for p, c in zip(all_perc, all_ci)],\n",
    "                         [c[1] - p for p, c in zip(all_perc, all_ci)]],\n",
    "                   capsize=5, color=['lightblue', 'lightblue'])\n",
    "\n",
    "    # Annotaties\n",
    "    for i in range(len(x)):\n",
    "        ax.text(x[i] - width/2, true_perc[i] + 2,\n",
    "                f\"{true_ov[i]}/{true_total[i]}\", ha='center', va='bottom', fontsize=9)\n",
    "        ax.text(x[i] + width/2, all_perc[i] + 2,\n",
    "                f\"{all_ov[i]}/{true_total[i]}\", ha='center', va='bottom', fontsize=9, color='dimgray')\n",
    "\n",
    "    # Aanduiding + legenda\n",
    "    ax.set_ylabel(\"Percentage overlapping peaks\")\n",
    "    ax.set_ylim(0, 110)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title(f\"Overlap analyse – patiënt {pid}, tijdstip {tp.upper()}\")\n",
    "    legend_handles = [\n",
    "        plt.Rectangle((0, 0), 1, 1, color='blue', label='True peaks'),\n",
    "        plt.Rectangle((0, 0), 1, 1, color='lightblue', label='Compared with all peaks'),\n",
    "        plt.Rectangle((0, 0), 1, 1, color='blue'),\n",
    "        plt.Rectangle((0, 0), 1, 1, color='lightblue')\n",
    "    ]\n",
    "    ax.legend(handles=legend_handles[:2], loc=\"upper right\")  # Alleen de blauwe legenda\n",
    "\n",
    "    ax.grid(axis=\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# === Instellingen (pas hier eenvoudig aan) ===\n",
    "pid = \"002\"\n",
    "tp = \"t24\"\n",
    "window = 0.5  # s: maximale verschil voor overlap\n",
    "window_width = 120  # breedte van het venster in seconden\n",
    "\n",
    "# === Data inladen ===\n",
    "df = pd.read_csv(\"emg_peak_assessment_all_patients.csv\")\n",
    "df[\"patient_id\"] = df[\"patient_id\"].astype(str).str.zfill(3)\n",
    "\n",
    "# Filter op patiënt, tijdstip en label\n",
    "df_sub = df[\n",
    "    (df[\"patient_id\"] == pid) &\n",
    "    (df[\"timepoint\"] == tp) &\n",
    "    (df[\"label\"] == \"True peak\")\n",
    "]\n",
    "\n",
    "# Haal tijdstippen per kanaal\n",
    "t_para = df_sub[df_sub[\"channel\"] == \"parasternal\"][\"time_s\"].to_numpy()\n",
    "t_dia = df_sub[df_sub[\"channel\"] == \"diaphragm\"][\"time_s\"].to_numpy()\n",
    "\n",
    "# Tijdsbereik\n",
    "start_time = 0\n",
    "end_time = max(t_para.max() if len(t_para) else 0, t_dia.max() if len(t_dia) else 0)\n",
    "\n",
    "# === Plotfunctie ===\n",
    "def plot_overlap_window(center_time):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Filter pieken binnen tijdsvenster\n",
    "    mask_dia = (t_dia >= center_time - window_width/2) & (t_dia <= center_time + window_width/2)\n",
    "    mask_para = (t_para >= center_time - window_width/2) & (t_para <= center_time + window_width/2)\n",
    "    t_dia_window = t_dia[mask_dia]\n",
    "    t_para_window = t_para[mask_para]\n",
    "\n",
    "    # Plot pieken\n",
    "    plt.scatter(t_dia_window, np.ones_like(t_dia_window), color=\"blue\", label=\"Diaphragm peaks\", marker='o')\n",
    "    plt.scatter(t_para_window, np.zeros_like(t_para_window), color=\"green\", label=\"Parasternal peaks\", marker='x')\n",
    "\n",
    "    # Lijnen bij overlap\n",
    "    for t1 in t_dia_window:\n",
    "        close = t_para_window[np.abs(t_para_window - t1) <= window]\n",
    "        for t2 in close:\n",
    "            plt.plot([t1, t2], [1, 0], color=\"red\", alpha=0.5, linewidth=1)\n",
    "\n",
    "    # Aankleding\n",
    "    plt.yticks([0, 1], [\"Parasternal\", \"Diaphragm\"])\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.title(f\"True peak overlap — patient {pid}, {tp} — ±{window}s\")\n",
    "    plt.xlim(center_time - window_width/2, center_time + window_width/2)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Interactieve slider aanroepen ===\n",
    "if end_time > window_width:\n",
    "    interact(plot_overlap_window,\n",
    "             center_time=FloatSlider(min=start_time + window_width/2,\n",
    "                                     max=end_time - window_width/2,\n",
    "                                     step=1.0,\n",
    "                                     value=(start_time + end_time)/2,\n",
    "                                     description='Tijd (s)',\n",
    "                                     continuous_update=False))\n",
    "else:\n",
    "    print(\" Not enough data points for scrolling within this window\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation EMG diafragma en EMG parasternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === INVOER: pas deze waarden aan ===\n",
    "pid = 5                # patiëntnummer (int)\n",
    "tp = \"t0\"              # timepoint (bijv. \"t0\", \"t1\")\n",
    "window = 0.5           # tijdsvenster in seconden\n",
    "confidence = 0.95      # betrouwbaarheidsinterval\n",
    "\n",
    "# === Bestanden inladen ===\n",
    "emg_df = pd.read_csv(\"emg_peak_assessment_all_patients.csv\")\n",
    "vent_df = pd.read_csv(\"ventilator_breaths_all_patients.csv\")\n",
    "\n",
    "# === Wilson CI functie ===\n",
    "def wilson_ci(x, n, confidence=0.95):\n",
    "    if n == 0:\n",
    "        return (0.0, 0.0)\n",
    "    z = norm.ppf(1 - (1 - confidence) / 2)\n",
    "    phat = x / n\n",
    "    denominator = 1 + (z**2 / n)\n",
    "    centre = phat + (z**2 / (2 * n))\n",
    "    margin = z * np.sqrt((phat * (1 - phat) + (z**2 / (4 * n))) / n)\n",
    "    lower = (centre - margin) / denominator\n",
    "    upper = (centre + margin) / denominator\n",
    "    return lower * 100, upper * 100\n",
    "\n",
    "# === Overlap-functie ===\n",
    "def compute_overlap_percent(reference_peaks, comparison_peaks, window):\n",
    "    count_overlap = 0\n",
    "    for t_ref in reference_peaks:\n",
    "        if np.any(np.abs(comparison_peaks - t_ref) <= window):\n",
    "            count_overlap += 1\n",
    "    percentage = (count_overlap / len(reference_peaks)) * 100 if len(reference_peaks) > 0 else 0\n",
    "    return count_overlap, percentage\n",
    "\n",
    "# === Analysefunctie ===\n",
    "def analyse_emg_vs_vent_overlap(patient_id, timepoint, window=0.3, confidence=0.95):\n",
    "    patient_id = int(patient_id)\n",
    "\n",
    "    emg_sub = emg_df[(emg_df[\"patient_id\"] == patient_id) & (emg_df[\"timepoint\"] == timepoint)]\n",
    "    vent_sub = vent_df[(vent_df[\"patient_id\"] == patient_id) & (vent_df[\"timepoint\"] == timepoint)]\n",
    "\n",
    "    true_peaks = emg_sub[emg_sub[\"label\"] == \"True peak\"]\n",
    "    t_dia = true_peaks[true_peaks[\"channel\"].str.contains(\"diaphragm\", case=False)][\"time_s\"].to_numpy()\n",
    "    t_int = true_peaks[true_peaks[\"channel\"].str.contains(\"parasternal\", case=False)][\"time_s\"].to_numpy()\n",
    "\n",
    "    t_onsets = vent_sub[\"time_onset_s\"].to_numpy()\n",
    "\n",
    "    overlap_dia, perc_dia = compute_overlap_percent(t_dia, t_onsets, window)\n",
    "    ci_dia = wilson_ci(overlap_dia, len(t_dia), confidence)\n",
    "\n",
    "    overlap_int, perc_int = compute_overlap_percent(t_int, t_onsets, window)\n",
    "    ci_int = wilson_ci(overlap_int, len(t_int), confidence)\n",
    "\n",
    "    print(f\" Overlapanalysis with ventilator-onsets (±{window}s window) patiënt {patient_id}, {timepoint}:\")\n",
    "    print(f\"- Diaphragm: {len(t_dia)} true peaks → {overlap_dia} overlap \"\n",
    "          f\"({perc_dia:.1f}%, 95% CI: {ci_dia[0]:.1f}% - {ci_dia[1]:.1f}%)\")\n",
    "    print(f\"- Parasternal: {len(t_int)} true peaks → {overlap_int} overlap \"\n",
    "          f\"({perc_int:.1f}%, 95% CI: {ci_int[0]:.1f}% - {ci_int[1]:.1f}%)\")\n",
    "\n",
    "    # === Visualisatie ===\n",
    "    labels = ['Diaphragm', 'Parasternal']\n",
    "    true_counts = [len(t_dia), len(t_int)]\n",
    "    overlaps = [overlap_dia, overlap_int]\n",
    "    percentages = [perc_dia, perc_int]\n",
    "    ci_lower = [perc - ci[0] for perc, ci in zip(percentages, [ci_dia, ci_int])]\n",
    "    ci_upper = [ci[1] - perc for perc, ci in zip(percentages, [ci_dia, ci_int])]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    bars = plt.bar(labels, percentages, yerr=[ci_lower, ci_upper], capsize=6, color=[\"blue\", \"green\"])\n",
    "    plt.ylabel(\"Percentage EMG peak overlap with ventilator onset\")\n",
    "    plt.ylim(0, 110)\n",
    "    plt.title(f\"Overlap EMG & Ventilator patient {patient_id}, {timepoint} (±{window}s)\")\n",
    "    plt.grid(axis=\"y\")\n",
    "\n",
    "    for bar, count, overlap in zip(bars, true_counts, overlaps):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 3,\n",
    "                 f\"{overlap}/{count}\", ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Uitvoeren ===\n",
    "analyse_emg_vs_vent_overlap(pid, tp, window, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# === INVOER: pas deze waarden aan ===\n",
    "pid = 5                # patiëntnummer (int)\n",
    "tp = \"t0\"              # timepoint (bijv. \"t0\", \"t1\")\n",
    "window = 0.5           # tijdsvenster in seconden\n",
    "confidence = 0.95      # betrouwbaarheidsinterval\n",
    "\n",
    "# === Bestanden inladen ===\n",
    "emg_df = pd.read_csv(\"emg_peak_assessment_all_patients.csv\")\n",
    "vent_df = pd.read_csv(\"vent_breaths_output.csv\")\n",
    "\n",
    "# === Wilson CI functie ===\n",
    "def wilson_ci(x, n, confidence=0.95):\n",
    "    if n == 0:\n",
    "        return (0.0, 0.0)\n",
    "    z = norm.ppf(1 - (1 - confidence) / 2)\n",
    "    phat = x / n\n",
    "    denominator = 1 + (z**2 / n)\n",
    "    centre = phat + (z**2 / (2 * n))\n",
    "    margin = z * np.sqrt((phat * (1 - phat) + (z**2 / (4 * n))) / n)\n",
    "    lower = (centre - margin) / denominator\n",
    "    upper = (centre + margin) / denominator\n",
    "    return lower * 100, upper * 100\n",
    "\n",
    "# === Aangepaste overlap-functie: alleen vóór ventilator-onsets ===\n",
    "def compute_overlap_percent_prior_window(emg_peaks, vent_onsets, window):\n",
    "    count_overlap = 0\n",
    "    for t_emg in emg_peaks:\n",
    "        if np.any((vent_onsets - window <= t_emg) & (t_emg < vent_onsets)):\n",
    "            count_overlap += 1\n",
    "    percentage = (count_overlap / len(emg_peaks)) * 100 if len(emg_peaks) > 0 else 0\n",
    "    return count_overlap, percentage\n",
    "\n",
    "# === Analysefunctie ===\n",
    "def analyse_emg_vs_vent_overlap(patient_id, timepoint, window=0.3, confidence=0.95):\n",
    "    patient_id = int(patient_id)\n",
    "\n",
    "    emg_sub = emg_df[(emg_df[\"patient_id\"] == patient_id) & (emg_df[\"timepoint\"] == timepoint)]\n",
    "    vent_sub = vent_df[(vent_df[\"patient_id\"] == patient_id) & (vent_df[\"timepoint\"] == timepoint)]\n",
    "\n",
    "    true_peaks = emg_sub[emg_sub[\"label\"] == \"True peak\"]\n",
    "    t_dia = true_peaks[true_peaks[\"channel\"].str.contains(\"diaphragm\", case=False)][\"time_s\"].to_numpy()\n",
    "    t_int = true_peaks[true_peaks[\"channel\"].str.contains(\"parasternal\", case=False)][\"time_s\"].to_numpy()\n",
    "\n",
    "    t_onsets = vent_sub[\"time_end_in_mv\"].to_numpy()\n",
    "\n",
    "    overlap_dia, perc_dia = compute_overlap_percent_prior_window(t_dia, t_onsets, window)\n",
    "    ci_dia = wilson_ci(overlap_dia, len(t_dia), confidence)\n",
    "\n",
    "    overlap_int, perc_int = compute_overlap_percent_prior_window(t_int, t_onsets, window)\n",
    "    ci_int = wilson_ci(overlap_int, len(t_int), confidence)\n",
    "\n",
    "    print(f\" Overlapanalyse met ventilator-onsets (in {window}s vóór onset) patiënt {patient_id}, {timepoint}:\")\n",
    "    print(f\"- Diaphragm: {len(t_dia)} true peaks → {overlap_dia} overlap \"\n",
    "          f\"({perc_dia:.1f}%, 95% CI: {ci_dia[0]:.1f}% - {ci_dia[1]:.1f}%)\")\n",
    "    print(f\"- Parasternal: {len(t_int)} true peaks → {overlap_int} overlap \"\n",
    "          f\"({perc_int:.1f}%, 95% CI: {ci_int[0]:.1f}% - {ci_int[1]:.1f}%)\")\n",
    "\n",
    "    # === Visualisatie ===\n",
    "    labels = ['Diaphragm', 'Parasternal']\n",
    "    true_counts = [len(t_dia), len(t_int)]\n",
    "    overlaps = [overlap_dia, overlap_int]\n",
    "    percentages = [perc_dia, perc_int]\n",
    "    ci_lower = [perc - ci[0] for perc, ci in zip(percentages, [ci_dia, ci_int])]\n",
    "    ci_upper = [ci[1] - perc for perc, ci in zip(percentages, [ci_dia, ci_int])]\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    bars = plt.bar(labels, percentages, yerr=[ci_lower, ci_upper], capsize=6, color=[\"blue\", \"green\"])\n",
    "    plt.ylabel(\"Percentage EMG peak overlap with ventilator onset\")\n",
    "    plt.ylim(0, 110)\n",
    "    plt.title(f\"EMG peak ventilator onset overlap - patiënt {patient_id}, {timepoint}\")\n",
    "    plt.grid(axis=\"y\")\n",
    "\n",
    "    for bar, count, overlap in zip(bars, true_counts, overlaps):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 3,\n",
    "                 f\"{overlap}/{count}\", ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Uitvoeren ===\n",
    "analyse_emg_vs_vent_overlap(pid, tp, window, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASYNCHRONY ANALYSIS ALL MEASUREMENTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# === PARAMETERS ===\n",
    "window_pre = 0.7       # window before ventilator onset (sec)\n",
    "window_post = 0.3      # window after ventilator onset (sec)\n",
    "window_overlap = 0.8   # window used for overlap between EMG channels\n",
    "\n",
    "# === CUSTOM SORTING FUNCTIONS ===\n",
    "def patient_sort_key(pid):\n",
    "    try:\n",
    "        return int(pid)\n",
    "    except:\n",
    "        return float('inf')\n",
    "\n",
    "def timepoint_sort_key(tp):\n",
    "    \"\"\"\n",
    "    Expects timepoint strings formatted like 't0', 't1', 't24', 't1v2', etc.\n",
    "    Returns a tuple (time_value, version) where version defaults to 0 if not present.\n",
    "    \"\"\"\n",
    "    m = re.match(r\"t(\\d+)(?:v(\\d+))?\", tp)\n",
    "    if m:\n",
    "        t_val = int(m.group(1))\n",
    "        v_val = int(m.group(2)) if m.group(2) is not None else 0\n",
    "        return (t_val, v_val)\n",
    "    else:\n",
    "        return (float('inf'), 0)\n",
    "\n",
    "# === DATA LOADING ===\n",
    "# Load the two CSV files.\n",
    "emg_df = pd.read_csv(\"emg_peak_assessment_all_patients.csv\")\n",
    "vent_df = pd.read_csv(\"vent_breaths_output.csv\")  # from ventilator detection pipeline\n",
    "\n",
    "# Ensure consistent string types.\n",
    "emg_df[\"patient_id\"] = emg_df[\"patient_id\"].astype(str)\n",
    "emg_df[\"timepoint\"] = emg_df[\"timepoint\"].astype(str)\n",
    "vent_df[\"patient_id\"] = vent_df[\"Patient ID\"].astype(str)\n",
    "vent_df[\"timepoint\"] = vent_df[\"Time ID\"].astype(str)\n",
    "\n",
    "# Build a set of unique measurement pairs available in either dataset.\n",
    "measurements = set()\n",
    "for idx, row in vent_df.iterrows():\n",
    "    measurements.add( (row[\"patient_id\"], row[\"timepoint\"]) )\n",
    "for idx, row in emg_df.iterrows():\n",
    "    measurements.add( (row[\"patient_id\"], row[\"timepoint\"]) )\n",
    "# Now sort measurements by patient id (numerically) then by timepoint using our custom key.\n",
    "measurements = sorted(list(measurements), key=lambda x: (patient_sort_key(x[0]), timepoint_sort_key(x[1])))\n",
    "\n",
    "# === HELPER FUNCTIONS ===\n",
    "def is_in_any_window(t_e, vent_array, window_pre, window_post):\n",
    "    for t_v in vent_array:\n",
    "        if (t_e >= t_v - window_pre) and (t_e <= t_v + window_post):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def compute_overlap_effective(emg_peaks, vent_onsets, window_pre, window_post):\n",
    "    count = 0\n",
    "    for t in emg_peaks:\n",
    "        for v in vent_onsets:\n",
    "            if (t >= v - window_pre) and (t <= v + window_post):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def compute_overlap(ref, comp, win):\n",
    "    count = 0\n",
    "    for t in ref:\n",
    "        if np.any(np.abs(comp - t) <= win):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# === ANALYSIS ===\n",
    "results = []  # to store one record per measurement\n",
    "\n",
    "# Loop over each measurement in sorted order.\n",
    "for pid, tp in measurements:\n",
    "    # Subset data for this measurement from both CSVs.\n",
    "    emg_sub = emg_df[(emg_df[\"patient_id\"] == pid) & (emg_df[\"timepoint\"] == tp)]\n",
    "    vent_sub = vent_df[(vent_df[\"patient_id\"] == pid) & (vent_df[\"timepoint\"] == tp)]\n",
    "    if emg_sub.empty or vent_sub.empty:\n",
    "        continue\n",
    "\n",
    "    # Use only \"True peak\" rows for EMG.\n",
    "    true_emg = emg_sub[emg_sub[\"label\"] == \"True peak\"]\n",
    "    # Separate EMG channels by name.\n",
    "    t_dia = true_emg[true_emg[\"channel\"].str.contains(\"diaphragm\", case=False)][\"time_s\"].to_numpy()\n",
    "    t_int = true_emg[true_emg[\"channel\"].str.contains(\"parasternal\", case=False)][\"time_s\"].to_numpy()\n",
    "    t_dia_sorted = np.sort(t_dia)\n",
    "    t_int_sorted = np.sort(t_int)\n",
    "    \n",
    "    # Ventilator onsets.\n",
    "    t_vent = vent_sub[\"time_end_in_mv\"].to_numpy()\n",
    "    \n",
    "    # Initialize counts for triggered breaths.\n",
    "    true_triggers = 0\n",
    "    diaphragm_induced_triggers = 0\n",
    "    parasternal_induced_triggers = 0\n",
    "    auto_triggered = 0   # triggers not matched in originally triggered breaths\n",
    "    \n",
    "    # Initialize forced breath counts (for auto breaths).\n",
    "    forced_breath = 0                  # Forced Breath: no EMG peak on either channel\n",
    "    forced_breath_with_respiratory = 0 # with both diaphragm and parasternal activity\n",
    "    forced_breath_with_diaphragm = 0     # only diaphragm activity\n",
    "    forced_breath_with_parasternal = 0   # only parasternal activity\n",
    "\n",
    "    # Used flags for candidate assignment in triggered analysis.\n",
    "    used_dia = np.full(t_dia_sorted.shape, False)\n",
    "    used_int = np.full(t_int_sorted.shape, False)\n",
    "    \n",
    "    # Iterate over each ventilator onset.\n",
    "    for _, vent_row in vent_sub.iterrows():\n",
    "        t_v = vent_row[\"time_end_in_mv\"]\n",
    "        breath_type_orig = vent_row[\"Breath Type\"].strip()  # from vent_breaths_output.csv\n",
    "        window_start = t_v - window_pre\n",
    "        window_end = t_v + window_post\n",
    "\n",
    "        if breath_type_orig != \"Auto Breath\":\n",
    "            # For originally triggered breaths: assign EMG candidates\n",
    "            cand_dia_idx = np.where((t_dia_sorted >= window_start) & (t_dia_sorted <= window_end) & (~used_dia))[0]\n",
    "            cand_int_idx = np.where((t_int_sorted >= window_start) & (t_int_sorted <= window_end) & (~used_int))[0]\n",
    "            if cand_dia_idx.size > 0 and cand_int_idx.size > 0:\n",
    "                used_dia[cand_dia_idx[0]] = True\n",
    "                used_int[cand_int_idx[0]] = True\n",
    "                true_triggers += 1\n",
    "            elif cand_dia_idx.size > 0 and cand_int_idx.size == 0:\n",
    "                used_dia[cand_dia_idx[0]] = True\n",
    "                diaphragm_induced_triggers += 1\n",
    "            elif cand_int_idx.size > 0 and cand_dia_idx.size == 0:\n",
    "                used_int[cand_int_idx[0]] = True\n",
    "                parasternal_induced_triggers += 1\n",
    "            else:\n",
    "                auto_triggered += 1\n",
    "        else:\n",
    "            # For auto breaths: force the classification.\n",
    "            count_dia = np.sum((t_dia_sorted >= window_start) & (t_dia_sorted <= window_end))\n",
    "            count_int = np.sum((t_int_sorted >= window_start) & (t_int_sorted <= window_end))\n",
    "            if count_dia == 0 and count_int == 0:\n",
    "                forced_breath += 1\n",
    "            elif count_dia > 0 and count_int > 0:\n",
    "                forced_breath_with_respiratory += 1\n",
    "            elif count_dia > 0 and count_int == 0:\n",
    "                forced_breath_with_diaphragm += 1\n",
    "            elif count_dia == 0 and count_int > 0:\n",
    "                forced_breath_with_parasternal += 1\n",
    "\n",
    "    total_triggered = int(true_triggers + diaphragm_induced_triggers + parasternal_induced_triggers + auto_triggered)\n",
    "    total_forced = int(forced_breath + forced_breath_with_respiratory + forced_breath_with_diaphragm + forced_breath_with_parasternal)\n",
    "    \n",
    "    # --- WASTED EFFORTS ---\n",
    "    wasted_dia = 0\n",
    "    wasted_int = 0\n",
    "    wasted_both = 0\n",
    "    checked_times = set()\n",
    "    emg_all = np.union1d(t_dia, t_int)\n",
    "    for t_e in emg_all:\n",
    "        if any(np.isclose(t_e, list(checked_times), atol=0.01)):\n",
    "            continue\n",
    "        if not is_in_any_window(t_e, t_vent, window_pre, window_post):\n",
    "            found_dia = np.any(np.isclose(t_e, t_dia, atol=0.01))\n",
    "            found_int = np.any(np.isclose(t_e, t_int, atol=0.01))\n",
    "            if found_dia and not found_int:\n",
    "                wasted_dia += 1\n",
    "            elif found_int and not found_dia:\n",
    "                wasted_int += 1\n",
    "            elif found_dia and found_int:\n",
    "                wasted_both += 1\n",
    "        checked_times.add(t_e)\n",
    "    \n",
    "    # --- OVERLAPS ---\n",
    "    overlap_dia = compute_overlap_effective(t_dia, t_vent, window_pre, window_post)\n",
    "    overlap_int = compute_overlap_effective(t_int, t_vent, window_pre, window_post)\n",
    "    overlap_dia_vs_int = compute_overlap(t_dia, t_int, window_overlap)\n",
    "    overlap_int_vs_dia = compute_overlap(t_int, t_dia, window_overlap)\n",
    "    \n",
    "    # --- ASYNCHRONY INDEX ---\n",
    "    # Denom includes ventilator onsets plus wasted efforts.\n",
    "    asynchrony_index = (auto_triggered + wasted_both + wasted_dia + wasted_int) / (len(t_vent) + wasted_both + wasted_dia + wasted_int if len(t_vent) > 0 else 1)\n",
    "    \n",
    "    # Build the result record for this measurement.\n",
    "    res = {\n",
    "        \"patient_id\": pid,\n",
    "        \"timepoint\": tp,\n",
    "        \"vent_onsets\": len(t_vent),\n",
    "        \"n_diaphragm_true_peaks\": len(t_dia),\n",
    "        \"n_parasternal_true_peaks\": len(t_int),\n",
    "        \"true_triggers\": true_triggers,\n",
    "        \"diaphragm_induced_triggers\": diaphragm_induced_triggers,\n",
    "        \"parasternal_induced_triggers\": parasternal_induced_triggers,\n",
    "        \"auto_triggers\": auto_triggered,\n",
    "        \"forced_breath\": forced_breath,\n",
    "        \"forced_breath_with_respiratory\": forced_breath_with_respiratory,\n",
    "        \"forced_breath_with_diaphragm\": forced_breath_with_diaphragm,\n",
    "        \"forced_breath_with_parasternal\": forced_breath_with_parasternal,\n",
    "        \"wasted_effort_both\": wasted_both,\n",
    "        \"wasted_effort_diaphragm\": wasted_dia,\n",
    "        \"wasted_effort_parasternal\": wasted_int,\n",
    "        \"overlap_diaphragm\": overlap_dia,\n",
    "        \"overlap_parasternal\": overlap_int,\n",
    "        \"dia_int_overlap\": overlap_dia_vs_int,\n",
    "        \"int_dia_overlap\": overlap_int_vs_dia,\n",
    "        \"asynchrony_index\": asynchrony_index\n",
    "    }\n",
    "    results.append(res)\n",
    "\n",
    "# Convert results to a DataFrame, then sort it by patient id and timepoint.\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(\n",
    "    by=[\"patient_id\", \"timepoint\"],\n",
    "    key=lambda col: col.map(lambda x: patient_sort_key(x) if col.name == \"patient_id\" else timepoint_sort_key(x) if col.name == \"timepoint\" else x)\n",
    ")\n",
    "results_df.to_csv(\"asynchrony_analysis_updated.csv\", index=False)\n",
    "print(\"Per-measurement output saved as asynchrony_analysis_updated.csv\")\n",
    "\n",
    "# === PRINT SUMMARY PER MEASUREMENT IN DESIRED ORDER ===\n",
    "for _, row in results_df.iterrows():\n",
    "    forced_simple = int(row[\"forced_breath\"])\n",
    "    forced_resp = int(row[\"forced_breath_with_respiratory\"])\n",
    "    forced_dia = int(row[\"forced_breath_with_diaphragm\"])\n",
    "    forced_int = int(row[\"forced_breath_with_parasternal\"])\n",
    "    total_forced = forced_simple + forced_resp + forced_dia + forced_int\n",
    "    total_triggered = int(row[\"true_triggers\"] + row[\"diaphragm_induced_triggers\"] + row[\"parasternal_induced_triggers\"] + row[\"auto_triggers\"])\n",
    "    \n",
    "    print(f\"\\nAnalysis for patient {row['patient_id']}, timepoint {row['timepoint']}:\")\n",
    "    print(f\"- Number of ventilator-onsets: {row['vent_onsets']}\")\n",
    "    print(f\"- Number of diaphragm true peaks: {row['n_diaphragm_true_peaks']}\")\n",
    "    print(f\"- Number of parasternal true peaks: {row['n_parasternal_true_peaks']}\")\n",
    "    print(f\"- Forced breaths (total): {total_forced} ({100*total_forced/row['vent_onsets']:.2f}%)\")\n",
    "    print(f\"    True Forced Breath: {forced_simple} \")\n",
    "    print(f\"    Forced Breath with Total Respiratory activity: {forced_resp} \")\n",
    "    print(f\"    Forced Breath with Diaphragm activity: {forced_dia} \")\n",
    "    print(f\"    Forced Breath with Parasternal activity: {forced_int} \")\n",
    "    print(f\"- Triggered breaths (total): {total_triggered} ({100*total_triggered/row['vent_onsets']:.2f}%)\")\n",
    "    print(f\"    Auto-Triggers {row['auto_triggers']}\")\n",
    "    print(f\"    True Triggers: {row['true_triggers']}\")\n",
    "    print(f\"    Parasternal Induced Triggers: {row['parasternal_induced_triggers']}\")\n",
    "    print(f\"    Diaphragm Induced Triggers: {row['diaphragm_induced_triggers']}\")\n",
    "    print(f\"- Complete Wasted Effort (both EMG, no vent): {row['wasted_effort_both']}\")\n",
    "    print(f\"- Wasted Effort Diaphragm: {row['wasted_effort_diaphragm']}\")\n",
    "    print(f\"- Wasted Effort Parasternal: {row['wasted_effort_parasternal']}\")\n",
    "    print(f\"- Overlap diaphragm ↔ vent: {row['overlap_diaphragm']}/{row['n_diaphragm_true_peaks']}\")\n",
    "    print(f\"- Overlap parasternal ↔ vent: {row['overlap_parasternal']}/{row['n_parasternal_true_peaks']}\")\n",
    "    print(f\"- Overlap diaphragm ↔ parasternal: {row['dia_int_overlap']}/{row['n_diaphragm_true_peaks']}\")\n",
    "    print(f\"- Overlap parasternal ↔ diaphragm: {row['int_dia_overlap']}/{row['n_parasternal_true_peaks']}\")\n",
    "    print(f\"- Asynchrony Index: {row['asynchrony_index']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---- Part 1: Load classification & select included measurements ----\n",
    "msr_df = pd.read_csv(\"measurement_classification.csv\")\n",
    "# Construct a key as \"PatientID_TimeID\"\n",
    "msr_df[\"key\"] = msr_df[\"Patient ID\"].astype(str).str.strip() + \"_\" + msr_df[\"Time ID\"].astype(str).str.strip()\n",
    "# Keep only measurements labeled as \"Include\"\n",
    "included_keys = set(msr_df[msr_df[\"Label\"] == \"Include\"][\"key\"].unique())\n",
    "\n",
    "# ---- Part 2: Load EMG peak assessment data and filter for true peaks from included measurements ----\n",
    "peaks_df = pd.read_csv(\"emg_peak_assessment_all_patients.csv\")\n",
    "# Construct same key from patient_id and timepoint\n",
    "peaks_df[\"key\"] = peaks_df[\"patient_id\"].astype(str).str.strip() + \"_\" + peaks_df[\"timepoint\"].astype(str).str.strip()\n",
    "# Filter: only true peaks and only from included measurements\n",
    "true_peaks = peaks_df[(peaks_df[\"label\"] == \"True peak\") & (peaks_df[\"key\"].isin(included_keys))].copy()\n",
    "\n",
    "# ---- Part 3: Compute overlap counts using a 0.8-second window for each measurement ----\n",
    "window = 0.8  # seconds\n",
    "\n",
    "# We'll accumulate overall counts.\n",
    "total_dia = 0\n",
    "total_para = 0\n",
    "overlap_dia = 0\n",
    "overlap_para = 0\n",
    "\n",
    "# Group by measurement key.\n",
    "grouped = true_peaks.groupby(\"key\")\n",
    "for key, group in grouped:\n",
    "    # Extract peak times for each channel; assume channel names are case-insensitive.\n",
    "    dia_times = group[group[\"channel\"].str.lower() == \"diaphragm\"][\"time_s\"].values\n",
    "    para_times = group[group[\"channel\"].str.lower() == \"parasternal\"][\"time_s\"].values\n",
    "\n",
    "    n_dia = len(dia_times)\n",
    "    n_para = len(para_times)\n",
    "    total_dia += n_dia\n",
    "    total_para += n_para\n",
    "\n",
    "    # For each diaphragm peak, count if there's any parasternal peak within the window.\n",
    "    cnt_dia = sum(any(abs(d - p) <= window for p in para_times) for d in dia_times)\n",
    "    # For each parasternal peak, count if there's any diaphragm peak within the window.\n",
    "    cnt_para = sum(any(abs(p - d) <= window for d in dia_times) for p in para_times)\n",
    "\n",
    "    overlap_dia += cnt_dia\n",
    "    overlap_para += cnt_para\n",
    "\n",
    "# To force symmetry, take the average of the two overlap counts.\n",
    "common_overlap = (overlap_dia + overlap_para) / 2\n",
    "\n",
    "# Compute overlap percentages per channel.\n",
    "perc_dia = (common_overlap / total_dia * 100) if total_dia > 0 else 0\n",
    "perc_para = (common_overlap / total_para * 100) if total_para > 0 else 0\n",
    "\n",
    "# ---- Part 4: Print results in the requested format ----\n",
    "print(\"Diaphragm with Parasternal:\")\n",
    "print(f\"  Total diaphragm true peaks: {total_dia}\")\n",
    "print(f\"  Overlap (diaphragm with parasternal): {int(common_overlap)} ({perc_dia:.1f}%)\\n\")\n",
    "\n",
    "print(\"Parasternal with Diaphragm:\")\n",
    "print(f\"  Total parasternal true peaks: {total_para}\")\n",
    "print(f\"  Overlap (parasternal with diaphragm): {int(common_overlap)} ({perc_para:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASYNCHRONY SUMMARY ALL MEASUREMENTS\n",
    "import pandas as pd\n",
    "\n",
    "# Load the asynchrony analysis CSV file.\n",
    "df = pd.read_csv(\"asynchrony_analysis_updated.csv\")\n",
    "\n",
    "# List of fields to sum.\n",
    "sum_fields = [\n",
    "    \"vent_onsets\",\n",
    "    \"n_diaphragm_true_peaks\",\n",
    "    \"n_parasternal_true_peaks\",\n",
    "    \"true_triggers\",\n",
    "    \"diaphragm_induced_triggers\",\n",
    "    \"parasternal_induced_triggers\",\n",
    "    \"auto_triggers\",\n",
    "    \"forced_breath\",\n",
    "    \"forced_breath_with_respiratory\",\n",
    "    \"forced_breath_with_diaphragm\",\n",
    "    \"forced_breath_with_parasternal\",\n",
    "    \"wasted_effort_both\",\n",
    "    \"wasted_effort_diaphragm\",\n",
    "    \"wasted_effort_parasternal\",\n",
    "    \"overlap_diaphragm\",\n",
    "    \"overlap_parasternal\",\n",
    "    \"dia_int_overlap\",\n",
    "    \"int_dia_overlap\"\n",
    "]\n",
    "\n",
    "# Compute totals for each field.\n",
    "totals = {field: df[field].sum() for field in sum_fields}\n",
    "\n",
    "# Get total ventilator onsets.\n",
    "vent_onsets = totals[\"vent_onsets\"]\n",
    "\n",
    "# Total wasted efforts is the sum of the different wasted effort fields.\n",
    "total_wasted = totals[\"wasted_effort_both\"] + totals[\"wasted_effort_diaphragm\"] + totals[\"wasted_effort_parasternal\"]\n",
    "\n",
    "# Total breaths is defined as ventilator onsets plus wasted efforts.\n",
    "total_breaths = vent_onsets + total_wasted\n",
    "\n",
    "# Total triggered breaths.\n",
    "total_triggered = int(\n",
    "    totals[\"true_triggers\"] +\n",
    "    totals[\"diaphragm_induced_triggers\"] +\n",
    "    totals[\"parasternal_induced_triggers\"] +\n",
    "    totals[\"auto_triggers\"]\n",
    ")\n",
    "\n",
    "# Total forced breaths.\n",
    "total_forced = int(\n",
    "    totals[\"forced_breath\"] +\n",
    "    totals[\"forced_breath_with_respiratory\"] +\n",
    "    totals[\"forced_breath_with_diaphragm\"] +\n",
    "    totals[\"forced_breath_with_parasternal\"]\n",
    ")\n",
    "\n",
    "# Calculate percentages relative to total breaths.\n",
    "pct_triggered_total = 100 * total_triggered / total_breaths if total_breaths > 0 else 0\n",
    "pct_forced_total    = 100 * total_forced / total_breaths if total_breaths > 0 else 0\n",
    "pct_wasted_total    = 100 * total_wasted / total_breaths if total_breaths > 0 else 0\n",
    "\n",
    "# Also, calculate percentages relative to ventilator onsets.\n",
    "pct_triggered_vent = 100 * total_triggered / vent_onsets if vent_onsets > 0 else 0\n",
    "pct_forced_vent    = 100 * total_forced / vent_onsets if vent_onsets > 0 else 0\n",
    "pct_wasted_vent    = 100 * total_wasted / vent_onsets if vent_onsets > 0 else 0\n",
    "\n",
    "# Compute the mean asynchrony index.\n",
    "mean_asynchrony_index = df[\"asynchrony_index\"].mean()\n",
    "\n",
    "# --- PRINT THE OVERALL SUMMARY ---\n",
    "print(\"Overall Summary of Asynchrony Analysis:\")\n",
    "print(\"----------------------------------------\")\n",
    "print(f\"Total breaths (ventilator onsets + wasted efforts): {total_breaths}\")\n",
    "print(f\"Number of ventilator-onsets: {vent_onsets}\")\n",
    "print(f\"Number of diaphragm true peaks: {totals['n_diaphragm_true_peaks']}\")\n",
    "print(f\"Number of parasternal true peaks: {totals['n_parasternal_true_peaks']}\")\n",
    "print(f\" -Total Triggered Breaths: {total_triggered} ({pct_triggered_total:.2f}% of total breaths, {pct_triggered_vent:.2f}% of ventilator onsets)\")\n",
    "print(f\"     True triggers: {totals['true_triggers']}\")\n",
    "print(f\"     Auto-Triggers: {totals['auto_triggers']}\")\n",
    "print(f\"     Diaphragm induced triggers: {totals['diaphragm_induced_triggers']}\")\n",
    "print(f\"     Parasternal induced triggers: {totals['parasternal_induced_triggers']}\")\n",
    "print(f\" -Total Forced Breaths: {total_forced} ({pct_forced_total:.2f}% of total breaths, {pct_forced_vent:.2f}% of ventilator onsets)\")\n",
    "print(f\"     True Forced Breath: {totals['forced_breath']}\")\n",
    "print(f\"     Forced Breath with Respiratory activity: {totals['forced_breath_with_respiratory']}\")\n",
    "print(f\"     Forced Breath with Diaphragm activity: {totals['forced_breath_with_diaphragm']}\")\n",
    "print(f\"     Forced Breath with Parasternal activity: {totals['forced_breath_with_parasternal']}\")\n",
    "print(f\" -Total Wasted Efforts: {total_wasted} ({pct_wasted_total:.2f}% of total breaths)\")\n",
    "print(f\"     Complete Wasted Effort (both EMG, no vent): {totals['wasted_effort_both']}\")\n",
    "print(f\"     Wasted Effort Diaphragm: {totals['wasted_effort_diaphragm']}\")\n",
    "print(f\"     Wasted Effort Parasternal: {totals['wasted_effort_parasternal']}\")\n",
    "\n",
    "print(f\"Overlap diaphragm ↔ vent: {totals['overlap_diaphragm']}/{totals['n_diaphragm_true_peaks']}\")\n",
    "print(f\"Overlap parasternal ↔ vent: {totals['overlap_parasternal']}/{totals['n_parasternal_true_peaks']}\")\n",
    "print(f\"Overlap diaphragm ↔ parasternal: {totals['dia_int_overlap']}/{totals['n_diaphragm_true_peaks']}\")\n",
    "print(f\"Overlap parasternal ↔ diaphragm: {totals['int_dia_overlap']}/{totals['n_parasternal_true_peaks']}\")\n",
    "print(f\"Mean asynchrony index: {mean_asynchrony_index:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASYNCHRONY ANALYSIS INCLUDED MEASUREMENTS\n",
    "import pandas as pd\n",
    "\n",
    "# --- LOAD THE QUALITY CHECK FILE ---\n",
    "inc_df = pd.read_csv(\"measurement_classification.csv\")\n",
    "# We'll assume that the included_measurements.csv file has columns \"Patient ID\", \"Time ID\", \"Label\", \"Reasons\"\n",
    "# Filter to keep only included measurements:\n",
    "#inc_df = inc_df[inc_df[\"Label\"].str.strip().str.lower() == \"include\"]\n",
    "\n",
    "# Filter to keep only subanalysis measurements:\n",
    "inc_df = inc_df[inc_df[\"Label\"].str.strip().str.lower() == \"subanalysis\"] #!!!aanpassen voor subanalysis\n",
    "\n",
    "# Build a set of keys (patient, timepoint) from the quality-check file.\n",
    "# Convert the values to strings and then strip extra whitespace.\n",
    "included_keys = set()\n",
    "for idx, row in inc_df.iterrows():\n",
    "    pid = str(row[\"Patient ID\"]).strip()\n",
    "    tp = str(row[\"Time ID\"]).strip()\n",
    "    included_keys.add((pid, tp))\n",
    "\n",
    "# --- LOAD THE ASYNCHRONY ANALYSIS CSV ---\n",
    "df = pd.read_csv(\"asynchrony_analysis_updated.csv\")\n",
    "# Ensure consistency by stripping whitespace.\n",
    "df[\"patient_id\"] = df[\"patient_id\"].astype(str).str.strip()\n",
    "df[\"timepoint\"] = df[\"timepoint\"].astype(str).str.strip()\n",
    "\n",
    "# Filter to include only those rows whose (patient_id, timepoint) key is in included_keys.\n",
    "df_inc = df[df.apply(lambda row: (row[\"patient_id\"], row[\"timepoint\"]) in included_keys, axis=1)]\n",
    "\n",
    "# --- PRINT HOW MANY PATIENTS and MEASUREMENTS ARE INCLUDED ---\n",
    "unique_patients = df_inc[\"patient_id\"].nunique()\n",
    "total_measurements = len(df_inc)\n",
    "print(f\"Summary is performed on {unique_patients} patients and {total_measurements} measurements.\")\n",
    "\n",
    "# --- SUMMARIZATION SCRIPT (for included measurements) ---\n",
    "\n",
    "# Define the list of fields to sum.\n",
    "sum_fields = [\n",
    "    \"vent_onsets\",\n",
    "    \"n_diaphragm_true_peaks\",\n",
    "    \"n_parasternal_true_peaks\",\n",
    "    \"true_triggers\",\n",
    "    \"diaphragm_induced_triggers\",\n",
    "    \"parasternal_induced_triggers\",\n",
    "    \"auto_triggers\",\n",
    "    \"forced_breath\",\n",
    "    \"forced_breath_with_respiratory\",\n",
    "    \"forced_breath_with_diaphragm\",\n",
    "    \"forced_breath_with_parasternal\",\n",
    "    \"wasted_effort_both\",\n",
    "    \"wasted_effort_diaphragm\",\n",
    "    \"wasted_effort_parasternal\",\n",
    "    \"overlap_diaphragm\",\n",
    "    \"overlap_parasternal\",\n",
    "    \"dia_int_overlap\",\n",
    "    \"int_dia_overlap\"\n",
    "]\n",
    "\n",
    "# Compute totals for each field over the included measurements.\n",
    "totals = {field: df_inc[field].sum() for field in sum_fields}\n",
    "\n",
    "# Get total ventilator onsets.\n",
    "vent_onsets = totals[\"vent_onsets\"]\n",
    "\n",
    "# Total wasted efforts is the sum of wasted_effort_both, wasted_effort_diaphragm, and wasted_effort_parasternal.\n",
    "total_wasted = totals[\"wasted_effort_both\"] + totals[\"wasted_effort_diaphragm\"] + totals[\"wasted_effort_parasternal\"]\n",
    "\n",
    "# Total breaths is defined as ventilator onsets plus wasted efforts.\n",
    "total_breaths = vent_onsets + total_wasted\n",
    "\n",
    "# Total triggered breaths.\n",
    "total_triggered = int(\n",
    "    totals[\"true_triggers\"] +\n",
    "    totals[\"diaphragm_induced_triggers\"] +\n",
    "    totals[\"parasternal_induced_triggers\"] +\n",
    "    totals[\"auto_triggers\"]\n",
    ")\n",
    "\n",
    "# Total forced breaths.\n",
    "total_forced = int(\n",
    "    totals[\"forced_breath\"] +\n",
    "    totals[\"forced_breath_with_respiratory\"] +\n",
    "    totals[\"forced_breath_with_diaphragm\"] +\n",
    "    totals[\"forced_breath_with_parasternal\"]\n",
    ")\n",
    "\n",
    "# Calculate percentages relative to total breaths.\n",
    "pct_triggered_total = 100 * total_triggered / total_breaths if total_breaths > 0 else 0\n",
    "pct_forced_total    = 100 * total_forced / total_breaths if total_breaths > 0 else 0\n",
    "pct_wasted_total    = 100 * total_wasted / total_breaths if total_breaths > 0 else 0\n",
    "\n",
    "# Also, calculate percentages relative to ventilator onsets.\n",
    "pct_triggered_vent = 100 * total_triggered / vent_onsets if vent_onsets > 0 else 0\n",
    "pct_forced_vent    = 100 * total_forced / vent_onsets if vent_onsets > 0 else 0\n",
    "pct_wasted_vent    = 100 * total_wasted / vent_onsets if vent_onsets > 0 else 0\n",
    "\n",
    "# Compute the mean asynchrony index.\n",
    "mean_asynchrony_index = df_inc[\"asynchrony_index\"].mean()\n",
    "\n",
    "# --- PRINT THE OVERALL SUMMARY ---\n",
    "print(\"\\nOverall Summary of Asynchrony Analysis (Included Measurements):\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(f\"Total breaths (ventilator onsets + wasted efforts): {total_breaths}\")\n",
    "print(f\"Number of ventilator-onsets: {vent_onsets}\")\n",
    "print(f\"Number of diaphragm true peaks: {totals['n_diaphragm_true_peaks']}\")\n",
    "print(f\"Number of parasternal true peaks: {totals['n_parasternal_true_peaks']}\")\n",
    "print(f\"  - Total Triggered Breaths: {total_triggered} ({pct_triggered_total:.2f}% of total breaths, {pct_triggered_vent:.2f}% of ventilator onsets)\")\n",
    "print(f\"      True triggers: {totals['true_triggers']}\")\n",
    "print(f\"      Auto-Triggers: {totals['auto_triggers']}\")\n",
    "print(f\"      Diaphragm induced triggers: {totals['diaphragm_induced_triggers']}\")\n",
    "print(f\"      Parasternal induced triggers: {totals['parasternal_induced_triggers']}\")\n",
    "print(f\"  - Total Forced Breaths: {total_forced} ({pct_forced_total:.2f}% of total breaths, {pct_forced_vent:.2f}% of ventilator onsets)\")\n",
    "print(f\"      True Forced Breath: {totals['forced_breath']}\")\n",
    "print(f\"      Forced Breath with Parasternal and Diaphragm activity: {totals['forced_breath_with_respiratory']}\")\n",
    "print(f\"      Forced Breath with Diaphragm activity: {totals['forced_breath_with_diaphragm']}\")\n",
    "print(f\"      Forced Breath with Parasternal activity: {totals['forced_breath_with_parasternal']}\")\n",
    "print(f\"  - Total Wasted Efforts: {total_wasted} ({pct_wasted_total:.2f}% of total breaths)\")\n",
    "print(f\"      Complete Wasted Effort (both EMG, no vent): {totals['wasted_effort_both']}\")\n",
    "print(f\"      Wasted Effort Diaphragm: {totals['wasted_effort_diaphragm']}\")\n",
    "print(f\"      Wasted Effort Parasternal: {totals['wasted_effort_parasternal']}\")\n",
    "print(f\"Overlap diaphragm ↔ ventilator: {totals['overlap_diaphragm']}/{totals['n_diaphragm_true_peaks']}\")\n",
    "print(f\"Overlap parasternal ↔ ventilator: {totals['overlap_parasternal']}/{totals['n_parasternal_true_peaks']}\")\n",
    "print(f\"Overlap diaphragm ↔ parasternal: {totals['dia_int_overlap']}/{totals['n_diaphragm_true_peaks']}\")\n",
    "print(f\"Overlap parasternal ↔ diaphragm: {totals['int_dia_overlap']}/{totals['n_parasternal_true_peaks']}\")\n",
    "print(f\"Mean asynchrony index: {mean_asynchrony_index:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASYNCHRONY ANALYSIS MEASUREMENTS LABELED SUBANALYSIS\n",
    "import pandas as pd\n",
    "\n",
    "# ---------------------------\n",
    "# Part 1: Load measurement classification and filter for Subanalysis measurements\n",
    "# ---------------------------\n",
    "class_df = pd.read_csv(\"measurement_classification.csv\")\n",
    "# Keep only measurements with Label equal to \"Subanalysis\" (case-insensitive)\n",
    "class_df = class_df[class_df[\"Label\"].str.strip().str.lower() == \"subanalysis\"]\n",
    "\n",
    "# Create a key for each measurement as \"PatientID_TimeID\"\n",
    "class_df[\"key\"] = class_df[\"Patient ID\"].astype(str).str.strip() + \"_\" + class_df[\"Time ID\"].astype(str).str.strip()\n",
    "\n",
    "# Determine the usable lead from the Reason.\n",
    "# If Reason contains \"no respiratory activity parasternal\" or \"motion artefacts parasternal\" => use diaphragm.\n",
    "# If Reason contains \"no respiratory activity diaphragm\" or \"motion artefacts diaphragm\" => use parasternal.\n",
    "def determine_usable_lead(reason):\n",
    "    r = reason.lower()\n",
    "    if \"no respiratory activity parasternal\" in r or \"motion artefacts parasternal\" in r:\n",
    "        return \"diaphragm\"\n",
    "    elif \"no respiratory activity diaphragm\" in r or \"motion artefacts diaphragm\" in r:\n",
    "        return \"parasternal\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "class_df[\"usable_lead\"] = class_df[\"Reason\"].apply(determine_usable_lead)\n",
    "\n",
    "# Build the set of keys from subanalysis measurements.\n",
    "subanalysis_keys = set(class_df[\"key\"].unique())\n",
    "\n",
    "# ---------------------------\n",
    "# Part 2: Load asynchrony analysis data and filter to subanalysis measurements\n",
    "# ---------------------------\n",
    "ana_df = pd.read_csv(\"asynchrony_analysis_updated.csv\")\n",
    "# Create the same key from the asynchrony analysis data.\n",
    "ana_df[\"key\"] = ana_df[\"patient_id\"].astype(str).str.strip() + \"_\" + ana_df[\"timepoint\"].astype(str).str.strip()\n",
    "# Filter to only measurements in subanalysis.\n",
    "subana_df = ana_df[ana_df[\"key\"].isin(subanalysis_keys)].copy()\n",
    "\n",
    "# Merge the usable lead information from classification into the asynchrony analysis data.\n",
    "merged_df = pd.merge(subana_df, class_df[[\"key\", \"usable_lead\"]], on=\"key\", how=\"left\")\n",
    "\n",
    "# ---------------------------\n",
    "# Part 3: Split into two groups based on usable lead\n",
    "# ---------------------------\n",
    "# Group A: If usable_lead is \"diaphragm\", then use diaphragm metrics.\n",
    "group_diaphragm = merged_df[merged_df[\"usable_lead\"] == \"diaphragm\"]\n",
    "\n",
    "# Group B: If usable_lead is \"parasternal\", then use parasternal metrics.\n",
    "group_parasternal = merged_df[merged_df[\"usable_lead\"] == \"parasternal\"]\n",
    "\n",
    "# ---------------------------\n",
    "# Part 4: Compute summary metrics for each group\n",
    "# ---------------------------\n",
    "# For group_diaphragm, using diaphragm metrics.\n",
    "fields_diaphragm = [\n",
    "    \"wasted_effort_diaphragm\",\n",
    "    \"diaphragm_induced_triggers\",\n",
    "    \"auto_triggers\",\n",
    "    \"forced_breath\",\n",
    "    \"forced_breath_with_diaphragm\",\n",
    "    \"n_diaphragm_true_peaks\",\n",
    "    \"vent_onsets\"\n",
    "]\n",
    "sums_diaphragm = { field: group_diaphragm[field].sum() for field in fields_diaphragm }\n",
    "total_breaths_diaphragm = sums_diaphragm[\"vent_onsets\"] + sums_diaphragm[\"wasted_effort_diaphragm\"]\n",
    "\n",
    "# For group_parasternal, using parasternal metrics.\n",
    "fields_parasternal = [\n",
    "    \"wasted_effort_parasternal\",\n",
    "    \"parasternal_induced_triggers\",\n",
    "    \"auto_triggers\",\n",
    "    \"forced_breath\",\n",
    "    \"forced_breath_with_parasternal\",\n",
    "    \"n_parasternal_true_peaks\",\n",
    "    \"vent_onsets\"\n",
    "]\n",
    "sums_parasternal = { field: group_parasternal[field].sum() for field in fields_parasternal }\n",
    "total_breaths_parasternal = sums_parasternal[\"vent_onsets\"] + sums_parasternal[\"wasted_effort_parasternal\"]\n",
    "\n",
    "# Calculate percentages relative to ventilator onsets.\n",
    "pct_triggers_diaphragm = (100 * sums_diaphragm[\"diaphragm_induced_triggers\"] / sums_diaphragm[\"vent_onsets\"]) if sums_diaphragm[\"vent_onsets\"] > 0 else 0\n",
    "pct_wasted_diaphragm = (100 * sums_diaphragm[\"wasted_effort_diaphragm\"] / total_breaths_diaphragm) if total_breaths_diaphragm > 0 else 0\n",
    "\n",
    "pct_triggers_parasternal = (100 * sums_parasternal[\"parasternal_induced_triggers\"] / sums_parasternal[\"vent_onsets\"]) if sums_parasternal[\"vent_onsets\"] > 0 else 0\n",
    "pct_wasted_parasternal = (100 * sums_parasternal[\"wasted_effort_parasternal\"] / total_breaths_parasternal) if total_breaths_parasternal > 0 else 0\n",
    "\n",
    "# ---------------------------\n",
    "# Part 5: Print the two separate asynchrony analysis summaries along with counts.\n",
    "# ---------------------------\n",
    "# For group_diaphragm (using diaphragm metrics)\n",
    "num_meas_diaphragm = len(group_diaphragm)\n",
    "num_patients_diaphragm = group_diaphragm[\"patient_id\"].nunique()\n",
    "\n",
    "print(\"\\n=== Diaphragm Asynchrony Analysis (using diaphragm metrics) ===\")\n",
    "print(f\"Measurements included: {num_meas_diaphragm}\")\n",
    "print(f\"Unique patients: {num_patients_diaphragm}\")\n",
    "print(f\"Total breaths(ventilator onset + wasted efforts): {total_breaths_diaphragm}\")\n",
    "print(f\"Number of ventilator-onsets: {sums_diaphragm['vent_onsets']}\")\n",
    "print(f\"Number of diaphragm true peaks: {sums_diaphragm['n_diaphragm_true_peaks']}\")\n",
    "print(f\"Wasted Effort Diaphragm: {sums_diaphragm['wasted_effort_diaphragm']} ({pct_wasted_diaphragm:.2f}% of total breaths)\")\n",
    "print(f\"Diaphragm induced triggers: {sums_diaphragm['diaphragm_induced_triggers']} ({pct_triggers_diaphragm:.2f}% of ventilator onsets)\")\n",
    "print(f\"Auto triggers: {sums_diaphragm['auto_triggers']}\")\n",
    "print(f\"True forced breath: {sums_diaphragm['forced_breath']}\")\n",
    "print(f\"Forced Breath with Diaphragm activity: {sums_diaphragm['forced_breath_with_diaphragm']}\")\n",
    "\n",
    "\n",
    "\n",
    "# For group_parasternal (using parasternal metrics)\n",
    "num_meas_parasternal = len(group_parasternal)\n",
    "num_patients_parasternal = group_parasternal[\"patient_id\"].nunique()\n",
    "\n",
    "print(\"\\n=== Parasternal Asynchrony Analysis (using parasternal metrics) ===\")\n",
    "print(f\"Measurements included: {num_meas_parasternal}\")\n",
    "print(f\"Unique patients: {num_patients_parasternal}\")\n",
    "print(f\"Total breaths(ventilator onsets + wasted efforts): {total_breaths_parasternal}\")\n",
    "print(f\"Number of ventilator-onsets: {sums_parasternal['vent_onsets']}\")\n",
    "print(f\"Number of parasternal true peaks: {sums_parasternal['n_parasternal_true_peaks']}\")\n",
    "print(f\"Wasted Effort Parasternal: {sums_parasternal['wasted_effort_parasternal']} ({pct_wasted_parasternal:.2f}% of total breaths)\")\n",
    "print(f\"Parasternal induced triggers: {sums_parasternal['parasternal_induced_triggers']} ({pct_triggers_parasternal:.2f}% of ventilator onsets)\")\n",
    "print(f\"Auto triggers: {sums_parasternal['auto_triggers']}\")\n",
    "print(f\"True forced breath: {sums_parasternal['forced_breath']}\")\n",
    "print(f\"Forced Breath with Parasternal activity: {sums_parasternal['forced_breath_with_parasternal']}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STATISTICAL ANALYSIS ALL PATIENTS\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest\n",
    "\n",
    "# === Bestand inladen ===\n",
    "df = pd.read_csv(\"breathing_sync_summary_all_patients.csv\")\n",
    "\n",
    "# === Container voor resultaten ===\n",
    "significance_results = []\n",
    "\n",
    "# === Itereer over elke rij en toets of overlap significant is ===\n",
    "for _, row in df.iterrows():\n",
    "    n_dia = row[\"n_diaphragm_true_peaks\"]\n",
    "    overlap = row[\"overlap_diaphragm_vs_parasternal\"]\n",
    "\n",
    "    if n_dia == 0:\n",
    "        p_value = None\n",
    "        significant = None\n",
    "    else:\n",
    "        # Binomiale toets: H0 = overlap toevalskans 0.5\n",
    "        p_value = binomtest(overlap, n=n_dia, p=0.5, alternative=\"greater\").pvalue\n",
    "        significant = p_value < 0.05\n",
    "\n",
    "    significance_results.append({\n",
    "        \"patient_id\": row[\"patient_id\"],\n",
    "        \"timepoint\": row[\"timepoint\"],\n",
    "        \"n_diaphragm_true_peaks\": n_dia,\n",
    "        \"overlap_with_parasternal\": overlap,\n",
    "        \"overlap_percentage\": round((overlap / n_dia * 100) if n_dia else 0, 1),\n",
    "        \"p_value\": p_value,\n",
    "        \"significant\": significant\n",
    "    })\n",
    "\n",
    "# === Resultaten tonen ===\n",
    "sig_df = pd.DataFrame(significance_results)\n",
    "sig_df = sig_df.sort_values(by=[\"patient_id\", \"timepoint\"])\n",
    "print(sig_df)\n",
    "\n",
    "# === Optioneel: opslaan ===\n",
    "sig_df.to_csv(\"significance_overlap_diaphragm_vs_parasternal.csv\", index=False)\n",
    "print(\"\\n✅ Results stored in 'significance_overlap_diaphragm_vs_parasternal.csv'\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === CSV-bestand inladen ===\n",
    "df = pd.read_csv(\"significance_overlap_diaphragm_vs_parasternal.csv\")\n",
    "\n",
    "# === Pivot tabellen maken ===\n",
    "pivot_vals = df.pivot(index=\"patient_id\", columns=\"timepoint\", values=\"overlap_percentage\")\n",
    "pivot_sig = df.pivot(index=\"patient_id\", columns=\"timepoint\", values=\"significant\")\n",
    "\n",
    "# === Heatmap tekenen ===\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.heatmap(pivot_vals, annot=True, fmt=\".1f\", cmap=\"YlGnBu\",\n",
    "                 linewidths=0.5, linecolor='gray', cbar_kws={\"label\": \"Overlap (%)\"})\n",
    "\n",
    "# === Randen tekenen voor significantie ===\n",
    "for y in range(pivot_vals.shape[0]):\n",
    "    for x in range(pivot_vals.shape[1]):\n",
    "        is_sig = pivot_sig.iloc[y, x]\n",
    "        if pd.notna(is_sig) and is_sig:\n",
    "            ax.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "\n",
    "# === Opmaak ===\n",
    "plt.title(\"Overlap diaphragm ↔ parasternal EMG-peaks (significant results marked red)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Patient ID\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTISCHE TOETS: parasternal overlap met diaphragm\n",
    "import pandas as pd\n",
    "from scipy.stats import binomtest\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Data inladen ===\n",
    "df = pd.read_csv(\"breathing_sync_summary_all_patients.csv\")\n",
    "\n",
    "# === Resultaten verzamelen ===\n",
    "results = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    n_int = row[\"n_parasternal_true_peaks\"]\n",
    "    overlap = row[\"overlap_parasternal_vs_diaphragm\"]\n",
    "\n",
    "    if n_int == 0:\n",
    "        p_value = None\n",
    "        significant = None\n",
    "        perc = 0\n",
    "    else:\n",
    "        p_value = binomtest(overlap, n=n_int, p=0.5, alternative=\"greater\").pvalue\n",
    "        significant = p_value < 0.05\n",
    "        perc = round((overlap / n_int) * 100, 1)\n",
    "\n",
    "    results.append({\n",
    "        \"patient_id\": row[\"patient_id\"],\n",
    "        \"timepoint\": row[\"timepoint\"],\n",
    "        \"n_parasternal_true_peaks\": n_int,\n",
    "        \"overlap_with_diaphragm\": overlap,\n",
    "        \"overlap_percentage\": perc,\n",
    "        \"p_value\": p_value,\n",
    "        \"significant\": significant\n",
    "    })\n",
    "\n",
    "# === Dataframe bouwen en opslaan ===\n",
    "sig_df = pd.DataFrame(results)\n",
    "sig_df = sig_df.sort_values(by=[\"patient_id\", \"timepoint\"])\n",
    "sig_df.to_csv(\"significance_overlap_parasternal_vs_diaphragm.csv\", index=False)\n",
    "print(\"\\n✅ Results stored in 'significance_overlap_parasternal_vs_diaphragm.csv'\")\n",
    "\n",
    "# === Heatmap genereren ===\n",
    "pivot_vals = sig_df.pivot(index=\"patient_id\", columns=\"timepoint\", values=\"overlap_percentage\")\n",
    "pivot_sig = sig_df.pivot(index=\"patient_id\", columns=\"timepoint\", values=\"significant\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.heatmap(pivot_vals, annot=True, fmt=\".1f\", cmap=\"YlGnBu\",\n",
    "                 linewidths=0.5, linecolor='gray', cbar_kws={\"label\": \"Overlap (%)\"})\n",
    "\n",
    "# Rode rand tekenen bij significante cellen\n",
    "for y in range(pivot_vals.shape[0]):\n",
    "    for x in range(pivot_vals.shape[1]):\n",
    "        is_sig = pivot_sig.iloc[y, x]\n",
    "        if pd.notna(is_sig) and is_sig:\n",
    "            ax.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "\n",
    "plt.title(\"Overlap parasternal ↔ diaphragm EMG-peaks (significant results marked red)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Patient ID\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import binomtest\n",
    "\n",
    "# ---------------------------\n",
    "# Part 1: Load measurement classification and select included measurements\n",
    "# ---------------------------\n",
    "msr_df = pd.read_csv(\"measurement_classification.csv\")\n",
    "# Create a key by concatenating \"Patient ID\" and \"Time ID\" (after stripping spaces)\n",
    "msr_df[\"key\"] = msr_df[\"Patient ID\"].astype(str).str.strip() + \"_\" + msr_df[\"Time ID\"].astype(str).str.strip()\n",
    "# Retain only measurements labeled as \"Include\"\n",
    "include_df = msr_df[msr_df[\"Label\"] == \"Include\"]\n",
    "included_keys = set(include_df[\"key\"].unique())\n",
    "\n",
    "# ---------------------------\n",
    "# Part 2: Load asynchrony analysis data and filter for included measurements\n",
    "# ---------------------------\n",
    "ana_df = pd.read_csv(\"asynchrony_analysis_updated.csv\")\n",
    "ana_df[\"key\"] = ana_df[\"patient_id\"].astype(str).str.strip() + \"_\" + ana_df[\"timepoint\"].astype(str).str.strip()\n",
    "included_ana = ana_df[ana_df[\"key\"].isin(included_keys)].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# Part 3: Compute overall overlap summaries\n",
    "# ---------------------------\n",
    "# For diaphragm overlap with parasternal:\n",
    "#   n_diaphragm_true_peaks (total diaphragm peaks) and dia_int_overlap (overlap count)\n",
    "total_diaphragm_true = included_ana[\"n_diaphragm_true_peaks\"].sum()\n",
    "overlap_diaphragm = included_ana[\"dia_int_overlap\"].sum()\n",
    "perc_diaphragm = (overlap_diaphragm / total_diaphragm_true * 100) if total_diaphragm_true > 0 else 0\n",
    "\n",
    "# For parasternal overlap with diaphragm:\n",
    "#   n_parasternal_true_peaks (total parasternal peaks) and int_dia_overlap (overlap count)\n",
    "total_parasternal_true = included_ana[\"n_parasternal_true_peaks\"].sum()\n",
    "overlap_parasternal = included_ana[\"int_dia_overlap\"].sum()\n",
    "perc_parasternal = (overlap_parasternal / total_parasternal_true * 100) if total_parasternal_true > 0 else 0\n",
    "\n",
    "print(\"=== Overall Overlap Summary for Included Measurements ===\\n\")\n",
    "print(\"Diaphragm with Parasternal:\")\n",
    "print(f\"  Total diaphragm true peaks: {total_diaphragm_true}\")\n",
    "print(f\"  Overlap (diaphragm with parasternal): {overlap_diaphragm} ({perc_diaphragm:.1f}%)\\n\")\n",
    "print(\"Parasternal with Diaphragm:\")\n",
    "print(f\"  Total parasternal true peaks: {total_parasternal_true}\")\n",
    "print(f\"  Overlap (parasternal with diaphragm): {overlap_parasternal} ({perc_parasternal:.1f}%)\\n\")\n",
    "\n",
    "# ---------------------------\n",
    "# Part 4: Compute per-measurement overlap percentages and p-values (using a binomial test)\n",
    "# ---------------------------\n",
    "# For diaphragm overlap: p-value testing if observed proportion (dia_int_overlap / n_diaphragm_true_peaks) > 0.5\n",
    "def compute_p_diaphragm(row):\n",
    "    n = row[\"n_diaphragm_true_peaks\"]\n",
    "    overlap = row[\"dia_int_overlap\"]\n",
    "    if n > 0:\n",
    "        return binomtest(int(overlap), n=int(n), p=0.5, alternative=\"greater\").pvalue\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "included_ana[\"p_value_diaphragm\"] = included_ana.apply(compute_p_diaphragm, axis=1)\n",
    "\n",
    "# For parasternal overlap: test if (int_dia_overlap / n_parasternal_true_peaks) > 0.5\n",
    "def compute_p_parasternal(row):\n",
    "    n = row[\"n_parasternal_true_peaks\"]\n",
    "    overlap = row[\"int_dia_overlap\"]\n",
    "    if n > 0:\n",
    "        return binomtest(int(overlap), n=int(n), p=0.5, alternative=\"greater\").pvalue\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "included_ana[\"p_value_parasternal\"] = included_ana.apply(compute_p_parasternal, axis=1)\n",
    "\n",
    "# Also compute per-measurement overlap percentages\n",
    "included_ana[\"overlap_percentage_diaphragm\"] = included_ana.apply(\n",
    "    lambda row: (row[\"dia_int_overlap\"] / row[\"n_diaphragm_true_peaks\"] * 100)\n",
    "    if row[\"n_diaphragm_true_peaks\"] > 0 else None, axis=1\n",
    ")\n",
    "\n",
    "included_ana[\"overlap_percentage_parasternal\"] = included_ana.apply(\n",
    "    lambda row: (row[\"int_dia_overlap\"] / row[\"n_parasternal_true_peaks\"] * 100)\n",
    "    if row[\"n_parasternal_true_peaks\"] > 0 else None, axis=1\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# Part 5: Create pivot tables (visual dataframes) for the percentages and p-values\n",
    "# ---------------------------\n",
    "pivot_diaphragm = included_ana.pivot(index=\"patient_id\", columns=\"timepoint\", values=\"overlap_percentage_diaphragm\")\n",
    "pivot_parasternal = included_ana.pivot(index=\"patient_id\", columns=\"timepoint\", values=\"overlap_percentage_parasternal\")\n",
    "\n",
    "pivot_diaphragm_p = included_ana.pivot(index=\"patient_id\", columns=\"timepoint\", values=\"p_value_diaphragm\")\n",
    "pivot_parasternal_p = included_ana.pivot(index=\"patient_id\", columns=\"timepoint\", values=\"p_value_parasternal\")\n",
    "\n",
    "# ---------------------------\n",
    "# Part 6: Print pivot tables and produce heatmaps with red boxes for significant cells (p < 0.05)\n",
    "# ---------------------------\n",
    "print(\"=== Pivot Table: Overlap Percentage (Diaphragm with Parasternal) ===\")\n",
    "print(pivot_diaphragm)\n",
    "print(\"\\n=== Pivot Table: Overlap Percentage (Parasternal with Diaphragm) ===\")\n",
    "print(pivot_parasternal)\n",
    "\n",
    "# Heatmap for diaphragm overlap\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax1 = sns.heatmap(pivot_diaphragm, annot=True, fmt=\".1f\", cmap=\"YlGnBu\", linewidths=0.5,\n",
    "                  linecolor='gray', cbar_kws={\"label\": \"Overlap (%)\"})\n",
    "plt.title(\"Heatmap: Diaphragm with Parasternal Overlap (%)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Patient ID\")\n",
    "# Draw red rectangle around cells where p < 0.05 (based on pivot_diaphragm_p)\n",
    "for y in range(pivot_diaphragm.shape[0]):\n",
    "    for x in range(pivot_diaphragm.shape[1]):\n",
    "        p_val = pivot_diaphragm_p.iloc[y, x]\n",
    "        if pd.notna(p_val) and p_val < 0.05:\n",
    "            ax1.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Heatmap for parasternal overlap\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax2 = sns.heatmap(pivot_parasternal, annot=True, fmt=\".1f\", cmap=\"YlGnBu\", linewidths=0.5,\n",
    "                  linecolor='gray', cbar_kws={\"label\": \"Overlap (%)\"})\n",
    "plt.title(\"Heatmap: Parasternal with Diaphragm Overlap (%)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Patient ID\")\n",
    "# Draw red rectangle where p < 0.05 (using pivot_parasternal_p)\n",
    "for y in range(pivot_parasternal.shape[0]):\n",
    "    for x in range(pivot_parasternal.shape[1]):\n",
    "        p_val = pivot_parasternal_p.iloc[y, x]\n",
    "        if pd.notna(p_val) and p_val < 0.05:\n",
    "            ax2.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Laad de data (pas het pad aan indien nodig)\n",
    "df = pd.read_csv(\"emg_peak_assessment_all_patients.csv\")\n",
    "\n",
    "# Filter alleen true peaks\n",
    "true_peaks = df[df['label'] == 'True peak']\n",
    "\n",
    "# Groepeer per patiënt en timepoint\n",
    "grouped = true_peaks.groupby(['patient_id', 'timepoint'])\n",
    "\n",
    "results = []\n",
    "\n",
    "# Voor elke patiënt en timepoint\n",
    "for (pid, tp), group in grouped:\n",
    "    # Splits op kanaal\n",
    "    diaphragm_peaks = group[group['channel'] == 'diaphragm']['time_s'].values\n",
    "    parasternal_peaks = group[group['channel'] == 'parasternal']['time_s'].values\n",
    "\n",
    "    # Als één van beide leeg is, kunnen we geen overeenkomst controleren\n",
    "    if len(diaphragm_peaks) == 0 or len(parasternal_peaks) == 0:\n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'timepoint': tp,\n",
    "            'chi2': np.nan,\n",
    "            'p_value': np.nan,\n",
    "            'reject_null': 'Insufficient data'\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Check of er binnen 0.5s een piek is in het andere kanaal\n",
    "    diaphragm_matched = sum(\n",
    "        any(abs(dp - pp) <= 0.5 for pp in parasternal_peaks) for dp in diaphragm_peaks\n",
    "    )\n",
    "    diaphragm_unmatched = len(diaphragm_peaks) - diaphragm_matched\n",
    "\n",
    "    parasternal_matched = sum(\n",
    "        any(abs(pp - dp) <= 0.5 for dp in diaphragm_peaks) for pp in parasternal_peaks\n",
    "    )\n",
    "    parasternal_unmatched = len(parasternal_peaks) - parasternal_matched\n",
    "\n",
    "    # Contingency table en chi-kwadraat test\n",
    "    contingency = np.array([\n",
    "        [diaphragm_matched, diaphragm_unmatched],\n",
    "        [parasternal_matched, parasternal_unmatched]\n",
    "    ])\n",
    "\n",
    "    try:\n",
    "        chi2, p, _, _ = chi2_contingency(contingency)\n",
    "        reject_null = 'Yes' if p < 0.05 else 'No'\n",
    "    except ValueError:\n",
    "        chi2, p, reject_null = np.nan, np.nan, 'Invalid test'\n",
    "\n",
    "    results.append({\n",
    "        'patient_id': pid,\n",
    "        'timepoint': tp,\n",
    "        'chi2': chi2,\n",
    "        'p_value': p,\n",
    "        'reject_null': reject_null\n",
    "    })\n",
    "\n",
    "# Zet om naar dataframe en sla op als CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"emg_peak_match_stats.csv\", index=False)\n",
    "\n",
    "print(\"Analysis complete results stored in 'emg_peak_match_stats.csv'.\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Laad de resultaten van de analyse\n",
    "results_df = pd.read_csv(\"emg_peak_match_stats.csv\")\n",
    "\n",
    "# Zet data in een pivot-formaat voor heatmap\n",
    "pivot_chi2 = results_df.pivot(index='patient_id', columns='timepoint', values='chi2')\n",
    "pivot_pval = results_df.pivot(index='patient_id', columns='timepoint', values='p_value')\n",
    "\n",
    "# Plot de heatmap met chi-kwadraatwaarden\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(pivot_chi2, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Chi-kwadraatwaarde'})\n",
    "\n",
    "# Rood kader tekenen rond significante p-values (< 0.05)\n",
    "for y in range(pivot_chi2.shape[0]):\n",
    "    for x in range(pivot_chi2.shape[1]):\n",
    "        pval = pivot_pval.iloc[y, x]\n",
    "        if pd.notna(pval) and pval < 0.05:\n",
    "            ax.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "\n",
    "# Aanpassingen voor leesbaarheid\n",
    "plt.title('Heatmap Chi-squared test EMG overlap')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Patient ID')\n",
    "\n",
    "# Legenda toevoegen voor rood kader\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='none', edgecolor='red', linewidth=2, label='p < 0.05 (significant)')]\n",
    "plt.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.3, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Ventilator with EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# === Stap 1: Laad de data ===\n",
    "emg_df = pd.read_csv(\"emg_peak_assessment_all_patients.csv\")\n",
    "vent_df = pd.read_csv(\"ventilator_breaths_all_patients.csv\")\n",
    "\n",
    "# Filter op true peaks\n",
    "true_peaks = emg_df[emg_df['label'] == 'True peak']\n",
    "vent_groups = vent_df.groupby(['patient_id', 'timepoint'])\n",
    "\n",
    "# === Stap 2: Functie voor chi-kwadraat analyse per kanaal ===\n",
    "def compute_chi2_vs_ventilator(emg_channel):\n",
    "    results = []\n",
    "    grouped_emg = true_peaks[true_peaks['channel'] == emg_channel].groupby(['patient_id', 'timepoint'])\n",
    "\n",
    "    for (pid, tp), emg_group in grouped_emg:\n",
    "        emg_peaks = emg_group['time_s'].values\n",
    "        try:\n",
    "            vent_onsets = vent_groups.get_group((pid, tp))['time_onset_s'].values\n",
    "        except KeyError:\n",
    "            results.append({\n",
    "                'patient_id': pid,\n",
    "                'timepoint': tp,\n",
    "                'chi2': np.nan,\n",
    "                'p_value': np.nan,\n",
    "                'reject_null': 'Insufficient ventilator data'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        if len(emg_peaks) == 0 or len(vent_onsets) == 0:\n",
    "            results.append({\n",
    "                'patient_id': pid,\n",
    "                'timepoint': tp,\n",
    "                'chi2': np.nan,\n",
    "                'p_value': np.nan,\n",
    "                'reject_null': 'Insufficient data'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        emg_matched = sum(any(abs(ep - vo) <= 0.3 for vo in vent_onsets) for ep in emg_peaks)\n",
    "        emg_unmatched = len(emg_peaks) - emg_matched\n",
    "\n",
    "        vent_matched = sum(any(abs(vo - ep) <= 0.3 for ep in emg_peaks) for vo in vent_onsets)\n",
    "        vent_unmatched = len(vent_onsets) - vent_matched\n",
    "\n",
    "        contingency = np.array([\n",
    "            [emg_matched, emg_unmatched],\n",
    "            [vent_matched, vent_unmatched]\n",
    "        ])\n",
    "\n",
    "        try:\n",
    "            chi2, p, _, _ = chi2_contingency(contingency)\n",
    "            reject_null = 'Yes' if p < 0.05 else 'No'\n",
    "        except ValueError:\n",
    "            chi2, p, reject_null = np.nan, np.nan, 'Invalid test'\n",
    "\n",
    "        results.append({\n",
    "            'patient_id': pid,\n",
    "            'timepoint': tp,\n",
    "            'chi2': chi2,\n",
    "            'p_value': p,\n",
    "            'reject_null': reject_null\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# === Stap 3: Analyse uitvoeren en opslaan ===\n",
    "df_chi2_diaphragm = compute_chi2_vs_ventilator('diaphragm')\n",
    "df_chi2_parasternal = compute_chi2_vs_ventilator('parasternal')\n",
    "\n",
    "df_chi2_diaphragm.to_csv(\"chi2_emg_diaphragm_vs_ventilator.csv\", index=False)\n",
    "df_chi2_parasternal.to_csv(\"chi2_emg_parasternal_vs_ventilator.csv\", index=False)\n",
    "\n",
    "# === Stap 4: Heatmap functie ===\n",
    "def plot_chi2_heatmap(df, title):\n",
    "    # Timepoints die we willen meenemen in logische (chronologische) volgorde\n",
    "    valid_order = ['t0', 't0v1', 't1', 't3', 't4', 't6', 't12', 't24', 't48']\n",
    "    df = df[df['timepoint'].isin(valid_order)]\n",
    "\n",
    "    # Zet de timepoints als categorische data zodat ze correct gesorteerd worden\n",
    "    df['timepoint'] = pd.Categorical(df['timepoint'], categories=valid_order, ordered=True)\n",
    "\n",
    "    # Pivot tabellen voor heatmap en p-waarden\n",
    "    pivot_chi2 = df.pivot(index='patient_id', columns='timepoint', values='chi2').sort_index(axis=1)\n",
    "    pivot_pval = df.pivot(index='patient_id', columns='timepoint', values='p_value').reindex(columns=pivot_chi2.columns)\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.heatmap(pivot_chi2, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", cbar_kws={'label': 'Chi-squared value'})\n",
    "\n",
    "    # Rode rand tekenen voor significante p-waarden\n",
    "    for y in range(pivot_chi2.shape[0]):\n",
    "        for x in range(pivot_chi2.shape[1]):\n",
    "            pval = pivot_pval.iloc[y, x]\n",
    "            if pd.notna(pval) and pval < 0.05:\n",
    "                ax.add_patch(plt.Rectangle((x, y), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "\n",
    "    # Labels en legenda\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Timepoint')\n",
    "    plt.ylabel('Patiënt ID')\n",
    "\n",
    "    legend_elements = [Patch(facecolor='none', edgecolor='red', linewidth=2, label='p < 0.05 (significant)')]\n",
    "    plt.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.3, 1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Voor diaphragm-resultaten\n",
    "plot_chi2_heatmap(df_chi2_diaphragm, 'Chi-squared: EMG Diaphragm vs Ventilator Onsets')\n",
    "\n",
    "# Voor parasternal-resultaten\n",
    "plot_chi2_heatmap(df_chi2_parasternal, 'Chi-squared: EMG Parasternal vs Ventilator Onsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WILCOXON SIGNED RANK TEST\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Laad data\n",
    "df = pd.read_csv(\"breathing_sync_summary_all_patients.csv\")\n",
    "\n",
    "# Bereken totale wasted efforts per spier\n",
    "df[\"total_diaphragm\"] = df[\"wasted_effort_diaphragm\"] + df[\"complete_wasted_effort\"]\n",
    "df[\"total_parasternal\"] = df[\"wasted_effort_parasternal\"] + df[\"complete_wasted_effort\"]\n",
    "\n",
    "# Wilcoxon signed-rank test (vergelijking tussen de twee spieren)\n",
    "stat, p_value = wilcoxon(df[\"total_diaphragm\"], df[\"total_parasternal\"])\n",
    "\n",
    "print(\"Wilcoxon signed-rank test:\")\n",
    "print(f\"  W-statistic: {stat}\")\n",
    "print(f\"  p-value: {p_value:.5f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"  ✅ Significant difference found between diaphragm and parasternal.\")\n",
    "else:\n",
    "    print(\"  ❌ No significant difference found.\")\n",
    "\n",
    "# 📈 Visualisatie: boxplot\n",
    "data_melted = df[[\"total_diaphragm\", \"total_parasternal\"]].melt(var_name=\"Lead\", value_name=\"Number of Wasted Efforts\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=data_melted, x=\"Lead\", y=\"Number of Wasted Efforts\", palette=\"pastel\")\n",
    "sns.swarmplot(data=data_melted, x=\"Lead\", y=\"Number of Wasted Efforts\", color=\"black\", alpha=0.6, size=3)\n",
    "plt.title(\"Wasted efforts diaphragm vs parasternal\")\n",
    "plt.ylabel(\"Number of wasted efforts\")\n",
    "plt.xlabel(\"Lead\")\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Laad data\n",
    "df = pd.read_csv(\"breathing_sync_summary_all_patients.csv\")\n",
    "\n",
    "# Totale wasted efforts berekenen\n",
    "df[\"total_diaphragm\"] = df[\"wasted_effort_diaphragm\"] + df[\"complete_wasted_effort\"]\n",
    "df[\"total_parasternal\"] = df[\"wasted_effort_parasternal\"] + df[\"complete_wasted_effort\"]\n",
    "\n",
    "# Paired Student’s t-test\n",
    "t_stat, p_value = ttest_rel(df[\"total_diaphragm\"], df[\"total_parasternal\"])\n",
    "\n",
    "print(\"Paired Student’s t-test:\")\n",
    "print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "print(f\"  p-value: {p_value:.5f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"  ✅ Significant difference found between diaphragm and parasternal.\")\n",
    "else:\n",
    "    print(\"  ❌ No significant difference found\")\n",
    "\n",
    "# 📈 Boxplot visualisatie\n",
    "data_melted = df[[\"total_diaphragm\", \"total_parasternal\"]].melt(\n",
    "    var_name=\"Lead\", value_name=\"Number of Wasted Efforts\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=data_melted, x=\"Lead\", y=\"Number of Wasted Efforts\", palette=\"pastel\")\n",
    "sns.swarmplot(data=data_melted, x=\"Lead\", y=\"Number of Wasted Efforts\", color=\"black\", alpha=0.6, size=3)\n",
    "plt.title(\"Wasted efforts diaphragm vs parasternal\")\n",
    "plt.ylabel(\"Number of wasted efforts\")\n",
    "plt.xlabel(\"Lead\")\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
